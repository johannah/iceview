%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{longtable}
\usepackage{float}
\usepackage{calc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{UTSAthesis}      
\usepackage{times}            
\usepackage{latexsym}

\newenvironment{ruledcenter}{%
  \begin{center}
  \rule{\textwidth}{1mm} } {%
  \rule{\textwidth}{1mm} 
  \end{center}}%


  \theoremstyle{definition}
  \newtheorem{defn}{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

  \providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}

\begin{document}



\committee{Sos Agaian, Ph.D., Chair}{Prof B, Ph.D.}{Prof. C, Ph.D.}{Prof. D, Ph.D.}{    Prof. E, Ph.D. }


\informationitems{Master of Science in Electrical Engineering}{M.Sc.}{Department of Electrical Engineering}{College of Engineering}{May}{ 2016 }


\thesiscopyright{Copyright 2016 Johanna Hansen \\
All rights reserved. }


\dedication{\emph{I would like to dedicate this thesis/dissertation template
to UTSA graduate students.}}


\title{\textbf{Mosaiking Images with Non-Stationary Features}}


\author{Johanna Hansen}
\maketitle
\begin{acknowledgements}

I would also like to thank the UTSA Graduate School for reviewing
the outcome of this template document and correction of formatting
errors. 

\begin{singlespace}
\emph{This Masters Thesis/Recital Document or Doctoral Dissertation
was produced in accordance with guidelines which permit the inclusion
as part of the Masters Thesis/Recital Document or Doctoral Dissertation
the text of an original paper, or papers, submitted for publication.
The Masters Thesis/Recital Document or Doctoral Dissertation must
still conform to all other requirements explained in the Guide for
the Preparation of a Masters Thesis/Recital Document or Doctoral Dissertation
at The University of Texas at San Antonio. It must include a comprehensive
abstract, a full introduction and literature review, and a final overall
conclusion. Additional material (procedural and design data as well
as descriptions of equipment) must be provided in sufficient detail
to allow a clear and precise judgment to be made of the importance
and originality of the research reported. }

\emph{It is acceptable for this Masters Thesis/Recital Document or
Doctoral Dissertation to include as chapters authentic copies of papers
already published, provided these meet type size, margin, and legibility
requirements. In such cases, connecting texts, which provide logical
bridges between different manuscripts, are mandatory. Where the student
is not the sole author of a manuscript, the student is required to
make an explicit statement in the introductory material to that manuscript
describing the students contribution to the work and acknowledging
the contribution of the other author(s). The signatures of the Supervising
Committee which precede all other material in the Masters Thesis/Recital
Document or Doctoral Dissertation attest to the accuracy of this statement.}
\end{singlespace}
\end{acknowledgements}

\begin{abstract}
Unmanned Aerial Vehicles (UAVs) are an emerging low-cost platform for 
performing high-resolution aerial surveys.
Historically, aerial surveys 
required the use of a costly piloted plane or helicopter or  
non-real time lower-resolution satellite images. Remote ships travelling 
through ice-congested waters are concerned with moving sea ice and have 
traditionally relied on expensive helicoptors or low-resolution and infrequent 
updates from satellite imagery. UAVs empower researchers, search missions, and 
cargo vessels working in and around sea ice gain survey their near area. 

UAVs are able to capture many images of the terrain, however, humans have a 
difficult time organizing this information and benefit from an overview image.
An overview mosaic generated from individual images can be computed quickly. 

Each image captured by a UAV only portion of the landscape, however, 
this is difficult for humans to understand easily. 
To understand the images, we develop a mosaic in which the images captured 
over a given area are aligned into a large aggregate. 
By registering many images, we can create scenes of high resolution.

Algorithms for aligning and stitching images into photomosaics have been 
widely studied and commercialized, however, traditional
methods tend to fail when tasked with stitching images with non-stationary 
objects. This work attempts to build a standard system in which to mosaic images
with slow moving dynamic objects, particularly sea ice.  
Features may not be reliably observed.

\end{abstract}

\pageone{}


\chapter{Introduction}
Expeditions into the worlds cold oceans requires expert navigation and 
real-time knowledge of the conditions. Sea ice is a substantial challenge 
that requires constant monitoring. Helicopters can be used to perform 
human led scouting expeditions from vessels locked in sea ice regions, 
however, these tools are costly to operate. Unmanned Aerial Vehicles 
(AUVs) equipped with high
resolution digital cameras offer a low-cost alternitive helicopters. An automated 
aerial system for ice monitoring could provide substantial cost savings both in 
engineering and equipment time.  

The 
many small images that are collected must be geolocated so that the terrain
they cover can be interpreted by humans. Sea ice and large areas 
of water present a challenge because of their non-stationary nature.

Feature-based matching can provide robustness against scene movement and are
typically faster. They can also recognize discover overlap in an unordered set
of images. 


- A median filter can be used to remove rapidly moving objects /cite{93}


\section{Motivation}

Although UAVs can provide images with high resolution, each images only cover
a small portion of the interesting area. To make the imagery human readable, 
we need to combine all of the sequential images together into a larger image 
that covers the surveyed area. Because the distance from the UAV's camera is
much greater than the motion of the camera between views, a homographic model
can be use to describe the relationship between neighboring images 
\cite{Semple, Ma}. 
A limitation with a static map in relation to ice management is the lack of 
temporal information in terms of ice drift. 

\section{Background}
Aerial photography has been used to gain a greater viewpoint of the world and 
has been used extensively reconassance, agriculture, and science. 
Historically, images were captured on air balloons and airplanes. 

SIFT (Scale Invariant Feature Transform) and SURF (Speeded.....) features 
provide robust feature extraction (how are the good what do they do)

Underwater ....


In more recent history, most digital cameras are capable of producing an 
automatic panorama on a small electronic platform. 
Traditional mosaics are built from images taken from the same point of view, 
a panorama. Such mosaics do not change Point of view, but do increase the 
Field of view of the camera. Mosaics with extended field of view benefit 
from the relatively large and equal distance to the scene in each image. 
This is rotational motion solved by a cylindrical or spherical surface model.
The UAV image mosaic, however, the rorational motion about the camera axis 
is replaced by a translational motion model that changes point point of view.
In the case of sea ice, the observed scene is planar, taking advantage of the 
large distance to the scene and equal to each object in the image.
Structural methods expect a repeating primitive, which is unexpected in sea-ice

\section{Thesis Overview}

The focus of this thesis is on 2D mosaicing....
No practical, robust, and repeatable way of mosaicing images with non-stationary 
features in an and unstrctured fashion. This thesis demonstrates large-area 
mosaicing of sea-ice, addressing issues of image registration in a global framework. 

Relate images using a multi-scale feature detector with matching based on 
descriptors that provide invariance to rotation, scaling, and affine changes in 
intensity. This approach is purely image based and does not neccessitate the use 
of navigation data.  This approach breaks the problem into several distinct 
phases: 
\begin{list}
    \item{isolation of stationary features}
    \item{feature extraction from stationary regions}
    \item{topology estimation} 
    \item{global registration}
\end{list}
\chapter{Homographic Transformation Computation}
Unknown motion between images
Attitude and scale changes betweeen images with UAV

\section{Masking non-stationary segments}
Sezgin and Sankur, clausi 2005, 
Image stitching of overlapping images works by finding where two images overlap. 
This is done by matching features. However, POV change and non-stationary pixels, 
as water is. We can exclude water from the feature extraction by first segmenting
the image. In this case, ice or non-ice pixels. There are many ways of segmenting 
images. Perhaps the most trivial is thrsholding.  
grey level co-occurrence probabilities (GLCPs) must be tuned by hand
Thresholding is simply the method of binarizing an image
by setting all pixels whose values are greater than some
threshold level to “high”, and the remaining pixels to “low”.
Gabor filter (signal processing based), 
gabor filters have had mixed success
(GLCPs) (statistically based), and Markov random fields
(MRFs) (model-based).
The associated
histograms for these images are generally bimodal so a mixture
model can be used to approximate such a histogram and obtain
the individual components. As mentioned earlier, a Gamma
distribution is used as a model in SAR image recognition. It
is therefore reasonable to assume that an ice-water image is a
mixture of two Gamma distributions.
edge detection
no ground truth - 

\section{Feature Extraction}
Overlapping images can be related by a motion model
A 2D motion model imposes on a image a single global 2D transformation 
that defines displacement of each pixel of an image. 

indirect vs direct methods

Directly matching pixel intensitiesis one method - slow, most systems instead 
implement feature based correspondence. Distinctive features sets are 
extracted from each images to establish image correspondence. 
A wide variety of scale and rotation invariant feature extraction algorithms 
are available for detecting correspondences between images. ... SFIT seems best
Schmid - survey of feature
Invariant features - 

Corner like features -Hessian and eigenvalue.
Harris corners are not invariant to scaling, and cross correlation
is not invariant to translation. 
- 2-D projective transformation. Can be computed without any knowledge of 
the internal camera calibration parameters.  No need to know focal length, 
optical center, or relative camera motion between frames. 
Manually identify four or more corresponding points between two views, which
 is enough information to solve for eight unknowns in the 2-D projective
 transformation. 
Image stitching covers the method of combining many individual images into 
one mosaic. Determine how two images are aligned to each other. Blending t
Image registration strategies find correspondences between two images. 
Most methods utilize intersting points, such as regions of color, edges, 
contours, or distinctive points. These features are then searched for in 
nearby images. If distinctive features are detected, they are matched to 
determine correspondences. UAV images are taken at different points of view 
and at different times. Features can be extracted.... discrete features of 
interest as keypoints that are identified in different viewing conditions. 
The neighborhood around the keypoints is represented by a description vector. 
Theoretically, only four corresponding points are required to determine 
homography between two images. 

Different type of feature extraction....
low-overlap
depth-reconstruction
3-D is more difficult to automate reliably. 

Descriptors are used to pre-process images in order to make their features more 
invariant to scale, rotation, and translation transformations. 
\subsection{Zernike Moments}
terrain is planar, optical axis is perpendicular, narrow field of view
\subsection{Learned Features}
\section{Feature Matching}
 Need to determine if two images overlap - correspondence problem before 
 solving for the transform that relates an image pair. Traditional implementations 
 use correlation. 
Direct methods, are effective with high image overlap 
- assume mostly translational 
- break down with high rotation and low overlap. 
Images with significant rotation, scalling, affine transforms can be registered 
using frequency based techniques. 
It is only necessary to match each image to a small number of neighboring 
images. 
Features are used to determine which features come from corresponding locations 
in the images. Local motion areound each feature point is expected to be mostly 
translational. 


\section{Perspective Tranformation}
Traditional matching algorithms recover motion models 

The distance from the camera to the target object is much greater than the 
motion between the camera views, so a homographic model can be used to describe. 
Once a match is determined between two images, each pixel from the source image 
must be mapped to a pixel coordinate in the destination image. An image 
transformation can be described by ... type of transformation matrix.
 To determine homography matrix from the features, direct or approximate methods. 
 Direct (direct linear tranform) .... 
 Require more feature matches than the minimum four. But each keypoint has 
 uncertanty. For robust homography, we find the homography that minimizes error.
\section{Homography Covariance Estimation}
The covariance matrix of the homography is used to measure accuracy. 
Random Sample Consensus (RANSAC) was used to determine homography 
between two images. 
\section{Blending}
When merging two images into one image, blending of the pixel values should 
be applied to produce a more pleasing result. This approach utilizes the open 
source tool, enblend, that uses a multi-resolution spline to blend images 
together. Enblend combines the images across a transition zone that is proportional 
to the spatial frequency of the region. Homogenous regions like an ice sheet 
have low spatial and are combined across a wide region. Strong color changes, 
like a seal lying on an ice sheet, show high spatial frequency and are fused 
over a small area. 

\section{Global Registration}
Bundle adjustment can solve for all camera parameters jointly. This minimizes
accumulated errors between pairwise homographies. 
Incremental links - solves for the global mosaic using the overlaps of the 
temporal sequence. 


\section{Assumptions and Approach}
Assume that images have been acquired in a temporal sequence. Although this is
not required, it will reduce convergence time. Navigation data
is not required. 

\section{Datasets}
\subsection{Aerial Surveys}

\subsection{Image Patches}

\chapter{Results}
Evaluation of quality - geospatial correctness of ground areas
standard measurments, cross correlation between images - 
speed ...
keypoint matching efficiency - 
W
\section{Error Metrics} 

\section{Validation - Synthetic Mosaic}
A synthetic survey is generated from a single image by dividing the image into
a grid overlapping sub-images.  This provides a planar scene with an ideal 
pinhole camera. Simple translations produce the resulting image. Another test 
should introduce rotation and scaling into each sub-image. 

\chapter{Conclusion and Future Work}
\subsection{UAV Sensor Integration}
\section{References}


\pagebreak{}

\bibliographystyle{plain}
\bibitem{J. Semple, G. Kneebone. "Algebraic projective geometry," Oxford
University Press, 1952}

\bibitem{S. Ma, Z. Zhang. "Computer Vision," Science Press, Beijing, 2004.}
\bibliography{sampleThesis}

\begin{vita}
This should be a one-page short vita.

There can be more paragraphs.\end{vita}

\end{document}


%
%\begin{figure}[H]
%\noindent \begin{centering}
%\framebox{\begin{minipage}[t]{1\columnwidth}%
%\textbackslash{}documentclass{[}12pt,english{]}\{report\}
%
%\textbackslash{}usepackage\{UTSAthesis\}
%
%... use other packages ...
%
%\textbackslash{}begin\{document\}
%
%\textbackslash{}committee\{... \}
%
%\textbackslash{}informationitems\{... \}
%
%\textbackslash{}thesiscopyright\{...\}
%
%\textbackslash{}dedication\{\textbackslash{}emph\{I would like to
%dedicate this thesis/dissertation to ...\}\}
%
%\textbackslash{}title\{\textbackslash{}textbf\{First line\}\textbackslash{}\textbackslash{}
%\textbackslash{}textbf\{second line \}...\}
%
%\textbackslash{}author\{...\} 
%
%\textbackslash{}maketitle 
%
%\textbackslash{}begin\{acknowledgements\} ... \textbackslash{}end\{acknowledgements\}
%
%\textbackslash{}begin\{abstract\} ... \textbackslash{}end\{abstract\}
%
%\textbackslash{}newpage 
%
%\textbackslash{}pagenumbering \{arabic\} 
%
%\textbackslash{}setcounter \{page\}\{1\} 
%
%\textbackslash{}pagestyle\{plain\}
%
%\textbackslash{}chapter\{...\} \% or \textbackslash{}include\{chap3\}
%
%...
%
%\textbackslash{}singlespace
%
%\textbackslash{}bibliographystyle\{...\} 
%
%\textbackslash{}bibliography\{...\}
%
%\textbackslash{}begin\{vita\}...\textbackslash{}end\{vita\}%
%\end{minipage}}
%\par\end{centering}
%
%\caption{Structure of a thesis \protect\LaTeX{} file\label{fig:Structure-of-thesis}}
%\end{figure}
%
%
%The following commands are defined in UTSAthesis.sty and should be
%used in the order suggested in Fig. \ref{fig:Structure-of-thesis}
%to provide required format information.
%\begin{itemize}
%\item \textbackslash{}title\{Thesis Title\}. This can contain multiple lines.
%Use ``\textbackslash{}\textbackslash{}'' to go to the next line.
%\item \textbackslash{}author\{Name of Thesis Author\}
%\item \textbackslash{}thesiscopyright\{Optional Copyright Statement\} 
%\item \textbackslash{}dedication\{Optional Dedication\} 
%\item Either \textbackslash{}committee\{Supervisor Name, Degree\}\{Co-Supervisor
%or Committee B Name, Degree\}\{Committee C Name, Degree\}\{Committee
%D Name, Degree\}\{Committee E Name, Degree\} or the following commands
%separately.
%
%\begin{itemize}
%\item \textbackslash{}supervisor\{Supervisor Name, Degree\} 
%\item \textbackslash{}cosupervisor\{Co-Supervisor Name, Degree\} or \textbackslash{}committeeB\{Committe
%member B Name, Degree\} 
%\item \textbackslash{}committeeC\{Committe member C, Degree\} 
%\item \textbackslash{}committeeD\{Committe member D, Degree\} 
%\item \textbackslash{}committeeE\{Committe member E, Degree\}
%\end{itemize}
%\item Either \textbackslash{}informationitems\{Full Name of Degree\}\{Short
%Name of Degree\}\{Full Name of Department\}\{Full Name of College\}\{Month
%of Thesis\}\{Year of Thesis\} or use the following commands separately.
%
%\begin{itemize}
%\item \textbackslash{}degree\{Full Degree Name\} 
%\item \textbackslash{}degreeshort\{Short Degree Name\} 
%\item \textbackslash{}department\{Department Name\} 
%\item \textbackslash{}college\{College Name\} 
%\item \textbackslash{}thesismonth\{Month\} 
%\item \textbackslash{}thesisyear\{Year\} 
%\end{itemize}
%\item \textbackslash{}maketitle is the command to produce the signature
%page, copyright page, dedication page, and the title page. The position
%of this command is important. 
%\item \textbackslash{}begin\{acknowledgements\}
%
%
%People, organization, supports that you want to thank for 
%
%
%\textbackslash{}end\{acknowledgements\}
%
%\item \textbackslash{}begin\{abstract\}
%
%
%The abstract starts here. Should within one page.
%
%
%\textbackslash{}end\{abstract\} 
%
%\item The thesis/dissertation should then continue with chapters, appendixes,
%references. Before the first chapter, it is necessary to set Arabic
%page number. If the thesis/dissertation is long, it may be better
%to place chapters into separate \LaTeX{} files and include these sub-files
%using \textbackslash{}include\{\} command.
%\item \textbackslash{}begin\{vita\}
%
%
%The last item is a one-page curriculum vita
%
%
%\textbackslash{}end\{vita\}
%
%\end{itemize}
%
%\subsection{Produce the Outcome}
%
%To produce the pdf version of the thesis/dissertation, run pdflatex
%and bibtex.
%
%
%\section{The utsathesis.layout Package}
%
%The utsathesis.layout is an \LyX{} layout that provides a \LyX{} document
%layout for UTSA dissertation/thesis. This layout should be used together
%with the UTSAthesis.sty.
%
%
%\subsection{Installation}
%
%First, install UTSAthesis.sty as described in Section \ref{sec:UTSAthesis.sty}.
%Then, installed the \LyX{} on your system by following the instruction
%that comes with the \LyX{} package. Next, place the utsathesis.layout
%into your personal \LyX{} directory. On a Linux/Unix system, this
%directory is at \textasciitilde{}/.lyx/layouts. On Mac OS, it is at
%/User/<name>/Library/Application Support/\LyX{}-<version>/layouts.
%On Windows 7, it is at C:\textbackslash{}Users\textbackslash{}<name>\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}lyx<version>\textbackslash{}layouts.
%Remember to run Tools->Reconfigure inside \LyX{} to re-configure the
%system.
%
%
%\subsection{Use of utsathesis.layout Package}
%
%This document (sampleThesis.lyx) provides a template for using the
%utsathesis.layout to write a Ph.D. dissertation. For a Master's thesis,
%go to Document->Settings and set the class option to ms. Other important
%settings may include Document->Settings->\LaTeX{} Preamble, and the
%bibliography style.
%
%The document setting should be ``report (UTSAthesis 2012)''. The
%document should begin with committee info, thesis info, copyright,
%and dedication. These can be formatted using items in the FrontMatter
%in the pull-down menu. These should be followed by title, author,
%acknowledgments and the abstract. The placement and the order of these
%four items are important for generating the correctly formatted front
%pages of the thesis/dissertation. It is also important to add the
%``Start First Page'' item right before the first chapter. This item
%will set the correct page numbers for the main portion of the thesis/dissertation.
%
%At the end of the document, the ``Vita'' item in the BackMatter
%in the pull-down menu needs to be used to format a one-page vita.
%
%Regular chapters can be included in the main thesis document or more
%likely as sub-files, one per chapter. If sub-files are preferred,
%make sure the document settings of all sub-files are identical to
%the main document. 
%
%
%\chapter{Literature Review}
%
%We have some citations \cite{dabiri-optimization-isqed-2008,melhem-ieeetc-2003,pradhan-fault-tolerance-1986}.
%See the Bibliography for the format of references.
%
%\include{chapt3}
%
%
%\chapter{Solution and Evaluation}
%
%In this chapter, we show the structures of math formula, theorem commands,
%and floats (such as algorithm and table).
%
%
%\section{A Theory}
%\begin{defn}
%This is another definition.\end{defn}
%\begin{thm}
%This is a theorem.
%\begin{equation}
%X=\frac{AB}{Y}
%\end{equation}
%\end{thm}
%\begin{proof}
%The proof is done here.
%\end{proof}
%
%\section{An Algorithm}
%
%The following is the algorithm.
%
%\begin{algorithm}
%\begin{enumerate}
%\item Step One
%\item Step Two
%\end{enumerate}
%\caption{The Do-It-Yourself Method}
%
%
%\end{algorithm}
%
%
%
%\subsection{Evaluation}
%
%The evaluation results is shown in the following table. It is straightforward
%to place the caption of the table above or below the table.
%
%\begin{table}
%\caption{Evaluation Results}
%
%
%\noindent \centering{}%
%\begin{tabular}{|c|c|c|c|}
%\hline 
% & Method 1 & Method 2 & Method 3\tabularnewline
%\hline 
%\hline 
%Criterion 1 &  &  & \tabularnewline
%\hline 
%Criterion 2 &  &  & \tabularnewline
%\hline 
%Criterion 3 &  &  & \tabularnewline
%\hline 
%\end{tabular}
%\end{table}
%
%
%The following is a long table
%
%\noindent \begin{center}
%\begin{longtable}{|c|c|c|c|c|}
%\caption{A Long Table\label{tab:A-Long-Table}}
%\endfirsthead
%\multicolumn{5}{c}{\textbf{Table \ref{tab:A-Long-Table}}: Continued}\tabularnewline
%\endhead
%\hline 
%Column1 & Column 2 & Column 3 & Column 4 & Column 5\tabularnewline
%\hline 
%\hline 
%1 &  &  &  & \tabularnewline
%\hline 
%2 &  &  &  & \tabularnewline
%\hline 
%3 &  &  &  & \tabularnewline
%\hline 
%4 &  &  &  & \tabularnewline
%\hline 
%5 &  &  &  & \tabularnewline
%\hline 
%6 &  &  &  & \tabularnewline
%\hline 
%7 &  &  &  & \tabularnewline
%\hline 
%8 &  &  &  & \tabularnewline
%\hline 
%9 &  &  &  & \tabularnewline
%\hline 
%10 &  &  &  & \tabularnewline
%\hline 
%11 &  &  &  & \tabularnewline
%\hline 
%12 &  &  &  & \tabularnewline
%\hline 
%13 &  &  &  & \tabularnewline
%\hline 
%14 &  &  &  & \tabularnewline
%\hline 
%15 &  &  &  & \tabularnewline
%\hline 
%16 &  &  &  & \tabularnewline
%\hline 
%17 &  &  &  & \tabularnewline
%\hline 
%18 &  &  &  & \tabularnewline
%\hline 
%19 &  &  &  & \tabularnewline
%\hline 
%20 &  &  &  & \tabularnewline
%\hline 
%21 &  &  &  & \tabularnewline
%\hline 
%22 &  &  &  & \tabularnewline
%\hline 
%23 &  &  &  & \tabularnewline
%\hline 
%24 &  &  &  & \tabularnewline
%\hline 
%25 &  &  &  & \tabularnewline
%\hline 
%26 &  &  &  & \tabularnewline
%\hline 
%27 &  &  &  & \tabularnewline
%\hline 
%28 &  &  &  & \tabularnewline
%\hline 
%29 &  &  &  & \tabularnewline
%\hline 
%30 &  &  &  & \tabularnewline
%\hline 
%31 &  &  &  & \tabularnewline
%\hline 
%32 &  &  &  & \tabularnewline
%\hline 
%33 &  &  &  & \tabularnewline
%\hline 
%\end{longtable}
%\par\end{center}
%
%
%\chapter{Future Directions}
%
%There can be more chapters.
%
%\appendix
%
%\chapter{Notations }
%
%Here we show the use of multiple appendixes.
%
%
%\section{Math Notations}
%
%Each appendix can have sub-sections as a regular chapter.
%
%
%\section{Additional Notations}
%
%
%\chapter{Ontologies}
%
%These is another appendix.

