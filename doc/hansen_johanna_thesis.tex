%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{longtable}
\usepackage{float}
\usepackage{calc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{UTSAthesis}      
\usepackage{times}            
\usepackage{latexsym}

\newenvironment{ruledcenter}{%
  \begin{center}
  \rule{\textwidth}{1mm} } {%
  \rule{\textwidth}{1mm} 
  \end{center}}%


  \theoremstyle{definition}
  \newtheorem{defn}{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

  \providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}

\begin{document}
\bibliographystyle{acm}
\committee{Sos Agaian, Ph.D., Chair}{Prof Hanumant Singh, Ph.D.}{Prof. C, Ph.D.}{Prof. D, Ph.D.}{Prof. E, Ph.D. }


\informationitems{Master of Science in Electrical Engineering}{M.Sc.}{Department of Electrical Engineering}{College of Engineering}{May}{ 2016 }


\thesiscopyright{Copyright 2016 Johanna Hansen \\
All rights reserved. }


\dedication{\emph{I would like to dedicate this thesis to the many mentors and 
teachers who have guided me throughout this process.}}


\title{\textbf{Mosaiking Images with Non-Stationary Features}}


\author{Johanna Hansen}
\maketitle
\begin{acknowledgements}

I would also like to thank the UTSA Graduate School for reviewing
the outcome of this template document and correction of formatting
errors. 

\end{acknowledgements}

\begin{abstract}

Unmanned Aerial Vehicles (UAVs) are an emerging low-cost platform for 
performing high-resolution aerial surveys. Low-altitude UAVs collect many 
high resolution images that represent only a small footprint of the scene. 
In order for this data to provide a useful overview of humans, overlapping images 
need to be aligned and stitched together to provide an overview of a scene. 
In this thesis, we look at data collected over sea ice with UAVs. Traditional 
stitching algorithms tend to fail when faced with sea ice scenes for two reasons; 
ice itself typically has very few features from which to match to overlapping 
images and water is  nonstationary, making it impossible to match with 
overlapping images that are taken at a different point in time. 

In this thesis we first detect and mask non-stationary features from keypoint 
consideration. We then investigate and compare several keypoint detection 
schemes. 

Functionality is tested on data collected by several UAVs in different 
conditions. 

\end{abstract}
\pageone{}

\chapter{Introduction}
Expeditions into the worlds cold oceans requires expert navigation and 
real-time knowledge of the conditions. 
This region of the earth 
is both interesting from a scientific perspective because it has had little 
exploration and from a commercial aspect because of increasing 
accessibility to Artic and Antartic in recent years. 
However, sea ice presents a substantial challenge 
that requires constant monitoring. Helicopters can be used to perform 
human led scouting expeditions from vessels locked in sea ice regions, 
however, these tools are costly to operate. Unmanned Aerial Vehicles 
(AUVs) equipped with high
resolution digital cameras offer a low-cost alternitive helicopters. An automated 
aerial system for ice monitoring could provide substantial cost savings both in 
engineering and equipment time.  

Although UAVs are able to capture imagery of the terrain, humans have a 
difficult time organizing this information and benefit from an overview image.
By registering many images into a single mosaic, 
we can create large scenes of high resolution.
Image registration involves overlaying multiple images from the same scene 
that were captured from a subset of different viewpoints, times, and/or cameras.

Algorithms for aligning and stitching images into photomosaics have been 
widely studied and commercialized, however, traditional
methods tend to fail when tasked with stitching sea ice imagery.
Both the ice and sea that are present in this type of imagery present challenges 
for tradational mosaiking approaches. The ice itself is near featureless. Bodies 
of water are generally useless for feature matching because of its dynamic 
properties and meaningless features over time. 

This work attempts to build a standard system in which to mosaic images
with non-stationary objects and near featureless terrain, particularly sea ice.  

\section{Motivation}
Although UAVs can provide images with high resolution, each image has a 
limited field of view (FOV). To make the imagery human readable, 
we need to combine all of the sequential images together into a larger image 
that covers the surveyed area. Because the distance from the UAV's camera is
much greater than the motion of the camera between views, a homographic model
can be use to describe the relationship between neighboring images 
\cite{Semple, Ma}. 

Assumptions made by traditional approaches that cause the algorithms to fail:



\section{Background}
Aerial photography has been used to gain a greater viewpoint of the world and 
has been used extensively reconassance, agriculture, and science. 
Historically, images were captured on air balloons and airplanes. 

A limitation with a static map in relation to ice management is the lack of 
temporal information in terms of ice drift. 
Could also make rough alignment using GPS data - fast , but quality suffers. 
Common features between consecutive images to infer motion between images. 
REquires overlap between images  and higher computing requirments, but produces
accurate results. May not be able to register images if the overlap area is too 
or if the scene is featureless. 

A set of features is computed for every image
feature tracking may fail if there is insufficient matches - low overlap or featureless.
Considerable effort has been invested in improving the robustness of 
image mosaic techniques to changes in sensors, illumination, and zoom.  
Lower resolution -to identify crossover points

SIFT provide a fully automatic construction 
of mosaic that is insensitive to ordering, orientation, scale, and illumination 
of the images. 

Underwater ....


In more recent history, most digital cameras are capable of producing an 
automatic panorama on a small electronic platform. 
Traditional mosaics are built from images taken from the same point of view, 
a panorama. Such mosaics do not change Point of view, but do increase the 
Field of view of the camera. Mosaics with extended field of view benefit 
from the relatively large and equal distance to the scene in each image. 
This is rotational motion solved by a cylindrical or spherical surface model.
The UAV image mosaic, however, the rorational motion about the camera axis 
is replaced by a translational motion model that changes point point of view.
In the case of sea ice, the observed scene is planar, taking advantage of the 
large distance to the scene and equal to each object in the image.
Structural methods expect a repeating primitive, which is unexpected in sea-ice

Most modern stitching algorithms utilize feature based correspondence and 
consist of the following steps: 
\begin{enumerate}
\item{Identify features or keypoints from each image}
\item{Determine matching features between images}
\item{Estimate homography between images that contain the same keypoints}
\item{Warp images according to estimated homographies so that their overlapping 
regions align}
\item{Paste warped images onto a common scene and blend neighboring pixels}
\end{enumerate}
 
For the iceview problem, we add an additional preliminary step to detect 
nonstationary features and remove them from the pixels that are considered for 
feature detection. 

\section{Thesis Overview}
This thesis introduces our efforts to create high quality mosaics given a sparse
sampling of either a static or dynamic environment
The focus of this thesis is on 2D mosaicing....
No practical, robust, and repeatable way of mosaicing images with non-stationary 
features in an and unstrctured fashion. This thesis demonstrates large-area 
mosaicing of sea-ice, addressing issues of image registration in a global framework. 

nearly planar scene

Relate images using a multi-scale feature detector with matching based on 
descriptors that provide invariance to rotation, scaling, and affine changes in 
intensity. This approach is purely image based and does not neccessitate the use 
of navigation data.  This approach breaks the problem into several distinct 
phases: 
%\begin{list}
%    \item{isolation of stationary features}
%    \item{feature extraction from stationary regions}
%    \item{topology estimation} 
%    \item{global registration}
%\end{list}
\chapter{Methods}
Unknown motion between images
Attitude and scale changes betweeen images with UAV

\section{Image Segmentation}

Image stitching techniques utilize features that are consistent amongst 
overlapping images. Overlapping images captured from a UAV of the same scene are 
captured at different points in time. If objects from the scene change between 
the times in which the image is taken, the matching algorithm can fail. At best 
this typically results in blurring of the scene which changes, at worst, this 
can cause the overlapping images to not be matched at all. 
 field of view of the camera includes mostly dynamic regions,
There are many methods for mosaicing a scene with dynamics in the static mosaic. 
Some approaches eliminate all dynamic information in the scene, while others 
attempt to encapsulate the changes between images by overlaying the movement 
into the mosaic. For the purposes of the iceview system, the dynamic movement 
of waves is not interesting information, so we blur the movement in this section. 
We can exclude water from the feature extraction by first segmenting
the image into ice or non-ice pixels. 

Segmentation: 
Thresholding gray level occurance
gabor filter - texture
glcp - statistical
mrf

The histograms for sea ice images are generally bimodal, so a mixture
model can be used to approximate such a histogram and obtain
the individual components. 

\section{Feature Extraction}

Image registration often use \emph{keypoints} or 
\emph{features} from an image and a 
\emph{descriptor} which contains a description of the neighborhood of 
pixels around a keypoint. 
Choosing an appropriate feature detection and description algorithm is a 
tradeoff between feature uniqueness, robustness, lighting, and 
computation time. 

\subsection{SIFT}
One of the most well known and often used keypoint descriptors is Scale
 Invariant Feature Transform  or SIFT \cite{SIFT} which detects keypoints 
 based on Difference of Gaussians (DOG). OLD - Large computational burden. 
 
 A successor to SIFT, Speeded-Up Robust Features (SURF) is a popular algorithm that yields similar feature performance to SIFT, but with 
 faster computation time \cite{SURF}. SURF keypoints are invariant to 
 rotation and scale changes \cite{SURF}.

Binary keypoint descriptors show similar performance to SIFT-like 
descriptors, but with lower computational costs. Each bit in a binary descriptor is independent and Hamming distance can be used as a similarity 
measure instad of Euclidean distance \cite{Bekele}. 


A wide variety of scale and rotation invariant feature extraction algorithms 
are available for detecting correspondences between images. ... SFIT seems best
SIFT features are computed by estimating a local orientation and using a 
histogram of the local gradient orientations. Gradients are copied into 
different orientation planes such that blurred, re-sampled versions of the images 
are used as features. This provides the descriptor with some insensitivity to 
small feature localization errors and geometric distortions. 

Schmid - survey of feature
Invariant features - 

Corner like features -Hessian and eigenvalue.
Harris corners are not invariant to scaling, and cross correlation
is not invariant to translation. 
- 2-D projective transformation. Can be computed without any knowledge of 
the internal camera calibration parameters.  No need to know focal length, 
optical center, or relative camera motion between frames. 
Manually identify four or more corresponding points between two views, which
 is enough information to solve for eight unknowns in the 2-D projective
 transformation. 
Image stitching covers the method of combining many individual images into 
one mosaic. Determine how two images are aligned to each other. Blending t
Image registration strategies find correspondences between two images. 
Most methods utilize intersting points, such as regions of color, edges, 
contours, or distinctive points. These features are then searched for in 
nearby images. If distinctive features are detected, they are matched to 
determine correspondences. UAV images are taken at different points of view 
and at different times. Features can be extracted.... discrete features of 
interest as keypoints that are identified in different viewing conditions. 
The neighborhood around the keypoints is represented by a description vector. 
Theoretically, only four corresponding points are required to determine 
homography between two images. 

Different type of feature extraction....
low-overlap
depth-reconstruction
3-D is more difficult to automate reliably. 

Descriptors are used to pre-process images in order to make their features more 
invariant to scale, rotation, and translation transformations. 
terrain is planar, optical axis is perpendicular, narrow field of view
\subsection{ORB}
\cite{ORB}
\subsection{Zernike Moments}
rotational invariant and can be made to be scale and translational invariant. 
Magnitude of zernike moments are rotationally invariant. Used by \cite{pizarro}

\section{Feature Matching}
 Ratio test? - ratio of the distance of the best match to the second best
 match - if this ratio is greater than 0.9 both of the matches are ignored. 
 If not, the best match is kept. This eliminates false matches. 

 Need to determine if two images overlap - correspondence problem before 
 solving for the transform that relates an image pair. Traditional implementations 
 use correlation. 
Simplist way is to compare all features in one images against all features 
in the other, however, this is quadratic in the expected number of features. 
Direct methods, are effective with high image overlap 
- assume mostly translational 
- break down with high rotation and low overlap. 
Images with significant rotation, scalling, affine transforms can be registered 
using frequency based techniques. 
It is only necessary to match each image to a small number of neighboring 
images. 
Features are used to determine which features come from corresponding locations 
in the images. Local motion areound each feature point is expected to be mostly 
translational. 

\subsection{Evaluation of Descriptors}
Recall and precision
can be used to compare performance of descriptors demonstrated \cite{Bekele}
and \cite{Schmid}. \cite{Schmid} concluded that SIFT-like descriptors yield
the best performance on the Oxford dataset. \cite{Heinly} compared SIFT, SURF, and ORB on the Oxford data set. Heinly concluded that the descriptors should be adapted to the data.

Corner detectors are fast to find 
and describe, but more effort must be spent to match and reject incorrect 
matches. Sharp corners and edges make excellent features for detection 
and matching, this does not exist on images that are encompassed 
entirely be and iceberg. 
Evaluation of keypoint detectors. Bekele et al provides an evaluation 
of keypoint detectors in \cite{Bekele} in which escriptors are considered 
from BRIEF, ORB, BRISK, and FREAK. 

Two images contain brightness changes, viewpoint, rotation, scale.
To evaluate the descriptors on this dataset, four parameters were 
calculated for each of the proposed descriptors. Average number of keypoints, precision in percentage, recall in percentage, 
average number of best matches. Parameters in each of the detectors are 
tuned so that xxx features are detected in the reference image.  
-- What is the best number of features? 
If more than xxx features are detected, the first xxx are taken as 
in \cite{Bekele}.  

Calculation of the precision is performed by finding 
the ration of the number of matches that are output of RANSAC from each 
ratio test matches. 

Recall is calculated by taking the ratio of ransac 
matches to the number of keypoints. 

Accuracy is the ratio of the number of ransac matches to the number of 
keypoints. 
Average number of best matches - multiplying the average number of 
keypoints with the percentage of the accuracy. 

\section{Perspective Tranformation} 
Traditional matching algorithms recover motion models 

The distance from the camera to the target object is much greater than the 
motion between the camera views, so a homographic model can be used to describe. 
Once a match is determined between two images, each pixel from the source image 
must be mapped to a pixel coordinate in the destination image. An image 
transformation can be described by ... type of transformation matrix.
 To determine homography matrix from the features, direct or approximate methods. 
 Direct (direct linear tranform) .... 
 Require more feature matches than the minimum four. But each keypoint has 
 uncertanty. For robust homography, we find the homography that minimizes error.
\section{Homography Covariance Estimation}
The covariance matrix of the homography is used to measure accuracy. 
RANdom Sample Consensus (RANSAC) was used to determine homography 
between two images.  Find the best projective relationship between the two 
image keypoints by computating a fundamental matrix from random sample 
points. Find the set of final best matches.
\section{Blending}
When merging two images into one image, blending of the pixel values should 
be applied to produce a more pleasing result. This approach utilizes the open 
source tool, enblend, that uses a multi-resolution spline to blend images 
together. Enblend combines the images across a transition zone that is proportional 
to the spatial frequency of the region. Homogenous regions like an ice sheet 
have low spatial and are combined across a wide region. Strong color changes, 
like a seal lying on an ice sheet, show high spatial frequency and are fused 
over a small area. 

\section{Global Registration}
add new images to mosaic one at a time, aligning the most recent image with the 
previous ones already in the collection. A better alternative is to simultaneously 
align all the images together using a least squares framework to distribute 
mis-registration errors. The process of simultaneously adjusting pose parameters 
number of images in bundle adjustment. structure from motion problem
Bundle adjustment can solve for all camera parameters jointly. This minimizes
accumulated errors between pairwise homographies. 

Incremental links - solves for the global mosaic using the overlaps of the 
temporal sequence. 
 
 The disadvantage of bundle adjustment is that there are more variables to solve 
 for, so both each iteration and overal onvergence is slower. 

extract features and put into indexing structure
compare feature descriptors to find best match
ransac find set of inliers using pair of matches to hypothesize a similary
which actually correspond? difficult problem, - can perform direct pixel based 
comparison - but will fail if moving objects
\section{Assumptions and Approach}
Assume that images have been acquired in a temporal sequence. Although this is
not required, it will reduce convergence time. Navigation data
is not required. 

\section{Datasets}
\subsection{Aerial Surveys}

\subsection{Image Patches}

\chapter{Results}
Evaluation of quality - geospatial correctness of ground areas
standard measurments, cross correlation between images - 
speed ...
keypoint matching efficiency - 
W
\section{Error Metrics} 

\section{Validation - Synthetic Mosaic}
A synthetic survey is generated from a single image by dividing the image into
a grid overlapping sub-images.  This provides a planar scene with an ideal 
pinhole camera. Simple translations produce the resulting image. Another test 
should introduce rotation and scaling into each sub-image. 

\chapter{Conclusion and Future Work}
\subsection{UAV Sensor Integration}


\pagebreak{}
\section{References}
\bibliography{biblio}
\begin{vita}
This should be a one-page short vita.

There can be more paragraphs.\end{vita}
\end{document}



%
%\begin{figure}[H]
%\noindent \begin{centering}
%\framebox{\begin{minipage}[t]{1\columnwidth}%
%\textbackslash{}documentclass{[}12pt,english{]}\{report\}
%
%\textbackslash{}usepackage\{UTSAthesis\}
%
%... use other packages ...
%
%\textbackslash{}begin\{document\}
%
%\textbackslash{}committee\{... \}
%
%\textbackslash{}informationitems\{... \}
%
%\textbackslash{}thesiscopyright\{...\}
%
%\textbackslash{}dedication\{\textbackslash{}emph\{I would like to
%dedicate this thesis/dissertation to ...\}\}
%
%\textbackslash{}title\{\textbackslash{}textbf\{First line\}\textbackslash{}\textbackslash{}
%\textbackslash{}textbf\{second line \}...\}
%
%\textbackslash{}author\{...\} 
%
%\textbackslash{}maketitle 
%
%\textbackslash{}begin\{acknowledgements\} ... \textbackslash{}end\{acknowledgements\}
%
%\textbackslash{}begin\{abstract\} ... \textbackslash{}end\{abstract\}
%
%\textbackslash{}newpage 
%
%\textbackslash{}pagenumbering \{arabic\} 
%
%\textbackslash{}setcounter \{page\}\{1\} 
%
%\textbackslash{}pagestyle\{plain\}
%
%\textbackslash{}chapter\{...\} \% or \textbackslash{}include\{chap3\}
%
%...
%
%\textbackslash{}singlespace
%
%\textbackslash{}bibliographystyle\{...\} 
%
%\textbackslash{}bibliography\{...\}
%
%\textbackslash{}begin\{vita\}...\textbackslash{}end\{vita\}%
%\end{minipage}}
%\par\end{centering}
%
%\caption{Structure of a thesis \protect\LaTeX{} file\label{fig:Structure-of-thesis}}
%\end{figure}
%
%
%The following commands are defined in UTSAthesis.sty and should be
%used in the order suggested in Fig. \ref{fig:Structure-of-thesis}
%to provide required format information.
%\begin{itemize}
%\item \textbackslash{}title\{Thesis Title\}. This can contain multiple lines.
%Use ``\textbackslash{}\textbackslash{}'' to go to the next line.
%\item \textbackslash{}author\{Name of Thesis Author\}
%\item \textbackslash{}thesiscopyright\{Optional Copyright Statement\} 
%\item \textbackslash{}dedication\{Optional Dedication\} 
%\item Either \textbackslash{}committee\{Supervisor Name, Degree\}\{Co-Supervisor
%or Committee B Name, Degree\}\{Committee C Name, Degree\}\{Committee
%D Name, Degree\}\{Committee E Name, Degree\} or the following commands
%separately.
%
%\begin{itemize}
%\item \textbackslash{}supervisor\{Supervisor Name, Degree\} 
%\item \textbackslash{}cosupervisor\{Co-Supervisor Name, Degree\} or \textbackslash{}committeeB\{Committe
%member B Name, Degree\} 
%\item \textbackslash{}committeeC\{Committe member C, Degree\} 
%\item \textbackslash{}committeeD\{Committe member D, Degree\} 
%\item \textbackslash{}committeeE\{Committe member E, Degree\}
%\end{itemize}
%\item Either \textbackslash{}informationitems\{Full Name of Degree\}\{Short
%Name of Degree\}\{Full Name of Department\}\{Full Name of College\}\{Month
%of Thesis\}\{Year of Thesis\} or use the following commands separately.
%
%\begin{itemize}
%\item \textbackslash{}degree\{Full Degree Name\} 
%\item \textbackslash{}degreeshort\{Short Degree Name\} 
%\item \textbackslash{}department\{Department Name\} 
%\item \textbackslash{}college\{College Name\} 
%\item \textbackslash{}thesismonth\{Month\} 
%\item \textbackslash{}thesisyear\{Year\} 
%\end{itemize}
%\item \textbackslash{}maketitle is the command to produce the signature
%page, copyright page, dedication page, and the title page. The position
%of this command is important. 
%\item \textbackslash{}begin\{acknowledgements\}
%
%
%People, organization, supports that you want to thank for 
%
%
%\textbackslash{}end\{acknowledgements\}
%
%\item \textbackslash{}begin\{abstract\}
%
%
%The abstract starts here. Should within one page.
%
%
%\textbackslash{}end\{abstract\} 
%
%\item The thesis/dissertation should then continue with chapters, appendixes,
%references. Before the first chapter, it is necessary to set Arabic
%page number. If the thesis/dissertation is long, it may be better
%to place chapters into separate \LaTeX{} files and include these sub-files
%using \textbackslash{}include\{\} command.
%\item \textbackslash{}begin\{vita\}
%
%
%The last item is a one-page curriculum vita
%
%
%\textbackslash{}end\{vita\}
%
%\end{itemize}
%
%\subsection{Produce the Outcome}
%
%To produce the pdf version of the thesis/dissertation, run pdflatex
%and bibtex.
%
%
%\section{The utsathesis.layout Package}
%
%The utsathesis.layout is an \LyX{} layout that provides a \LyX{} document
%layout for UTSA dissertation/thesis. This layout should be used together
%with the UTSAthesis.sty.
%
%
%\subsection{Installation}
%
%First, install UTSAthesis.sty as described in Section \ref{sec:UTSAthesis.sty}.
%Then, installed the \LyX{} on your system by following the instruction
%that comes with the \LyX{} package. Next, place the utsathesis.layout
%into your personal \LyX{} directory. On a Linux/Unix system, this
%directory is at \textasciitilde{}/.lyx/layouts. On Mac OS, it is at
%/User/<name>/Library/Application Support/\LyX{}-<version>/layouts.
%On Windows 7, it is at C:\textbackslash{}Users\textbackslash{}<name>\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}lyx<version>\textbackslash{}layouts.
%Remember to run Tools->Reconfigure inside \LyX{} to re-configure the
%system.
%
%
%\subsection{Use of utsathesis.layout Package}
%
%This document (sampleThesis.lyx) provides a template for using the
%utsathesis.layout to write a Ph.D. dissertation. For a Master's thesis,
%go to Document->Settings and set the class option to ms. Other important
%settings may include Document->Settings->\LaTeX{} Preamble, and the
%bibliography style.
%
%The document setting should be ``report (UTSAthesis 2012)''. The
%document should begin with committee info, thesis info, copyright,
%and dedication. These can be formatted using items in the FrontMatter
%in the pull-down menu. These should be followed by title, author,
%acknowledgments and the abstract. The placement and the order of these
%four items are important for generating the correctly formatted front
%pages of the thesis/dissertation. It is also important to add the
%``Start First Page'' item right before the first chapter. This item
%will set the correct page numbers for the main portion of the thesis/dissertation.
%
%At the end of the document, the ``Vita'' item in the BackMatter
%in the pull-down menu needs to be used to format a one-page vita.
%
%Regular chapters can be included in the main thesis document or more
%likely as sub-files, one per chapter. If sub-files are preferred,
%make sure the document settings of all sub-files are identical to
%the main document. 
%
%
%\chapter{Literature Review}
%
%We have some citations \cite{dabiri-optimization-isqed-2008,melhem-ieeetc-2003,pradhan-fault-tolerance-1986}.
%See the Bibliography for the format of references.
%
%\include{chapt3}
%
%
%\chapter{Solution and Evaluation}
%
%In this chapter, we show the structures of math formula, theorem commands,
%and floats (such as algorithm and table).
%
%
%\section{A Theory}
%\begin{defn}
%This is another definition.\end{defn}
%\begin{thm}
%This is a theorem.
%\begin{equation}
%X=\frac{AB}{Y}
%\end{equation}
%\end{thm}
%\begin{proof}
%The proof is done here.
%\end{proof}
%
%\section{An Algorithm}
%
%The following is the algorithm.
%
%\begin{algorithm}
%\begin{enumerate}
%\item Step One
%\item Step Two
%\end{enumerate}
%\caption{The Do-It-Yourself Method}
%
%
%\end{algorithm}
%
%
%
%\subsection{Evaluation}
%
%The evaluation results is shown in the following table. It is straightforward
%to place the caption of the table above or below the table.
%
%\begin{table}
%\caption{Evaluation Results}
%
%
%\noindent \centering{}%
%\begin{tabular}{|c|c|c|c|}
%\hline 
% & Method 1 & Method 2 & Method 3\tabularnewline
%\hline 
%\hline 
%Criterion 1 &  &  & \tabularnewline
%\hline 
%Criterion 2 &  &  & \tabularnewline
%\hline 
%Criterion 3 &  &  & \tabularnewline
%\hline 
%\end{tabular}
%\end{table}
%
%
%The following is a long table
%
%\noindent \begin{center}
%\begin{longtable}{|c|c|c|c|c|}
%\caption{A Long Table\label{tab:A-Long-Table}}
%\endfirsthead
%\multicolumn{5}{c}{\textbf{Table \ref{tab:A-Long-Table}}: Continued}\tabularnewline
%\endhead
%\hline 
%Column1 & Column 2 & Column 3 & Column 4 & Column 5\tabularnewline
%\hline 
%\hline 
%1 &  &  &  & \tabularnewline
%\hline 
%2 &  &  &  & \tabularnewline
%\hline 
%3 &  &  &  & \tabularnewline
%\hline 
%4 &  &  &  & \tabularnewline
%\hline 
%5 &  &  &  & \tabularnewline
%\hline 
%6 &  &  &  & \tabularnewline
%\hline 
%7 &  &  &  & \tabularnewline
%\hline 
%8 &  &  &  & \tabularnewline
%\hline 
%9 &  &  &  & \tabularnewline
%\hline 
%10 &  &  &  & \tabularnewline
%\hline 
%11 &  &  &  & \tabularnewline
%\hline 
%12 &  &  &  & \tabularnewline
%\hline 
%13 &  &  &  & \tabularnewline
%\hline 
%14 &  &  &  & \tabularnewline
%\hline 
%15 &  &  &  & \tabularnewline
%\hline 
%16 &  &  &  & \tabularnewline
%\hline 
%17 &  &  &  & \tabularnewline
%\hline 
%18 &  &  &  & \tabularnewline
%\hline 
%19 &  &  &  & \tabularnewline
%\hline 
%20 &  &  &  & \tabularnewline
%\hline 
%21 &  &  &  & \tabularnewline
%\hline 
%22 &  &  &  & \tabularnewline
%\hline 
%23 &  &  &  & \tabularnewline
%\hline 
%24 &  &  &  & \tabularnewline
%\hline 
%25 &  &  &  & \tabularnewline
%\hline 
%26 &  &  &  & \tabularnewline
%\hline 
%27 &  &  &  & \tabularnewline
%\hline 
%28 &  &  &  & \tabularnewline
%\hline 
%29 &  &  &  & \tabularnewline
%\hline 
%30 &  &  &  & \tabularnewline
%\hline 
%31 &  &  &  & \tabularnewline
%\hline 
%32 &  &  &  & \tabularnewline
%\hline 
%33 &  &  &  & \tabularnewline
%\hline 
%\end{longtable}
%\par\end{center}
%
%
%\chapter{Future Directions}
%
%There can be more chapters.
%
%\appendix
%
%\chapter{Notations }
%
%Here we show the use of multiple appendixes.
%
%
%\section{Math Notations}
%
%Each appendix can have sub-sections as a regular chapter.
%
%
%\section{Additional Notations}
%
%
%\chapter{Ontologies}
%
%These is another appendix.

