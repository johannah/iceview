%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{longtable}
\usepackage{float}
\usepackage{calc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

%graphicx is not part of included utsa thesis
\usepackage{graphicx}
%\usepackage{subcaption}
\graphicspath{{./figures/}}
\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{UTSAthesis}      
\usepackage{times}            
\usepackage{latexsym}

\newenvironment{ruledcenter}{%
  \begin{center}
  \rule{\textwidth}{1mm} } {%
  \rule{\textwidth}{1mm} 
  \end{center}}%


  \theoremstyle{definition}
  \newtheorem{defn}{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

  \providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}

\begin{document}
\bibliographystyle{acm}
%\committee{Sos Agaian, Ph.D., Chair}{Prof Hanumant Singh, Ph.D.}{Prof. C, Ph.D.}{Prof. D, Ph.D.}{Prof. E, Ph.D. }
\supervisor{Sos Agaian, Ph.D.}
\cosupervisor{Hanumant Singh}
\committeeC{Prof A}
\committeeD{Prof A}
\committeeE{Prof A}

\informationitems{Master of Science in Electrical Engineering}{M.Sc.}{Department of Electrical Engineering}{College of Engineering}{December}{ 2016 }


\thesiscopyright{Copyright 2016 Johanna Hansen \\
All rights reserved. }


\dedication{\emph{I would like to dedicate this thesis to the many mentors and 
teachers who have guided me throughout this process.}}


\title{\textbf{Monitoring Sea Ice with Unmanned Aerial Vehicles}}


\author{Johanna Hansen}
\maketitle
\begin{acknowledgements}

Thanks!

\end{acknowledgements}

\begin{abstract}

    Unmanned Aerial Vehicles (UAVs) are providing revolutionary  
real-time access to the terrain around us. The low cost and accessability of this technology has empowered military, agricultural, commercial, and recreational applications with new sensing capabilities. 
This thesis will focus on the application of low-altitude aerial photography for sea ice monitoring, useful for polar sea expidentions and research endeavors as scientists 
try to better understand the world's changing climate. 
For ships navigating in ice laden waters, UAVs provide the potential
to replace manned helicopters acting as scouts for 
 ships navigating in ice laden waters. For these ships, 
real-time knowledge about the changing and often dangerous 
conditions is necessary. Though UAVs provide an excellent data collection platform, 
that data can be labor intensive to process and interpret. Images captured from 
a UAV provide a small field-of-view, meaning that hundreds, if not thousands of 
images are collected on a single scouting mission. The common way to organize 
this information is by joining the overlapping images into a single field of
view image known as a mosaic. The process of creating a mosaic automatically requires 
finding overlapping scenes within neighboring images and then registering each image 
based on the overlap onto a common scene which is known as the mosaic. 
Although this is a fairly routine process with modern computers, traditional 
image mosaicing algorithms tend to fail when faced with sea ice 
scenes. Sea ice is difficult to mosaic for two main reasons; ice itself 
typically has very few distinguishing features from which 
to match to overlapping images, and water pixels are dynamic in nature,  
making it impossible to match images with overlapping scenes that are taken 
at different points in time as in the case of images captured from a UAV flying 
over a scene.
Here we present a method for adding robustness to the mosaicing process by utilizing
sensor information from the vehicle and providing a tier of matching solutions that
isolate dynamic scenes. In addition, we provide an estimate of surface coverage 
of ice. 
The surface estimation provides a quantitative tool which is useful for
scientific endeavors and vessel operators. 
This approach is demonstrated using 
real data obtained over several days on an Artic Expedition. 

\end{abstract}
\pageone{}

\chapter{Introduction}
The problem of establishing correspondences between a set of images taken from 
different viewpoints is well studied in computer vision. Applications of this 
type of work include motion recovery, image retreival, and robot navigation 
to name a few. We limit the problem to image mosaicing and tackle the issue of 
correspondence for .....TODO

Sea ice has a large impact on the global climate, maintaining a large heat sink 
in the poles and increasing the Earth's albedo \cite{Sephton94}. It is important to 
study because it can hinder travel and provide significant scientificant information.


Capturing images from a low-altitute provides detailed information of the 
target scene, but the tradeoff for resolution is field-of-view. To obtain understanding 
of a scene spread across many high resolution images with a small field-of-view, 
it necessary to combine the information into a larger image by mosaicing the images 
together into a single image. 
Image mosaicing has been utilized to join images of overlapping aerial
scenes since long before digital photographs \cite{Wolf83}. Originally, film 
photographs were captured from hot air balloons or low-flying aircraft and pasted 
together by hand. Later, satellites and digital photography advanced the field 
of remote sensing and we began to stitch and analyze large volumes of images 
with computers. Now, image stitching is commonplace and the technology is embedded 
in many smart phones equipped with cameras for use for stabilization, small panoramas, 
and multiple image super-resolution. Many dedicated software programs are 
available to provide image stitching including 
AutoPano, Hugin, PhotoScan \cite{AutoPano, Hugin, Photoscan}. In this work, we 
tackle a dataset which remains challenging for conventional mosaicing pipelines, 
high resolution imagery of sea ice. 

\section{Motivation}


Expeditions into the world's frozen oceans requires expert navigation and 
real-time knowledge of the constantly shifting conditions. This region of the earth 
is both interesting from a scientific perspective  
because much of it remains unexplored and because it is rapidly changing.
It also harbours rich natural resources 
that are increasingly accessible and important to government and commercial 
interests. However, navigating and working in remote sea ice still presents 
a significant technological challenge and requires constant monitoring of
sea ice to work 
safely. 

Historically, ships working in these conditions
have relied on human scouts, helicopters, and/or satellite imagery to monitor 
the sea ice movement.  However, these approaches are resource intensive in the 
case of helicopters and suboptimal in the case of satellites. 
Manned aircraft are expensive to operate, requiring 
expert pilots and precious deck space and do not necessarily solve the scientific 
problem of cataloguing the sea state. In addition, the low cost and lack of a human 
operator in a UAVs means that 
they can be operated in riskier conditions than manned aircraft. 
Satellite sensors can provide useful
overviews, but the data captured is low-resolution both in time and coverage. It 
is also prone to occlusion by cloud cover or atmospheric conditions. 

Unmanned Aerial Vehicles (UAVs) equipped with high
resolution digital cameras offer a low-cost alternative to manned aircraft. The 
advantage over sattelite imagery is obvious in that the 
data is much higher resolution and a survey can be conducted at the
operators discretion. 
UAVs require little expertise to operate and little deck space. However, because 
there is no human observer of the terrain, the data collected from the vehicle must 
be processed and analyzed in a way that is useful for non-technical decision makers. 
Although UAVs can provide images with high resolution, each image only covers a 
small part of the interesting area.
 This means that a single flight can result in thousands 
of images that must be organized into a human-readable format. 
A process called image mosaicing must be performed to merge overlapping images 
of the terrain into a single high resolution image that is easy to comprehend and 
integrate into existing workflows. 
Image registration is the process of developing a pixel-to-pixel mapping between 
the views in the distinct images. 
By registering the many images into a single image, 
we create a composite scene called a mosaic with a large field of 
view, while maintaining high resolution.  

Several commercially available programs 
have been applied to sea ice dataset with disappointing results. 
However, our experminents indicate that these packages were not 
reliable for developing mosaics with sea ice 
data. The large volume of images with poor features that results from a typical  UAV sea 
ice survey seemed to incapacitate the algorithms available in commercial software.
When the surveys were divided 
into geographic batches, 
stitching and warping errors typically resulted from the accuracy of feature 
matching or the projection of object height. 


The features 
from the sea ice data are often poor or dynamic, causing the non-specialized programs 
to misregister images or fail completely. 

Our approach addresses the reasons these
approaches fail and adds additional advantage in the form of sea ice coverage information. 

In addition, the size of an iceberg is necessary for calculating the 
iceberg's trajectory and stability. However, obtaining data on the geometry is not 
simple, and typically underwater and overhead measurements must be taken to determine 
the size. 

\section{Problem Statement}
The high-resolution low field-of-view tradeoff accepted by the  UAV means that many 
high resolution images are captured in an attempt to understand a scene. Our aim  
in this thesis is to make sense of the data by aligning the many images  
 into a an overview mosaic of the scene while providing useful information about 
 the survey area. The process of creating a mosaic 
requires recognizing overlapping regions between images (if they exist) and 
then determining the transformation between each image onto the base overview scene. 
We require that the scene be orthorectified so that the relative distances between 
features are preserved and georeferenced, so that the overview image can be 
incorporated into Geographic Information Systems (GIS) for further intrepretation, 
analysis, and combining with other data sources. We also wish to provide an 
analysis of the images in the form of ice coverage. This is important both for 
scienctific enquiries and for ship operations. Considering the aforementioned goals 
and challenges, we address and solve the three following problems: 
\begin{itemize}
    \item{Segmenting sea ice from water and other objects to reduce false matches 
        while providing ice coverage information at the same time. }
    \item{How to exploit metadata from the UAV to speed up image matching and 
            registration by reducing the search space of overlapping images and by 
            pre-aligning images so that low-cost feature descriptors can be used for 
            matching.}
    \item{Aligning images when metadata is not available by escalating feature 
            extraction complexity in regions with poor features.
    This iterative scheme adds additional complex only as needed, using fast descriptors when possible and slower, more robust methods only when needed. 
    }
\end{itemize}




\section{Contribution}
This process has been tested on data collected off of an ice breaker working in 
the Artic in various ice conditions. 

The problem of image mosaicing can be broken several steps. The first step 
is to identify images that have 
overlapping regions. Then these regions must be correctly aligned and 
merged onto the larger mosaic. Identifying overlapping regions is a difficult 
problem, especially in a large search space. Sea ice images also present a 
fairly unique problem in that the images contain largely repeating, homogenous 
pixels that do not perform well with traditional techniques.
We add an additional preliminary step to the typical stitching pipeline to detect 
known nonstationary features and remove them from the pixels that are considered for 
feature detection. We use these features to gain understanding about ice floes and 
provide an estimate of sea ice coverage based on this measurement. 
Our mosaic is built incementally by updating the scene 
as new images are captured. This approach means that the overview mosaic is
produced more quickly than with methods that wait for all images to refine homographies. 
We also utilize metatdata to speed up the 
matching process and reduce search space for matching images.


\section{Outline}
The remainder of this thesis is organized as follows. Chapter \ref{chap:background} 
provides a history of image mosaicing and stitching approaches. 
Chapter \ref{chap:related} discusses related work in sea ice and image mosaicing 
tasks of aerial and underwater imagery. In Chapter \ref{chap:features} we discuss 
the process of assessing feature descriptor performance on this dataset and present 
performance results of common approaches. Segmenting sea ice from the surrounding 
water and size estimation considered in Chapter \ref{chap:segmentation}. Image matching, 
registration, and blending is presented in Chapter \ref{chap:registration}. In Chapter 
\ref{chap:results} sample results are provided with a discussion and evaluation 
of the approach. Finally, in Chapter \ref{chap:conclusion}, a summary and goals 
for future work is presented. 

We assume that the readers have basic knowledge of digital photography and 
aerial vehicles, however basic concepts are summarized here before 
delving into more complicated computational concepts. 

\chapter{Background}
\label{chap:background}
Sea ice monitoring is an important issue for vessels operating in polar environments. 
Many governments and organizations dedicate significant resources to providing 
timely assessments and maps of sea ice coverage to ensure safety 
of their citizens and gain greater understanding of the earth's processes. 

According to Sephton et al. in \cite{Sephton94} the following qualities of sea ice are of 
significance:
\begin{itemize}
    \item{The position  of the ice edge}
    \item{Concentration of ice as defined by the fraction of the surface area covered 
            by ice }
    \item{The type of ice. Ice can be categorized into first freeze, 
        multi-year, and icebergs TODO is this extensive enough?}
    \item{The size and distribution of ice flows}
    \item{Thickness of ice cover}
    \item{Local and global movement of ice floes}
\end{itemize}

The position of the ice edge and the concentration are the most feasible 
to calculate given the limited labeled data and the small range of temporal 
coverage of our particular dataset. 

To quantify ice floes it is advantageous to first segment the ice from the 
surounding water and neighboring floes. This has been well studied for SAR 
imagery.


\section{Remote Sensing}
Remote sensing is the term used to describe the process of obtaining data without 
physical contact. The field of remote sensing, like most modern fields that 
are associated with data, has experienced an explosion in the amount, quality, and 
accessibility of data. 


Aerial mosaicing includes images captured from platforms such as satellites, 
manned aircraft, and unmanned aircraft. The first two platforms generally 
observe the earth from a higher altitude than what we are concerned with here and 
thus have looser requirements for stitching accuracy. For example, a popular instrument 
for observing the earth from satellite is MODIS (Moderate Resolution Imaging 
Spectroradiometer). MODIS is housed on the Terra and Aqua satellites which view the 
entire earth surface every 1 to 2 days at 36 distinct wavelengths with a spatial 
resoution of 500 m in the visible spectrum \cite{MODIS}. 

Traditional remote sensing platforms like airplanes and 
satelites are being augmented with low-cost UAVs making data production and analysis 
accessible to hobbyist and professionals alike. In addition to sensors working through 
the air, underwater platforms like Remotely Operated Vehicles (ROVs) and Autonomous 
Underwater Vehicles (AUVs) are also providing remote sensing through water 
with sound and images. 
With the balloon in accessibility of data have come 
automated methods for interpreting the data including, but not limited to  mosaicing. 
Pixel-wise segmentation of imagery and object classification are 
two additional tasks that 
simplify the data into categories and allow for more complex 
analysis and understanding.


\section{Unmanned Aerial Vehicles}
Aerial platforms are a staple of the modern economy and provide important platforms 
for transport, data retreival, and security. Flight has long been dominated by 
governments, commercial organizations, and weathly individuals, but recent 
advances in unmanned aerial vehicles have brought the capabilities of flight to 
the average consumer and researcher. In this discussion, we focus primarily on 
the use of UAVs for low-altitude remote sensing and mapping, however, the 
technology promises to open countless new sectors to entrepreneurs, hobbyists, 
and humanitarians. For a more complete overview of UAV capabilities and history, 
please refer to a review by Colomina \cite{Colomina14}.

UAVs have a wide variety of capabilities in terms of payload, endurance, weight, 
and speed. One important consideration for shipboard 
operations is the space needed for launch and recovery. Fixed wing vehicles are 
typically more stable and have longer range than rotary wing vehicles, but have 
a more complicated deployment, especially on a small ship. UAVs also vary greatly 
in their computational capabilities and complexity. Many are capable of autonomous 
flight, while others rely solely on remote control by humans. 

\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=.9\linewidth,height=0.6\linewidth]{uav_snow_d.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{The Phantom FPV Flying Wing EPO UAV used to gather data over sea ice. This vehicle was equipped with a TODO camera for capturing images. }
         \label{fig:no_features}
     \end{minipage}%
     \begin{minipage}{.5\textwidth}
         \centering
        \includegraphics[width=.9\linewidth,height=0.6\linewidth]{launch_uav_d.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{UAVs have small space requirments for both storage and flight, making them ideal scouts for working off of a ship.}
             \label{fig:good_features}
      \end{minipage}
\end{figure}


Nearly all systems will have some sensing capabilities necessary for navigation, 
though the accuracy and capabilities of these devices can vary widely and 
have enormous impact on the quality of flight and data products captured.

\subsection{Global Positioning System (GPS) Receivers}
The Global Positioning System, frequently shortened to GPS, is a system which 
provides location and time when a compatible receiver is within view 
of at least four of the system's satellites. A GPS receiver monitors the 
the time of flight for the messages coming from each satellite within its site 
and performs a calculation of its position based on the known positions 
of each of the satellites. This position is presented as latitude, longitude, 
and elevation from mean sea level. 

\subsection{Inertial Measurement Unit (IMU)}
An inertial measurement unit (IMU) is a sensor utilizes accelerometers, 
gyroscopes, and magnetometers to estimate movement and position. 

\subsection{Digital Cameras}
Digital cameras are ubiquitous and convienent sensors for
capturing and recording a specific 
range of electromagnetic radiation. The images that we are working with in this 
thesis are from the visible spectrum and represent images as they are seen 
with the human eye. 
TODO: talk about focal length - lens properties, resolution

The accuracy of stereo degrades as the distance to the scene increases and is 
lower with a larger baseline distance. A large baseline is not feasible on many
platforms, especially airborne systems. Rather than using two fixed cameras 
capturing the scene simultaneously, we can use a wide-baseline stereo system.
Wide-baseline stereo systems capture the scene from different positions 
using the same camera. 
Larger baseline can allow for a more accurate depth estimation of distant 
terrain, given that the location estimates of the camera position are accurate. This 
position estimation is inaccurate when compared to the strictly known 
viewpoint disparity in traditional stereo vision systems. Determining the overlapping scene with wide-baseline can be more difficult than traditional 
systems, because there is often a larger difference in perspective.  \cite{Olson10}

\chapter{Sea Ice Detection}
\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{pancakes.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A close photo of pancakes, small pieces of ice with raised edges from bumping one another. }
         \label{fig:pancake}
     \end{minipage}%
     \begin{minipage}{.5\textwidth}
         \centering
        \includegraphics[width=.9\linewidth]{cakes.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{An example of a large ice cakes. For reference, the pictured ship, the R/V Sikuliaq, is 79.6 m in length.}
             \label{fig:cake}
      \end{minipage}
\end{figure}



The Manual of Ice (MANICE) provided by the Canadian Ice Service, describes various 
types of ice discussed throughout this paper \cite{CanadianIceService}. Below we provide 
a brief introduction to several forms of ice included in our experiments. 
\begin{itemize}
    \item{\textbf{Pancake ice} is defined as predominetly 
circular pieces of ice the is 30 cm to 3 m in diameter. The edges are typically 
raised from the pieces striking against one another. See Figure \ref{fig:pancake} for reference. }
\item{An \textbf{ice cake} is a flat piece that is less than 20 m across. See Figure \ref{fig:cake} for reference. }
\item{An \textbf{ice floe} is a flat piece of ice that is 20 m or more across. Small floes are 
    less than 100 m and giant floes are those pieces that are greater than 10 km across. }
\item{\textbf{Slush} is snow which is saturated with water} 
\end{itemize}


Ice concentration is expressed as a ratio of the area of the water surface 
covered by ice over the entire area.
Much of the published work concerning the segmentation of sea 
ice from water is performed on data collected 
from synthetic apertaure radar images collected from satellites. 
While this work is interesting 
and encouraging, the dataset from the low-resolution SAR imagery and our high 
resolution images are different enough that there exists little overlap in the 
applications. Nevertheless, the approaches used for SAR segmentation will be 
covered briefly in the following section. 


\section{High Altitude Sea Ice Segmentation}


\begin{figure}
\label{fig:eggcode}
\centering
\includegraphics[width=.9\linewidth, height=0.6\linewidth]{egg_code.jpg}
  \captionsetup{width=.9\linewidth}
  \captionof{figure}{
  Ice estimates over the Hudson Bay region of Canada produced by the Canadian Ice Service \cite{CanadianIceService}. These reports are produced daily in season, subject to atmospheric and sea conditions. }
\end{figure}




Today, the most common technique for monitoring sea ice is through data obtained 
by satellites.  In addition to cameras operating in the visual spectrum,
sea ice is also frequently monitored by active sensors which can 
build models of the physical geometry of the ice. 
Radar can effectively evalutate 
sea ice thickness and allow estimates of ice density. 
Synthetic Aperture Radars (SARs) 
are a form of high-resolution active microwave 
that is commonly used to determine the 
age of ice and differentiate between ice and water.
SAR is advantageous because it can operate without natural light and despite 
harsh weath conditions such as clouds or rain. Considering the 
poles experience long periods of darkness, this allows for monitoring of ice 
even during these times. 

One of the most public datasets for sea ice is produced by the Canadian Ice Service. 
Their team of experts provide regular ice assesments over the Artic.
The agency also produces daily ice charts, which are an estimate of the current ice 
conditions based on satelite data that is augmented with aerial and ship data. 
Regions with visually homogenous ice according to human experts are assigned with 
"egg code" symbols (see Figure \ref{fig:eggcode} ) to summarize the region's ice characteristics with details 
such as ice floe, ice concentration, and ice types \cite{Clausi08, CanadianIceService}. 
The process of developing the ice charts by hand is a demanding task. Many attempts have 
been made to automate this process, though none have been successfully used in full 
production \cite{Clausi03, Clausi08}. These manually labeled ice maps have provided a 
rich dataset for those interested in detecting the characteristics of ice coverage, 
but it has limitations when relating to our problem of high-resolution ice imagery. 
The SAR dataset is captured at a much lower resolution, with 1 pixel represeting 
50 meters on the earth's surface and the data is often plagued with speckle noise 
 \cite{CanadianIceService, Li15, Xu14, Clausi08}. In addition, the egg codes provided by the 
 Canadian Ice Service do not provide pixelwise ground truth, but instead estimates 
 of the percentages of each type of ice or water within a particular egg code. 
 In the following paragraph, we will summarize recent approaches to determine 
 the ice/water boundary in SAR imagery. 

Most current SAR sea ice segmentation approaches are pixel-based or 
texture-based.  Because sea ice images tend to be bimodal in nature, a simple grey threshold 
has been shown to be a reliable way to seperate between ice and water \cite{Haverkamp93}. 
This simple approach, as one may suspect, is sensitive to speckle noise. Other pixel-based methods include mixture models \cite{Samadani95} and k-means
clustering \cite{Remund98}. Texture-based algorithms  approaches use texture features which are functions of neighboring pixels. Many use 
the grey-level co-occurence matrix (GLCM) introduced by Haralick et al. \cite{Haralick73} and used extensively by others including Soh in \cite{Soh98} and Clausi \cite{Clausi01, Clausi03}. Markov Random Fields, described in \cite{Li95MRF} was used by Deng and Clausi in \cite{Deng04, Deng05}, Yang and Clausi in \cite{Yang09} and by Clausi in \cite{Clausi01}. MRFs base the pixel segmentation class of each pixel on its neighboring pixel values and on the conditional segment probabilities. 

In \cite{Clausi03}, Clausi considers practical segmentation of SAR sea ice for the Canadian Ice Agency and demonstrates segmentation using a finite gamma mixture model, K-means clustering, binary hierarchical K-means iterative Fisher, and Markov random field modeling and shows good results with the gamma mixture model followed by a MRF label model to discriminate between ice and water. 
Xu et al. \cite{Xu14} use kernal principle component analysis (KPCA) 
local texture feature model to segment sea ice from SAR data efficiently despite speckle noise for operational segmentation. 
In conjunction with the Canadian Ice Service, Clausi presented in \cite{Clausi08} MAp-Guided Ice 
Classification system or (MAGIC) to interpret SAR sea ice images with ice charts. 
This software estimates pixel level classification allowing the user to specify polygons 
on the earth's surface. MAGIC uses the watershed \cite{watershed} algorithm to segment the SAR image into several regions and performs supervised classification using a MRF. 
In 2014, Leigh et al. \cite{Leigh14} extended MAGIC's classifiation with a pixel-based support vector machine that uses gray-level cooccurence texture and backscatter. 

Several new approaches utilize Convolutional Neural Networks, or CNNs. CNNs 
have recently dominated many computer vision applications, outperforming methods 
which rely on hand-crafted features \cite{Imagenet}. Basu et al. \cite{Basu15} has shown that 
CNNs perform well on remotely sensed images. 
In an innovative paper, Li et al. in \cite{Li15} utilized the egg codes from 
the Canadian Ice Service to label ice pixels using a "Learning from 
Label Proportions (LFLP)" approach. He used CNNs and probabilistic graphical 
models to learn a model for patch-level ice-water classification using the label 
proportions.  Wang et. al \cite{Wang16} demonstrated pixel-wise segmentation 
to with absolute mean error of less than 10\%  when compared to human experts using 
deep CNNs in a small case study. 

%Manual of ICE
%https://www.ec.gc.ca/glaces-ice/default.asp?lang=En&n=2CE448E2-1





\subsection{Low-Altitude Sea Ice Observations}

Skjetne et al. proposed utilizing UAVs for drift prediction to aid ships 
attempting to maintain Dynamic Positioning (DP) in ice-laden waters \cite{Skjetne14}.
Dynamic Positioning refers to the computer control system that maintains a 
vessel's position and heading. DP systems typically actuate a vessels propellers 
and thrusters based on input from position reference sensors such as GPS, 
gyrocompasses, wind sensors, and current measurement devices. 
These systems are a vital part of modern ships and are incredibly 
important for drilling operations in which a vessel must maintain an absolute position 
above a drill site. For a ship attempting to maintain position amongst ice, it is 
important to know where the ice is moving in advance so as to correctly position 
the ship. At present, sea ice is usually measured at close range using a marine radar 
or manually with helicopter surveillence. UAVs are safer and less 
resouce intensive than helicopters and can easily provide larger coverage than 
marine solutions. Skjetne divided ice monitoring into two problems; the first is 
the one that we will tackle, dynamic sea ice monitoring to track the movement 
of large bodies of ice sheets. The second problem is that of tracking large icebergs 
which involves recognizing icebergs on temporally spaced observations and tracking 
their movement.  
Skjetne worked on path planning with simulated icebergs. He also proposed a method 
of monitoring sea ice concentration by thresholding grayscale imagery of sea ice. 
He also estimated floe size, by finding closed boundaries around individual 
ice flows using the Gradient Vector Flow Snake algorithm to detect closed curves. 


Lagunov et al. \cite{Lagunov14} describes the value of sea ice monitoring and provided an 
overview of useful sensor platforms including the UAV and provides a thorough description 
of the many considerations of sensors and operational constraints involved in 
deploying a UAV for ice observation. 
This paper also demonstrates the usefullness of the platform with a microwave sensor 
and camera over an ice covered river, but did not cover problems related to organizing 
the imagery or automatically evaluating ice coverage.

Billington proposed the use of UAVs for shape estimation of icebergs at sea
with UAVs equiped with imaging systems and provided a description of requirements 
for operations \cite{Billington15}. He proposed a neural network to perform 
shape estimation of the submerged portion of the iceberg based on the observed 
surface and demostrated his effort on a small sample size that made it difficult to 
evaluate. 


Zhang et al. has published a number of papers on sea ice segmentation and floe 
detection. In \cite{ Zhang13}, Zhang operates on high resolution images by first 
determining seperate ice floes using the Otsu \cite{OTSU} threshold algorithm to 
binarize the image. Then a watershed segmentation is used to segment indiviual ice floes. 
Both \cite{Blunt12, Zhang13} use watershed algorithms to segment ice images,
but found that oversegmentation reduced the accuracy.
Over-segmentation is caused by the structure of the watershed algorithm. The
watershed algorithm depends on the local minima  for the starting point. When
there are multiple local minima in the 
image, like is often the case in sea ice imagery, over-segmentation occurs. 
Zhang, in \cite{Zhang13} corrects this for the watershed algorithm
by using a combination of concave detection and neighboring region merging
to isolate floes. Blunt, in 
 \cite{Blunt12} simply removes over-segmented 
lines manually. 

In \cite{Zhang14} discussed Otsu thresholding and k-means clustering
\cite{MacQueen67} and demonstrated how k-means could be used to better segment images with several types of ice and water. Zhang then demonstrates segmentation of floes using a Gradient Vector Flow Snake Algorithm with a circular shape that deforms to 
the floe boundary on the binary image. 
Zhang then uses morphological cleaning to ensure completeness of the ice floe so 
that smaller foes contained in larger floes are removed. 
In \cite{Zhang15floe}, Zhang improves segmentation of ice floe boundaries, which can be difficult to identify when floes are touching again using the Gradient Vector Flow Snake Algorithm, but this time separating the image into 
different layers based on ice type and sizes. 

Flaten discussed mosaicing sea ice images for the purpose of UAV navigation in \cite{Flaten-thesis15}, 
but, was unable to demonstrate results using field data. 
This project also attempted to provide ice density 
estimation by segmenting the image to produce an occupancy grid 
map estimation of sea ice density. 
Flaten demonstrated Otsu thresholding segmentation on several photos collected from a UAV
and from simulated imagery.



\chapter{Image Mosaicing}

An image mosaic is a synthetic wide-angle camera view which is built from a set of smaller images with 
an overlapping field of view. 
Image mosaicing has been extensively used to gain a greater viewpoint of the world. 
Historically, images were captured on air balloons and airplanes and then printed 
and aligned by hand. In modern times, digital cameras and smartphones are capable of 
automatically stitching panoramas on a small platform. 
There exists a large and robust body of work for creating mosaics from digital photographs
\cite{Milgram75,  Szeliski97, Shum00, Brown03 },
video \cite{Szeliski96, Steedly05} and for full 3D 
reconstruction \cite{Morimoto97, Shum-3D98}. These methods are more fully 
reviewed by Szeliski \cite{Microsoft}, 
Prathap \cite{Prathap16} and Zitova \cite{Zitova03}.
Since the influential paper by Schmid and Mohr \cite{Schmid97} on wide-baseline stereo, many new algorithms have been introduced.


TODO: panoramic vs mosaic
Mosaics with extended field of view benefit 
from the relatively large and equal distance to the scene in each image. 
- taken in such scenarios are challenging as compared to panoramic construction
or other mosaicing methods such as satellite image mosaicing. 

Constructing an image mosaic typically consists of several general steps:

\begin{enumerate}
    \item{\textbf{Determine images with overlapping views of a scene.} }
    \item{\textbf{Estimate the homography between images with overlapping scenes.} }
    \item{\textbf{Register images onto a common frame.}}
    \item{\textbf{Blend image seams to improve appearance.}}
\end{enumerate}

In the next few sections, each step in the mosaic building process will be 
discussed with more detail and we will give an explanation of our approach to the 

\section{Determining Image Overlap}
A reasonable amount of scene overlap (about 15-30\% overlap) with high quality features 
is typically required to determine that two images should be stitched together. 
Even if two images contain the scene, they  
may have a different view of the same region. This difference in view can make
make determining the correspondence difficult. Common changes in scene include 
differences in illumination, a rotated view, scaling, or moving objects. 
In the next section we discuss 
methods used to quantify how similar two images are, given different viewpoints. 

\subsection{Quantifying Images}
Relating the images 
requires overcoming noise and finding unrelated, unknown translations, scaling, 
and rotations between images. 
Methods of determining image similarity generally falls into two camps:
direct and feature based approaches. Direct methods perform correlations or 
convolution operations over the prospective
images to measure their similarity. This involes 
a computation across all of the pixels in the image and tends to be
slow and memory intensive 
\cite{Lucas81, Barnea72, Szeliski95, Shum-local98, Irani00}. 
However, direct methods are able to solve for motion of the 
camera and the correspondence of every pixel at the same time. Because this approach 
compares pixel values directly, it is prone to falter under illumination changes. 
The more modern approach is feature based..
Feature
based methods only measure the similarity of images based on 
interesting regions of the image, such as lines, blobs, or edges. 
The interesting regions are called \emph{features} 
or \emph{keypoints}. Keypoints within the image must be found algorithmically 
by a keypoint detection algorithm. Then the keypoint is described by a 
\emph{descriptor} using a descriptor algorithm.  Descriptors have been developed so 
that they are invariant to many of the transformations that plague images. 
By comparing images using only their interesting features, the motion of the 
camera can be solved for using only the
parts of the image in which correspondence is easy to detect. This reduces 
computational waste and improves accuracy.
The geometry calculated using the descriptors 
is then used to transform all of the pixels in 
the image. 

The feature based technique was perhaps first described by Schmid, who utilized Gaussian derivitives 
to describe a keypoint in a manner that was rotationally invariant \cite{Schmid97}.
Feature based methods are typically the modern approach because they are 
generally less computationally intensive than direct methods and because the 
feature descriptors can be developed to be invariant to image
tranformations \cite{Forstner86, Lowe99, Brown03, Hu06, Elibol08}. 
Our approach utilizes features and is discussed more thouroughly in 
Chapter \ref{chap:features}. From here onward
we will assume that overlap detection 
is performed using the feature based approach. 

Reliable  extraction of a manageable number of potentially 
corresponding features is a crucial prerequisite to successful mosaicing. The 
feature dectector and descriptor choice is of significant importance. 
\subsection{Matching Features}
After keypoints are extracted from two images, they must be compared for 
similarity to determine if the images contain regions of the same scene. 

Discrete Linear Transform is a least squares method that reduces the 
effects of noise in the image measurements. A least-squares approach 
may be corrupted by outliers, which are especially common among images with 
repetitive features. 

TODO: talk about Flann matcher - others, 
Approximate nearest neighbors
Maximum Likelihood
Least Median of Squares (LMS),

The correctness of the final mosaic is highly dependent on the 
acuracy of each of the calculated 
geometric relationship between overlapping images. 
Robust estimation methods are an essential part of determining the relationship 
between images. Many initial matches are incorrect. These incorrect matches 
can be thrown out by a filtering. 
Lowe showed that if the two best matches were close in distance, then the 
probability of a false match was high \cite{Lowe04}. To combat this, he 
proposed a simple \emph{Ratio Test}
to measure the distance of the best match over the distance 
of the second best match and eliminated the match if it was greater than a theshold. 
%Second param is boolean variable, crossCheck which is false by default. If it is true, Matcher returns only those matches with value (i,j) such that i-th descriptor in set A has j-th descriptor in set B as the best match and vice-versa. That is, the two features in both sets should match each other. It provides consistant result, and is a good alternative to ratio test proposed by D.Lowe in SIFT paper.



Another, more robust approach to filtering matches is RANSAC or "RANdom SAmple Consensus. RANSAC is a well known and widely in image registration \cite{RANSAC}



%  iterative parameter 
% estimation technique. It works by repeatedly taking random samples from a set 
% of data, fitting it to a model and then measuring the error. 
%
%Fit a model to data with the RANSAC (random sample consensus) algorithm.
%
%RANSAC is an iterative algorithm for the robust estimation of parameters from a subset of inliers from the complete data set. Each iteration performs the following tasks:
%
%    Select min_samples random samples from the original data and check whether the set of data is valid (see is_data_valid).
%    Estimate a model to the random subset (model_cls.estimate(*data[random_subset]) and check whether the estimated model is valid (see is_model_valid).
%    Classify all data as inliers or outliers by calculating the residuals to the estimated model (model_cls.residuals(*data)) - all data samples with residuals smaller than the residual_threshold are considered as inliers.
%    Save estimated model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has less sum of residuals.
%
%These steps are performed either a maximum number of times or until one of the special stop criteria are met. The final model is estimated using all inlier samples of the previously determined best model.
%




RANSAC can be described by the following actions: 
\begin{enumerate}
    \item{Select a random set of minimum correspondences and compute the homography.}
    \item{Calculate a distance error for each of the sampled matches and classify 
        those within a threshold of ever as \emph{inliers}}
   \item{Select the homography, with the most inliers as the matrix that describes the image transformation.}
   \item{Restimate the homography based on all of the matches classified as inliers}
\end{enumerate}





\subsection{Image Overlap Search Space}
Knowing the location of the viewpoint from 
which the images were captured can reduce the search space for overlap. This 
may include using a GPS location or timestamp of the photo with some knowledge 
of the motion of the camera. Low cost sensors, particularly those used on 
lightweight UAVs, generally do not provide accurate enough estimates of position 
to give per-pixel allignment for high-resolution images at close range (<100m). 

Several practitioners of image mosaicing have demonstrated 
ways in which to use sensor information to reduce the search space for overlapping 
images in applications. 




\section{Defining the Transformation}
After the corresponding pixels 
between overlapping images have been identified, we need to estimate
the relationship between the images. This 
process is called image registration and attempts to find an alignment  
between the images that minimizes the difference between overlapping pixels.
A Homography is a transformation that is defined by a matrix which 
maps the points in one image to
the corresponding points in the other image.
The transformations 
can be translation, similarity, affine, or projective with 2, 4, 6, and 8 parameters 
respectively. 
We will discuss each 
of these transformations in the following paragraphs as they are defined in 
\cite{SzeliskiBook}..
TODO explain transformations 

The image registration process can 
be described as $x'=H*x$ where $x$ is the image coordinate system and 
$x'$ is the mosaic coordinate system, and $H$ is the homography 
matrix that defines the tranformstion. 

A projective transform only preserves straight lines and is the farthest an 
image can be transformed. 
The projective transformation is used in many mosaicing approaches, but can 
result in errors in instances with low overlap between 
images or when there are few distinctive features available \cite{Wang11}.

An affine tranformation describes scale, rotation, translation, and skew 
between two 2D planes in 2D space. This model is unable to 
explain 3D motions between two image planes, but provides superior 
stability when compared to projective transformation. 
In near-flat  areas,  the 
errors of object height projections  may be  negligible. Thus, the 
affine  transformation  can  be  directly  implemented.  
For our sea ice imagery, we take advantage of the 
large distance to the scene and the generally planar terrain surface and
 adopt a model which assumes equal distance to each object in the image. This 
 allows the use of the more stable  
utilize affine transformation to translate the image coordinates.

% it is viewed from sufficient distance that relative depth variation is low and parallax is small. This allows a much simpler model to be used: two images of a planar surface captured through a pinhole camera are related by a perspective transformation: if two images each show the same plane, then there is a homography (3×3 matrix)H such that for all x in the first image and x′ in the second image (represented in homogeneous coordinates), Hx=x′.
%
%For many mosaicing applications a simpler model is appropriate: for a rotating camera at a fixed location (all points are on the plane at infinity), a simple 2D translation and 1D rotation is sufficient to align two images. For a strictly down-pointing camera on an aerial platform a similarity transform (rotation, translation and scale) is sufficient. For a camera with a small field-of-view the perspective transformation may be approximated with an affine transformation: Ax+t=x′ for a 2×2 transformation matrix A and 2D translation t.

% This can be computed without any knowledge of 
%the internal camera calibration parameters such as focal length, 
%optical center, or relative camera motion between frames. 


%An image 
%transformation can be described by ... type of transformation matrix.
%\ref{eq:General tranformation equation} where 
%\emph{$s_i$} indicates scaling, 
%\emph{$r_i$} rotation, and \emph{$t_i$} dictactes translation in the i-th direction. 
%Thus, the problem can be reduced to recovering each component independently.
%
%
% $$
% \label{eq:General transformation equation}
% M =
% \begin{bmatrix}
% s_xr_{11}&s_xr_{12}&t_x \\ s_yr_{21}&s_yr_{22}&t_y \\ 0&0&1\\
% \end{bmatrix}
% $$


%TODO: read \cite{Shum-local98}
%%%%%%%%%%%%%%%%%%%%%%%
%TODO: read \cite{Shum-3D98} about 3d stuff 
%This reduces the undesirable projection errors that are easily propagated 
%with prjoective transformations \cite{Wang11}.


\section{Projection Models}


The calculated homography 
is used to warp the image onto the reference plane. 
A projection model is necessary to project a 3D scene onto a two-dimensional 
surface. The choice of a projection model is important and highly dependent on 
the selected data. 
For this work we assume a planar model to preserve simplicity and because the 
dataset consists of flat ice over a planar surface.
Here there exists a much  larger distance between 
the camera and the ground than  the vertical component of any of the  features. 

A spherical projection is often used in the case of a panoramoic in which 
the camera was rotated about its centerline. 

TODO: expand

\section{Global Optimization}

A globally consistent mosaic should use all overlap information to produce 
the best possible representation of the scene. This mosaic will include links
from images that are not consecutive in time

Typical approaches 
will either work by adding incremental links to the mosaics as in a real-time 
approach, or by solving for all of the images at once to distribute mis-registration 
errors after all images have been collected. 

Strictly local methods, which match neighboring images until until there is 
only the final mosaic left, tend to accumulate errors 
resulting in distortion \cite{Lin07}. Lin \cite{Lin07} proposed to register 
each frame in an image sequence to its previous image that has been 
referanced to a large frame map of the region. This resolves scale and rotation 
differences between the images before solving for pixel wise matching which 
prevents errors between frames from accumulating. 
Although an interesting approach, 
satellite imagery generally updates too slowly 
to be useful for the dynamic state of sea ice. 

TODO: talk about kalman filtering methods, etc

The process of simultaneously 
aligning all of the images is known as bundle adjustment and can be slow 
to converge, but generally produces a more correct image \cite{Pizarro-thesis03}. 


\section{Blending}

Neighboring images in a mosaic can vary greatly in lighting, especially when 
subsequent images are seperated by time. 
To compensate for changes in illumination between neighboring images, 
it is often necessary to blend the images together in a 
manner such that the resulting mosaic is visually pleasing.  There are many 
methods of performing blending. 

TODO: talk about different approaches to blending

Our approach utilizes the open 
source tool, Enblend, that uses a multi-resolution spline to blend images 
together using multi-resolution splines and Laplacian pyramids \cite{enblend, 
Burt83thelaplacian}. 
The spline operates across a transition zone that is proportional 
to the spatial frequency of the region. Homogenous regions like an ice sheet 
have low spatial frequency and are combined across a wide region.
Strong color changes, 
show high spatial frequency and are fused over a small area. 

\section{Related Techniques}
\subsection{Structure From Motion}
\subsection{Simultaneous Localization and Mapping (SLAM)}
\chapter{Related Work}
\label{chap:related}
Although the area of image mosaicing has been widely studied for many years, 
some problems remain elusive. 
High altitude imagery and on-ground mosaicing such
as panoramic image construction are not in our area of in-
terest since they are dealing with different challenges.
These include but are not limited to: 

\begin{itemize}
    \item{Recovering from poor overlap}
    \item{Determining overlapping scenes with poor features}
    \item{Images taken with drastic differences (day and night or change in seasons)} 
    \item{Resolution and quality of output mosaic}
    \item{Dynamic Scenes}
    \item{Classification of terrain}
\end{itemize}

Prathap gives a thorough review of the current state of mosaicing \cite{Prathap16}. 

Many researchers and engineers have utilized UAVs to gather images to form large-scale 
photo mosaics \cite{ Caballero07, Yahyanejad10, Cheng10, Pritt14, Kekec14, Prasad16, Vousdoukas11, Wang11, Wang14}.
Images collected with a UAV can often be quickly, but roughly  aligned 
using data from sensors such as Global Positioning System (GPS) points and 
Intertial Measurement Unit (IMU) estimates.
However, these measurements are typically not 
accurate or reliable enough to generate a visually appealling image. 
Instead, most approaches for mosaicing UAV images use some form of a feature 
based approach to match images. Problems tend to occur when there exists 
low-overlap between images, moving objects in the survey area, or featureless 
images. 

Caballero uses the match success between images to limit the homography model selection. 
Using a simpler model if fewer matches are available \cite{Caballero07}.  
 Lin utilizes a low-resolution global map to align images \cite{Lin07}

 Qian demonstrates the use of vehicle rotation rate
 information from gyros mounted to the vehicle to assist in the process 
 of matching camera features from frame to frame \cite{Qian01}. 

Registration \cite{Barnea72, Shum-local98, Sawhney99}


Cheng \cite{Cheng10} divides image sequences from UAV flight into small groups of 
overlapping images and then performs local optimization based on the Extended Kalman 
Filter (EKF). This corrects homographies in a local area before performing a 
global optimization step. Civera \cite{Civera09} also 
uses an Extended Kalman Filter to improve consistent mosaics, but from 
a SLAM (Simultaneous Localization and Mapping) perspective. SLAM, a probablistic
filtering approach which has recently become common in the field of 
mobile robotics, allows a moving sensor to build a map of the world while 
moving through it. Similarly, Civera uses the EKF to predict the location 
in the next frame of a rotating camera. 
This allows for 
real-time, drift free mosaicing, though it was only demonstrated in a small scene. 

Proposed a real-time approach of mosaicing images from UAVs for disaster 
response. First, the images were downsampled and roughly aligned using only 
GPS and IMU data, then as bandwidth allowed, the alignment was refined using 
feature based methods \cite{TODO}

In 2010, Botterill proposed using Bag-of-Words representation of images 
to reduce the search space for overlapping images. This provides a cheap 
approach for finding wide-baseline correspondences for mosaic building \cite{Botterill10}



\section{Featureless Scenes}
Prasad, et al investigated the problem of developing mosaics in quadcopter surveys 
with gaps in features using imu information to improve convergence time.
The approach was demonstrated on building walls with only small regions (paintings) 
that provided keypoints\cite{Prasad16} 
\cite{Schaffalitzky01}

\cite{Olson10} Captured more than two images of the same scene with varying baselines to improve depth estimates.

\cite{Bay05} matched scenes using line segments in addition to descriptors to match homogenous scenes like 
architectural interiors. Line segments conveny geometrical and topological information while the region descriptors capture details 
about local appearence. Made wide-baseline more reliable. Line segments are 
not very descriptive. 
Line segments extracted using a Canny edge detector. Edges are split at points 
of high curvature. 

Large area addition aided by navigational sensors 
to generate 3D submaps that are merged using bundle adjustment \cite{Pizarro04}.


 \section{Dynamic Scenes}
Small dynamic scene mosaics have been tackled in \cite{Fitzgibbon01, Rav-Acha07, Davis98, Uyttendaele01}. 
However, our approach was to use a simpler, masking scheme to bar the feature 
extraction algorithm from extracting keypoints from the dynamic portions of our 
images. This is similar to the approach taken by Vousdoukas to mask sea and sea foam
from shoreline images captured form an UAV in which he 
manually selecting pixels associated with the 
sea and foam and thresholding based on these intensities \cite{Vousdoukas11}. Because 
Vousdoukas' mosaic was created along the shoreline, he was able to use 
interesting keypoints from the shoreline to complete the mosaic using SIFT features. 

Because image stitching techniques utilize features that are consistent amongst 
overlapping images, dynamic or moving objects can cause false matches and incorrect 
homography estimations. Our images are captured serially with a single camera so 
that no two views of the scene are captured at the same moment. This means that 
nonstationary 
features in the scene are subject to change between images.

In sea ice imagery, 
the sea is subject to waves and ripples that may be extracted as features, but 
will change over time and could result in false matches or no matches. 
There are many methods for mosaicing a scene with dynamics in the static mosaic. 
Some approaches eliminate all dynamic information in the scene, while others 
attempt to encapsulate the changes between images by overlaying the movement 
into the mosaic. 

TODO: do keypoints ever fall on water?
For the purposes of this system, the dynamic movement 
of waves is not interesting information.
We can exclude water from the feature extraction by first segmenting
the image into ice and non-ice pixels. In addition to improving the feature 
extraction process, we are also able to form an estimate of the sea ice coverage 
for scientific and ship navigational purposes. 






\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{no_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A typical image of sea ice captured from a UAV with few features and homogoneous texture. }
         \label{fig:no_features}
     \end{minipage}%
     \begin{minipage}{.5\textwidth}
         \centering
        \includegraphics[width=.9\linewidth]{good_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A sea ice image with many corners and distinctive  features to use for feature matching. }
             \label{fig:good_features}
      \end{minipage}
\end{figure}

\chapter{Feature Evaluation in Homogenous Images}
\label{chap:features}

Like, most modern approaches, we register images by selecting key 
features from each image 
and attempting to relate them to other images in the scene. 
There exist a wide variety of feature extraction and description
techniques that enable matching between visual correspondences despite 
rotation, scaling, or environmental changes such as lighting 
noise. 
In addition to invariance, a high number of detected features is also desireable
to improve matching. 
Keypoints should have high information content as measured by 
repeatibility rate and information content. 

Feature detectors rely on the existence of edges, corners, or  blobs in 
the image to match images. If none occur, then no features can be detected. 
Feature detecting algorithms tend to have different strengths and weaknesses as 
discussed in several studies \cite{Tuytelaars08, Mikolajczyk05, Heinly12, Bekele13}. 
Bekele \cite{Bekele13} in particular proved a good 
overview of popular feature descriptors and 
detectors and their performance which guided our evaluation on sea ice dataset.
Describing keypoints is difficult in ice surveys 
because of the lack of distinguishable features on images that contain 
only ice or only water. All ice images often contain a high degree of repetitive 
simularity which means even distinctive features can be incorectly matched with 
non-overlapping images. 

Heinly showed that the descriptors should be adapted to the transofrmations 
present in the data \cite{Heinly12}.

Equation \ref{eq:putativematches} was introduced by \cite{Heinly12}.

% Quantifying a match
In the following sections, feature detectors and descriptors are discussed and 
evaluated on our dataset based on a number of points: 

%where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).


\begin{itemize}
    \item{Average number of keypoints}
    \item{Precision of matches}
    \item{Recall of matches} 
    \item{Average number of good matches}
\end{itemize}

\begin{equation}
recall = \frac{number of correct matches }{number of correspondences}
\label{eq:recall}
\end{equation}

\begin{equation}
1-precision = \frac{number of false matches }{number of matches}
\label{eq:precision}
\end{equation}

\begin{equation}
putative match ratio = \frac{number of putative matches }{maximum possible matches}
\label{eq:putativematches}
\end{equation}

\begin{figure}
\label{fig:rotate_results}
\centering
\includegraphics[width=\linewidth, height=.6\paperheight]{rotate.png}
        \captionsetup{width=.9\linewidth}
        \captionof{figure}{
A comparison of different feature descriptors on two datasets of 60 images randomly selected over a variety of conditions. The dataset labeled "good features" contained images with strong corners and lines, while the dataset labeled "bad features" contained images with only snow or ice and not significant features. Each image was subjected to a change in rotation and scored on its ability to match to the original image using a brute-force matcher.  }
\end{figure}

\begin{figure}
\label{fig:scale_results}
\centering
\includegraphics[width=\linewidth, height=.6\paperheight]{Scale.png}
        \captionsetup{width=.9\linewidth}
        \captionof{figure}{
A comparison of different feature descriptors on two datasets of 60 images randomly selected over a variety of conditions. The dataset labeled "good features" contained images with strong corners and lines, while the dataset labeled "bad features" contained images with only snow or ice and not significant features. Each image was subjected to a change in scale and scored on its ability to match to the original image using a brute-force matcher.  }
\end{figure}


Today, the most common technique for monitoring sea ice is through data obtained 
by satellites. 
%A  perfect descriptor would give a recall equal to 1 for any precision

Putative matches, proposed by Heinly, allows us to measure the 
selectivity of the descriptor. 
precision is also the inlier ratio (ransac). The precision greatly influences the performance of robust estimation techniques like RANSAC. RANSAC's runtime increases exponentially as the inlier ratio decreases \cite{Heinly12}. 

%Percent of matches - quotient of dividing matches count on the minimum of keypoints count on two frames in percents.
%Percent of matches - quotient of dividing matches count on the minimum of keypoints count on two frames in percents.
%Percent of correct matches - quotient of dividing correct matches count on total matches count in percents.
%Matching ratio - percent of matches * percent of correct matches. In all charts i will use "Matching ratio" ( in percents) value for Y-axis.


Parameters in each of the detectors are 
tuned so that 4000 features are detected in the reference image.  
If more than 4000 features are detected in the image, only the first 4000 
are used in the evaluation.  

TODO:
plot featureless comparisons for each of the descriptors at one rotation

\section{SIFT}
One of the most well known and often used keypoint descriptors is Scale
Invariant Feature Transforms (SIFT) \cite{Lowe04}. SIFT descriptors detects keypoints 
based on Difference of Gaussians (DOG). This algorithm, developed in 2004
has consistently been the top performer in terms of  
scale and rotation invariance, though it is has the highest overhead
of the descriptors discussed. Since SIFT, many SIFT-like descriptors have been 
introduced such as SURF \cite{Bay-SURF08}, and ASIFT  \cite{ASIFT} to 
reduce computation time.  


\section{SURF}
A successor to SIFT, Speeded-Up Robust Features (SURF) 
yields similar feature performance to SURF, but with 
faster computation time \cite{Bay-SURF08}. The performance improvement is 
acomplished by describing keypoints with the responses of Haar-like filters. 
Haar features are global-texture based. Both SIFT and SURF use an orientation 
operator. 
%Good foundation paper on multiscale approach \cite{Brown05} ??
%- this seemed to have a good descript of sift: http://www.cs.cmu.edu/~rahuls/pub/cvpr2004-keypoint-rahuls.pdf

\section{ORB}
%ORB
Although SURF achieves some speed gain over SIFT, it is still not realistic 
for real-time applications on platorms with limited capability \cite{Bekele13}. 
Binary keypoint descriptors aim to provide lightweight and fast computation with 
good performance by building the descriptor such that each bit is independent.
This allows Hamming distance to be used rather than Eucliden distance to measure 
similarity \cite{Bekele13}. TODO: should I change matching depending on Descriptor?
Heinly showed that the speed improvement in matching binary desscriptors 
result in only marginal matching performance penalties \cite{Heinly12}.

The Oriented FAST and Rotated BRIEF descriptor, or ORB, 
is a computationally efficient alternative to SIFT and SURF
and can be used in real-time 
on many platforms \cite{Rublee-ORB11}. 
Like its name suggests, it works off of the very efficient FAST keypoint 
detector \cite{Rosten-FAST06} and BRIEF descriptor \cite{Calonder-BRIEF10}.
ORB overcomes the lack or rotational invariance in the BRIEF descriptor by 
de-correlating BRIEF features under rotational invariance, however, ORB is
only somewhat scale invariant.

%BRISK
%FREAK
\section{FREAK}
The FREAK descriptor, developed in 2012 by Alahi improves upon the BRISK
descriptor \cite{Leutenegger-BRISK11} and was 
inspired by the retinal pattern in the biological eye. 
FREAKs are in general faster to compute with lower memory load than 
 SIFT, SURF or BRISK \cite{Alahi-FREAK12}. Most approaches use 
SURF keypoints for FREAK descriptors as 
the they are invariant to rotation and scale changes.

% A cascade of binary strings is computed by efficiently comparing image intensities over a retinal sampling pattern. FREAKs are in general faster to compute with lower memory load and also more robust than SIFT, SURF or BRISK. They are competitive alternatives to existing keypoints in particular for embedded applications.



\section{Harris Keypoints with Zernike Descriptors}
Zernike moment descriptors are a set of orthogonal polynomials that 
work well in the presence of 
rotation, noise,  and large scale changes in a computationally efficient manner. 
In 2003, Pizarro introduced a zernike-feature based 
approach to mosaic large scale featureless
scenes underwater with lighting correction \cite{Pizarro03}.

We utilize the classic Harris keypoints for fast corner finding. 
Harris keypoints are detected at the local minima of an autocorrelation 
function that is invariant to geometric image transformation \cite{Schmid98}. 

TODO: read and cite these
Used zernike to create mosaic - read more \cite{Zhanlong13}
\cite{dudek}
\cite{Zhanlong13, Pizarro03, Badra98, Badra99}
\cite{Bin02}
Use this for equations
\cite{Ameyah07} 
\cite{Hwang08}
\cite{Chen10}
Learn descriptors using conv net. 
\cite{Simo15}
%Zernike Polynomials 
%complex polynomials that are orthogonal over the unit circle $x^2 + y^2 = 1$. 
%They can be expressed in radial and angular components. 
%
%\label{eq:zernike polynomial}
%V_{nm}(x,y) = V_{nm}(\rho, \theta) = R_{nm}(\rho)\emph{e}^{im\theta}
%$
%\emph{n} is a positive integer
%\emph{m} is an integer such that $n-|m|$ is even and $|m|<=n$
%$\rho$ is the magnitude of the vector from the origin to the point $(x,y)=x^2+y^2$
%$\theta$ is the angle between the vector and the x-axis in a counter-clockwise direction



\section{Feature Discussion}
Alahi et al. show that using a grid of well performing descriptors achieves better 
matching than using a single one to match an image region \cite{Alahi10}. 
%Features with a low success ratio in matching (about 0.5) are deleted from the 
%map if at least 10 matches have been attempted. Mapmaintence allows deleting of non 
%trackable features - for instance those captured on moving objects such as 
%waves or people. 

%The percentage of successful matches obtained by the point tracker is used to have an estimation about the level ofthehierarchywherethehomographycomputationshould start.Thesepercentagethresholdswereobtainedempirically byprocessinghundredsofaerialimages.Eachlevelinvolves thefollowingdifferentsteps:
%.Complete homography. Least median of squares (LMedS) is used for outlier rejection and a M-Estimator to compute the final result. This model is used if more than the 65\% of the matches are successfully tracked.
%. Affine homography. If the percentage of success in thetrackingstepisbetween40\% and65\%,thenthe LMedS isnotused,giventhereductioninthenumber ofmatches.A relaxedM-Estimator(softpenalization) is carried out to compute the model.
%
%Euclidean homography. If the percentage is below 40\%, the set of data is too noisy and small to apply non- linear minimizations. The model is computed using least-squares.
%\cite{Caballero07}

\chapter{Categorizing Ice}

The Jaccard index is the same thing as the Jaccard similarity coefficient. We call it a similarity coefficient since we want to measure how similar two things are.

The Jaccard distance is a measure of how dis-similar two things are. We can calculate the Jaccard distance as 1 – the Jaccard index.

\chapter{Description of Approach}

\section{Online Approach}
\section{Global Approach}
This approach utilizes 
the knowledge that the UAV captured images in a spatial order as it was flying, 
so we attempt to match images with neighboring timestamps first.
This sequential approach is not necessary, but will decrease convergence time 
as it limits the number images that must be searched in a typical mission. 
Local motion around each feature point is expected to be mostly 
translational with minimal roll and pitch of the camera. 



\chapter{Ice Density Estimation}
\label{chap:density}

\chapter{Experiments and Results}
\label{chap:results}
demo 
translation - minimal overlap, detected that there was no rotation or scaling.
rotation   - what angle limit?
-- show plot of actual angle of rotation vs calulated
scaling - images should be scaled to size of smallest before stitching
-- show plot of actual scaling vs calculated
demo 
\subsection{Aerial Surveys}

\subsection{Image Patches}
\section{Error Metrics} 
standard measurments, cross correlation between images - 
speed ...


\section{Validation - Synthetic Mosaic}
A synthetic survey is generated from a single image by dividing the image into
a grid overlapping sub-images.  This provides a planar scene with an ideal 
pinhole camera. Simple translations produce the resulting image. Another test 
introduced rotation and scaling into each sub-image. 

\chapter{Conclusion and Future Work}
\label{chap:conclusion}


\pagebreak{}
\section{References}
\bibliography{biblio}
\begin{vita}
This should be a one-page short vita.

There can be more paragraphs.\end{vita}
\end{document}



%
%\begin{figure}[H]
%\noindent \begin{centering}
%\framebox{\begin{minipage}[t]{1\columnwidth}%
%\textbackslash{}documentclass{[}12pt,english{]}\{report\}
%
%\textbackslash{}usepackage\{UTSAthesis\}
%
%... use other packages ...
%
%\textbackslash{}begin\{document\}
%
%\textbackslash{}committee\{... \}
%
%\textbackslash{}informationitems\{... \}
%
%\textbackslash{}thesiscopyright\{...\}
%
%\textbackslash{}dedication\{\textbackslash{}emph\{I would like to
%dedicate this thesis/dissertation to ...\}\}
%
%\textbackslash{}title\{\textbackslash{}textbf\{First line\}\textbackslash{}\textbackslash{}
%\textbackslash{}textbf\{second line \}...\}
%
%\textbackslash{}author\{...\} 
%\textbackslash{}maketitle 
%\textbackslash{}begin\{acknowledgements\} ... \textbackslash{}end\{acknowledgements\}
%\textbackslash{}begin\{abstract\} ... \textbackslash{}end\{abstract\}
%\textbackslash{}newpage 
%\textbackslash{}pagenumbering \{arabic\} 
%\textbackslash{}setcounter \{page\}\{1\} 
%\textbackslash{}pagestyle\{plain\}
%\textbackslash{}chapter\{...\} \% or \textbackslash{}include\{chap3\}
%...
%\textbackslash{}singlespace
%\textbackslash{}bibliographystyle\{...\} 
%\textbackslash{}bibliography\{...\}
%\textbackslash{}begin\{vita\}...\textbackslash{}end\{vita\}%
%\end{minipage}}
%\par\end{centering}
%\caption{Structure of a thesis \protect\LaTeX{} file\label{fig:Structure-of-thesis}}
%\end{figure}
%
%
%The following commands are defined in UTSAthesis.sty and should be
%used in the order suggested in Fig. \ref{fig:Structure-of-thesis}
%to provide required format information.
%\begin{itemize}
%\item \textbackslash{}title\{Thesis Title\}. This can contain multiple lines.
%Use ``\textbackslash{}\textbackslash{}'' to go to the next line.
%\item \textbackslash{}author\{Name of Thesis Author\}
%\item \textbackslash{}thesiscopyright\{Optional Copyright Statement\} 
%\item \textbackslash{}dedication\{Optional Dedication\} 
%\item Either \textbackslash{}committee\{Supervisor Name, Degree\}\{Co-Supervisor
%or Committee B Name, Degree\}\{Committee C Name, Degree\}\{Committee
%D Name, Degree\}\{Committee E Name, Degree\} or the following commands
%separately.
%
%\begin{itemize}
%\item \textbackslash{}supervisor\{Supervisor Name, Degree\} 
%\item \textbackslash{}cosupervisor\{Co-Supervisor Name, Degree\} or \textbackslash{}committeeB\{Committe
%member B Name, Degree\} 
%\item \textbackslash{}committeeC\{Committe member C, Degree\} 
%\item \textbackslash{}committeeD\{Committe member D, Degree\} 
%\item \textbackslash{}committeeE\{Committe member E, Degree\}
%\end{itemize}
%\item Either \textbackslash{}informationitems\{Full Name of Degree\}\{Short
%Name of Degree\}\{Full Name of Department\}\{Full Name of College\}\{Month
%of Thesis\}\{Year of Thesis\} or use the following commands separately.
%
%\begin{itemize}
%\item \textbackslash{}degree\{Full Degree Name\} 
%\item \textbackslash{}degreeshort\{Short Degree Name\} 
%\item \textbackslash{}department\{Department Name\} 
%\item \textbackslash{}college\{College Name\} 
%\item \textbackslash{}thesismonth\{Month\} 
%\item \textbackslash{}thesisyear\{Year\} 
%\end{itemize}
%\item \textbackslash{}maketitle is the command to produce the signature
%page, copyright page, dedication page, and the title page. The position
%of this command is important. 
%\item \textbackslash{}begin\{acknowledgements\}
%
%
%People, organization, supports that you want to thank for 
%
%
%\textbackslash{}end\{acknowledgements\}
%
%\item \textbackslash{}begin\{abstract\}
%
%
%The abstract starts here. Should within one page.
%
%
%\textbackslash{}end\{abstract\} 
%
%\item The thesis/dissertation should then continue with chapters, appendixes,
%references. Before the first chapter, it is necessary to set Arabic
%page number. If the thesis/dissertation is long, it may be better
%to place chapters into separate \LaTeX{} files and include these sub-files
%using \textbackslash{}include\{\} command.
%\item \textbackslash{}begin\{vita\}
%
%
%The last item is a one-page curriculum vita
%
%
%\textbackslash{}end\{vita\}
%
%\end{itemize}
%
%\subsection{Produce the Outcome}
%
%To produce the pdf version of the thesis/dissertation, run pdflatex
%and bibtex.
%
%
%\section{The utsathesis.layout Package}
%
%The utsathesis.layout is an \LyX{} layout that provides a \LyX{} document
%layout for UTSA dissertation/thesis. This layout should be used together
%with the UTSAthesis.sty.
%
%
%\subsection{Installation}
%
%First, install UTSAthesis.sty as described in Section \ref{sec:UTSAthesis.sty}.
%Then, installed the \LyX{} on your system by following the instruction
%that comes with the \LyX{} package. Next, place the utsathesis.layout
%into your personal \LyX{} directory. On a Linux/Unix system, this
%directory is at \textasciitilde{}/.lyx/layouts. On Mac OS, it is at
%/User/<name>/Library/Application Support/\LyX{}-<version>/layouts.
%On Windows 7, it is at C:\textbackslash{}Users\textbackslash{}<name>\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}lyx<version>\textbackslash{}layouts.
%Remember to run Tools->Reconfigure inside \LyX{} to re-configure the
%system.
%
%
%\subsection{Use of utsathesis.layout Package}
%
%This document (sampleThesis.lyx) provides a template for using the
%utsathesis.layout to write a Ph.D. dissertation. For a Master's thesis,
%go to Document->Settings and set the class option to ms. Other important
%settings may include Document->Settings->\LaTeX{} Preamble, and the
%bibliography style.
%
%The document setting should be ``report (UTSAthesis 2012)''. The
%document should begin with committee info, thesis info, copyright,
%and dedication. These can be formatted using items in the FrontMatter
%in the pull-down menu. These should be followed by title, author,
%acknowledgments and the abstract. The placement and the order of these
%four items are important for generating the correctly formatted front
%pages of the thesis/dissertation. It is also important to add the
%``Start First Page'' item right before the first chapter. This item
%will set the correct page numbers for the main portion of the thesis/dissertation.
%
%At the end of the document, the ``Vita'' item in the BackMatter
%in the pull-down menu needs to be used to format a one-page vita.
%
%Regular chapters can be included in the main thesis document or more
%likely as sub-files, one per chapter. If sub-files are preferred,
%make sure the document settings of all sub-files are identical to
%the main document. 
%
%
%\chapter{Literature Review}
%
%We have some citations \cite{dabiri-optimization-isqed-2008,melhem-ieeetc-2003,pradhan-fault-tolerance-1986}.
%See the Bibliography for the format of references.
%
%\include{chapt3}
%
%
%\chapter{Solution and Evaluation}
%
%In this chapter, we show the structures of math formula, theorem commands,
%and floats (such as algorithm and table).
%
%
%\section{A Theory}
%\begin{defn}
%This is another definition.\end{defn}
%\begin{thm}
%This is a theorem.
%\begin{equation}
%X=\frac{AB}{Y}
%\end{equation}
%\end{thm}
%\begin{proof}
%The proof is done here.
%\end{proof}
%
%\section{An Algorithm}
%
%The following is the algorithm.
%
%\begin{algorithm}
%\begin{enumerate}
%\item Step One
%\item Step Two
%\end{enumerate}
%\caption{The Do-It-Yourself Method}
%
%
%\end{algorithm}
%
%
%
%\subsection{Evaluation}
%
%The evaluation results is shown in the following table. It is straightforward
%to place the caption of the table above or below the table.
%
%\begin{table}
%\caption{Evaluation Results}
%
%
%\noindent \centering{}%
%\begin{tabular}{|c|c|c|c|}
%\hline 
% & Method 1 & Method 2 & Method 3\tabularnewline
%\hline 
%\hline 
%Criterion 1 &  &  & \tabularnewline
%\hline 
%Criterion 2 &  &  & \tabularnewline
%\hline 
%Criterion 3 &  &  & \tabularnewline
%\hline 
%\end{tabular}
%\end{table}
%
%
%The following is a long table
%
%\noindent \begin{center}
%\begin{longtable}{|c|c|c|c|c|}
%\caption{A Long Table\label{tab:A-Long-Table}}
%\endfirsthead
%\multicolumn{5}{c}{\textbf{Table \ref{tab:A-Long-Table}}: Continued}\tabularnewline
%\endhead
%\hline 
%Column1 & Column 2 & Column 3 & Column 4 & Column 5\tabularnewline
%\hline 
%\hline 
%1 &  &  &  & \tabularnewline
%\hline 
%2 &  &  &  & \tabularnewline
%\hline 
%3 &  &  &  & \tabularnewline
%\hline 
%4 &  &  &  & \tabularnewline
%\hline 
%5 &  &  &  & \tabularnewline
%\hline 
%6 &  &  &  & \tabularnewline
%\hline 
%7 &  &  &  & \tabularnewline
%\hline 
%8 &  &  &  & \tabularnewline
%\hline 
%9 &  &  &  & \tabularnewline
%\hline 
%10 &  &  &  & \tabularnewline
%\hline 
%11 &  &  &  & \tabularnewline
%\hline 
%12 &  &  &  & \tabularnewline
%\hline 
%13 &  &  &  & \tabularnewline
%\hline 
%14 &  &  &  & \tabularnewline
%\hline 
%15 &  &  &  & \tabularnewline
%\hline 
%16 &  &  &  & \tabularnewline
%\hline 
%17 &  &  &  & \tabularnewline
%\hline 
%18 &  &  &  & \tabularnewline
%\hline 
%19 &  &  &  & \tabularnewline
%\hline 
%20 &  &  &  & \tabularnewline
%\hline 
%21 &  &  &  & \tabularnewline
%\hline 
%22 &  &  &  & \tabularnewline
%\hline 
%23 &  &  &  & \tabularnewline
%\hline 
%24 &  &  &  & \tabularnewline
%\hline 
%25 &  &  &  & \tabularnewline
%\hline 
%26 &  &  &  & \tabularnewline
%\hline 
%27 &  &  &  & \tabularnewline
%\hline 
%28 &  &  &  & \tabularnewline
%\hline 
%29 &  &  &  & \tabularnewline
%\hline 
%30 &  &  &  & \tabularnewline
%\hline 
%31 &  &  &  & \tabularnewline
%\hline 
%32 &  &  &  & \tabularnewline
%\hline 
%33 &  &  &  & \tabularnewline
%\hline 
%\end{longtable}
%\par\end{center}
%
%
%\chapter{Future Directions}
%
%There can be more chapters.
%
%\appendix
%
%\chapter{Notations }
%
%Here we show the use of multiple appendixes.
%
%
%\section{Math Notations}
%
%Each appendix can have sub-sections as a regular chapter.
%
%
%\section{Additional Notations}
%
%
%\chapter{Ontologies}
%
%These is another appendix.

%the individual components. 
