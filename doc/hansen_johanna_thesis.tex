%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{longtable}
\usepackage{float}
\usepackage{calc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

%graphicx is not part of included utsa thesis
\usepackage{graphicx}
%\usepackage{subcaption}
\graphicspath{{./figures/}}
\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{UTSAthesis}      
\usepackage{times}            
\usepackage{latexsym}

\newenvironment{ruledcenter}{%
  \begin{center}
  \rule{\textwidth}{1mm} } {%
  \rule{\textwidth}{1mm} 
  \end{center}}%


  \theoremstyle{definition}
  \newtheorem{defn}{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

  \providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}

\begin{document}
\bibliographystyle{acm}
\committee{Sos Agaian, Ph.D., Chair}{Prof Hanumant Singh, Ph.D.}{Prof. C, Ph.D.}{Prof. D, Ph.D.}{Prof. E, Ph.D. }


\informationitems{Master of Science in Electrical Engineering}{M.Sc.}{Department of Electrical Engineering}{College of Engineering}{May}{ 2016 }


\thesiscopyright{Copyright 2016 Johanna Hansen \\
All rights reserved. }


\dedication{\emph{I would like to dedicate this thesis to the many mentors and 
teachers who have guided me throughout this process.}}


\title{\textbf{IceView: A System for Mosaicing Sea Ice in Changing Environments}}


\author{Johanna Hansen}
\maketitle
\begin{acknowledgements}

Thanks!

\end{acknowledgements}

\begin{abstract}

    Unmanned Aerial Vehicles (UAVs) are providing revolutionary inexpensive, 
real-time access to the terrain around us. One application where this technology 
is especially valuable is for ships navigating in ice laden waters. For these ships, 
satellites are often too slow to provide up-to-date information and helicopters 
are cost prohibitive. UAVs collect many images with small fields of view. To 
organize these photos so that the data is human interpretable, 
they are organized into a single mosaic which combines many views of the 
same scene into a single image. To acomplist this, the geometric
 relationships between the images must be determined.

Traditional image mosaicing algorithms tend to fail when faced with sea ice 
scenes for two reasons; ice itself typically has very few features from which 
to match to overlapping images and water pixels are dynamic in nature  
making it impossible to match with overlapping images that are taken at different 
points in time. The Iceview system attempts to solve these obstacles by 
utilizing multi-scale Harris point detector coupled with a Zernike feature 
descriptor.  This approach assumes that the extended scene 
is planar and determines homographies for each image by topology estimation 
through feature-based pairwise image registation across all images using a 
multi-scale Harris point detector with a feature descriptor. The approach is 
demonstrated using real data obtained on an Artic Expedition. 

\end{abstract}
\pageone{}

\chapter{Introduction}

\section{Motivation}

Expeditions into the world's frozen oceans requires expert navigation and 
real-time knowledge of the constantly shifting conditions. This region of the earth 
is both interesting from a scientific perspective  
because much of it remains unexplored. It also harbours rich natural resources 
that passage ways that are increasingly important to government and commercial 
interests. However, navigating and working in remote sea ice still presents 
a significant technological challenge and requires constant monitoring to work 
safely. Historically, ships working in these conditions
have relied on human scouts, helicopters, and/or satellite imagery to monitor 
the sea ice movement.  However, these approaches are resource intensive suboptimal
solutions. Manned aircraft such as helicopters are often prohibitively 
expensive and require 
expert pilots and precious deck space. Satellite sensors provide useful overviews, 
but are typically low-resolution, 
prone to occlusion by cloudcover or atmospheric conditions, 
and often updated at a prohibitively low frequency for shifting conditions.

Unmanned Aerial Vehicles (UAVs) equipped with high
resolution digital cameras offer a low-cost, real-time alternative to manned aircraft. 
They require little expertise to operate and little deck space. However, because 
there is no human observer of the terrain, the data collected from the vehicle must 
be processed and analyzed in a way that is useful for non-technical decision makers. 
Although UAVs can provide images with high resolution, each image only covers a 
small part of the interesting area.
 This means that a single flight can result in thousands 
of images that must be organized into a human-readable format. 
A process called image mosaicing must be performed to merge overlapping images 
of the terrain into a single high resolution image that is easy to comprehend and 
integrate into existing workflows. 
Image registration is the process of developing a pixel-to-pixel mapping between 
the views in the distinct images. 
By registering the many images into a single mosaic, 
we can create a composite scene called a mosaic with a large field of 
view, while maintaining high resolution.  


    However, traditional
methods tend to fail when tasked with stitching sea ice imagery.
Both the ice and sea that are present in this type of imagery present challenges 
for tradational mosaicing approaches. The ice itself is often nearly featureless, 
making it difficult for feature-based matching schemes to work robustly. 
Bodies of water are generally useless for feature matching because of its dynamic 
properties and meaningless features over time. 
This report approaches these problems by developing a pipeline for working 
with a sea ice dataset. 


\section{Related Work}

Aerial photography has been used to gain a greater viewpoint of the world and 
has been used extensively reconassance, agriculture, and science. 
Historically, images were captured on air balloons and airplanes and then printed 
and aligned by hand. In modern times, digital cameras and smartphones are capable of 
automatically stitching panoramas on a small platform. 
There exists a large and robust body of work for creating mosaics from digital photographs
\cite{Milgram75, Milgram77, Szeliski97, Shum00, Marcon13,   
Brown03, Brown07, Autopano, PhotoScan }, video \cite{Szeliski96, Steedly05} and for full 3D 
reconstruction \cite{Morimoto97, Shum-3D98}. These methods are more fully 
reviewed in \cite{Prathap16, Zitova03}.

How do satellite images over water get mosaiced ?
Can you treat ice like grayscale text?
\section{Background}

Early work in digital mosaicing generally fell into two camps, 
direct and feature based. Direct methods attempt to use correlations 
over the entire image to find overlapping regions in images and can be
slow and memory intensive \cite{Lucas81, Barnea72, Szeliski95, Szeliski97, Shum-local98, Irani00}.  Feature
based methods extract interesting regions (such as lines or edges) and
measures the similarity of these regions to determine overlaps
with less computational cost than the direct method 
\cite{Tuytelaars08, Forstner86, Lowe99, Brown03, Hu06, Elibol08}. 
These are features are locations in the image in which we expect will be 
easy to match with overlapping images. The direct methods uses all available data 
from each image of video frame and is heavily dependent on illumination. 
Feature-based methods utilize interesting parts of the image, such as corners, 
lines, or blobs that are extracted from each image to find overlapping regions 
between images .
Feature based methods will be further investigated and compared in Section \ref{sec:features}.

Many researchers and engineers have utilized UAVs to gather images to form large-scale 
photo mosaics \cite{ Caballero07, Yahyanejad10, Cheng10, Pritt14, Kekec14, Prasad16, Vousdoukas11, Wang11}.
Images collected with a UAV can often be quickly, but roughly  aligned 
using data from sensors such as Global Positioning System (GPS) points and 
Intertial Measurement Unit (IMU) estimates.
However, these measurements are typically not 
accurate or reliable enough to generate a visually appealling image. 
Instead, most approaches for mosaicing UAV images is to extract common 
features between consecutive images to infer the motion between images.
This approach requires some degree of overlap between images and significantly 
higher computing requirments than a simple alignment based on sensors, but it 
produces much more accurate results. 

\section{Aerial Mosaics}

TODO: talk about matching then registration
translational motion model that changes point of view.
Mosaics with extended field of view benefit 
from the relatively large and equal distance to the scene in each image. 
How to recover mosaic with 3D rotations rather than 8 parameter planer 
perspective transforms \cite{Szeliski97}
Registration \cite{Barnea72, Shum-local98, Sawhney99}
However, our experminents indicate that these packages were not 
reliable for developing mosaics with sea ice 
data. The large volume of images with poor features that results from a typical  UAV sea 
ice survey seemed to incapacitate the algorithms available in commercial software.
When the surveys were divided 
into geographic batches, 
stitching and warping errors typically resulted from the accuracy of feature 
matching or the projection of object height. 
Flaten discussed mosaicing sea ice images for the purpose of UAV navigation in \cite{Flaten-thesis15}, 
but, was unable to demonstrate results using field data. 
TODO: What does NOAA do? - by hand?
The  approach discussed in this paper assumes that the scene lies on a 
planar surface, as sea ice typically does, 
and utilizes knowledge about the structure of the survey to reduce 
the search space.

In the remaining paragraphs we discuss how different researchers approached 
similar problems in mosaicing images from difficult datasets. 

Prasad, et al investigated the problem of developing mosaics in quadcopter surveys 
with gaps in features using imu information to improve convergence time.
The approach was demonstrated on building walls with only small regions (paintings) 
that provided keypoints\cite{Prasad16} 
\section{Underwater Mosaics}

Underwater scenes resemble ice scenes in that they can both be featureless and 
large datasets. In 1996, Fleischer introduced video mosaicing underwater for arbitray 
\cite{Fleischer96}. In 2003, Pizarro introduced a zernike-feature based 
approach to mosaic large scale featureless 
scenes underwater with lighting correction \cite{Pizarro03}. 
Large area addition aided by navigational sensors 
to generate 3D submaps that are merged using bundle adjustment \cite{Pizarro04}.
MATISSE, released 
in 2004 also provides mosaicing capability to seabed videos with navigation data
in conjunction with ArcView\cite{Vincent03, Vincent04}. 
TODO: read \cite{Eustice02, Ferrer07, Fleischer96, Vincent03, Vincent04} 
In 2013 LAPM was 
introduced to provide a general tool for underwater mosaicing for end-user scientists 
in Matlab \cite{Marcon13}. It uses an open-source implementation of 
SIFT features to match images in addition to track information. 
Parallax free underwater \cite{Nagaraja14}

\section{Dynamic Mosaics}
Small dynamic scene mosaics have been tackled in \cite{Fitzgibbon01, Rav-Acha07, Davis98, Uyttendaele01}. 
However, our approach was to use a simpler, masking scheme to bar the feature 
extraction algorithm from extracting keypoints from the dynamic portions of our 
images. This is similar to the approach taken by Vousdoukas to mask sea and sea foam
from shoreline images captured form an UAV in which he 
manually selecting pixels associated with the 
sea and foam and thresholding based on these intensities \cite{Vousdoukas11}. Because 
Vousdoukas' mosaic was created along the shoreline, he was able to use 
interesting keypoints from the shoreline to complete the mosaic using SIFT features. 

ICEBERGS
https://brage.bibsys.no/xmlui/bitstream/handle/11250/2354133/13934_FULLTEXT.pdf?sequence=1&isAllowed=y


Discussed how to measure error in underwater mosaics using vehicle navigation 
data \cite{Roman01}.

MEASURE CHANGE vent growth \cite{Bodenmann14}


Prathap gives a thorough review of the current state of mosaicing \cite{Prathap16}. 

\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{no_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A typical image of sea ice captured from a UAV with few features and homogoneous texture. }
         \label{fig:no_features}
     \end{minipage}%
     \begin{minipage}{.5\textwidth}
         \centering
        \includegraphics[width=.9\linewidth]{good_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A sea ice image with many corners and distinctive  features to use for feature matching. }
             \label{fig:good_features}
      \end{minipage}
\end{figure}



\section{Thesis Overview}

The problem of image mosaicing can be broken several steps. The first step 
is to identify images that have 
overlapping regions. Then these regions must be correctly aligned and 
merged onto the larger mosaic. Identifying overlapping regions is a difficult 
problem, especially in a large search space. Sea ice images also present a 
fairly unique problem in that the images contain largely repeating, homogenous 
pixels that do not perform well with traditional techniques.
For the iceview problem, we add an additional preliminary step to detect 
nonstationary features and remove them from the pixels that are considered for 
feature detection. 

Like, most modern approaches, we register images by selecting key 
features from each image 
and attempting to relate them to other images in the scene. Relating the images 
requires overcoming noise and finding unrelated, unknown translations, scaling, 
and rotations between images. 
After the relationships have been determined, 
it is also necessary to blend the related images together in a 
manner such that the resulting mosaic is visually pleasing, seamless, and accurate.
\begin{enumerate}
\item{Segment the image into stationary and non-stationary regions}
\item{Extract features from stationary regions}
\item{Determine matching features between images}
\item{Estimate homography between images that contain the same keypoints}
\item{Warp images according to estimated homographies so that their overlapping 
regions align}
\item{Paste warped images onto the common scene and blend neighboring pixels}
\end{enumerate}

The approach disucussed in this thesis 
is purely image based and does not neccessitate the use 
of navigation data, however, neighboring images in 
time are searched first for overlap to improve convergence time.


\chapter{Feature Detectiong and Matching}

The main problem in generating a map from ice imagery is 
finding overlapping regions between neighboring images and pasting them together 
with the correct rotation, translation, and scaling between images. 
%%%%%%%%%
Photometric and geometric invariance is the primary
motivation for adopting a feature-based approach.  Direct approaches need a photometric
map between corresponding pixels or have constant intensity between overlapping images. 
Feature based methods can be made to be invariant to changing conditions. 
Feature based methods are able to cope with severe viewing and photometric distortion 
that has led to a wide variety of feature-based algorithms. Feature based approaches, 
the errors are uncorrelated between features so that statistical independance 
can be assumed and bundle adjustment is available over long sequences. Features 
allow us to use less noisy data to compute homography. 

Most 
methods utilize extract intersting points from overlapping images, 
such as regions of color, edges, 
contours, or distinctive points and then match them 
based on a local descriptor which can 
often made to be invariant to rotation or scaling between the images. 
This was first described by Schmid who utilized Gaussian derivitives 
to describe a keypoint in a manner that was rotationally invariant \cite{gausskpt}.
%%%%%%%%%%%%
The first step in describing an image using 
a feature based method is to detect interesting features within the image such as 
corners, blobs, or lines using a feature or keypoint detector. Then these interesting  
features are described by a neighborhood of pixels called descriptors. 
The descriptors are what is used to identified and match keypoints between features.
The feature detector should exhibit repeatability given the same scene under different 
viewing conditions. This is acomplished through the aforementioned descriptor invariance. 
A high number of detected features is also desireable to improve matching. 
The detected features should be accurately localized in location and scale. 
This is especially important when mosaicing because registration of overlapping 
images works off of the keypoint locations. 

Harris keypoints are detected at the local minima of an autocorrelation 
function that is invariant to geometric image transformation \cite{Schmid98}. 
Keypoints should have high information content as measured by 
repeatibility rate and information content. 

Describing keypoints is difficult in ice surveys 
because of the lack of distinguishable features on images that contain 
only ice or only water. All ice images often contain a high degree of repetitive 
simularity which means even distinctive features can be incorectly matched with 
non-overlapping images. 

There exist a wide variety of feature extraction and description
techniques that enable matching between visual correspondences despite 
rotation, scaling, or environmental changes such as lighting 
noise. In the following text, several popular feature descriptors are compared
for their performance on the sea ice dataset. 

Evaluation and selection of features detection algorithms was guided by 
Tuytelaar \cite{Tuytelaars08}. Bekele \cite{Bekele13} which provide good 
overviews of popular feature descriptors and 
detectors and their performance. 

One of the most well known and often used keypoint descriptors is Scale
Invariant Feature Transforms (SIFT) \cite{Lowe04}. SIFT descriptors detects keypoints 
based on Difference of Gaussians (DOG). This algorithm, developed in 2004
has consistently been the top performer in terms of  
scale and rotation invariance, though it is has the highest overhead
of the descriptors discussed. 
%SURF
A successor to SIFT, Speeded-Up Robust Features (SURF) 
yields similar feature performance to SURF, but with 
faster computation time \cite{Bay-SURF08}. The performance improvement is 
acomplished by describing keypoints with the responses of Haar-like filters. 
Haar features are global-texture based. Both SIFT and SURF use an orientation 
operator. 
%Good foundation paper on multiscale approach \cite{Brown05} ??
%- this seemed to have a good descript of sift: http://www.cs.cmu.edu/~rahuls/pub/cvpr2004-keypoint-rahuls.pdf

%ORB
The Oriented FAST and Rotated BRIEF descriptor, or ORB, 
is a computationally efficient alternative to SIFT and can be used in real-time 
on many platforms \cite{Rublee-ORB11}. 
Like its name suggests, it works off of the very efficient FAST keypoint 
detector \cite{Rosten-FAST06} and BRIEF descriptor \cite{Calonder-BRIEF10}.
ORB overcomes the lack or rotational invariance in the BRIEF descriptor by 
de-correlating BRIEF features under rotational invariance. 
Orb only somewhat scale invariant

%BRISK
%FREAK
The FREAK descriptor, developed in 2012 by Alahi et al improves upon the BRISK
descriptor \cite{Leutenegger-BRISK11}
inspired by the retinal pattern in the biological eye. 
FREAKs are in general faster to compute with lower memory load and also
more robust than SIFT, SURF or BRISK \cite{Alahi-FREAK12}

%ZERNIKE
Zernike \cite{Zhanlong13, Pizarro03, Badra98, Badra99}
\cite{Bin02}
about zernike \cite{Ameyah07} ??
Zernike moment descriptors allow matching between points with arbitrary 
rotation and large scale changes in a computationally efficient methodology.  Zernike moements perform well in the presence of noise. 

The assumption of a planar surface allows reduces distrtion. 

Edge density

Pizarro sucessfully demonstrated the the use of Zernike Moments for shape descriptors 
.... mosaic  \cite{Pizarro03, Badra99}. This technique has been applied 
s well as for classification 
problems TODO cite other.

rotational invariant and can be made to be scale and translational invariant. 
Magnitude of zernike moments are rotationally invariant. Used by \cite{Pizarro03}
Zernike momemnt are a set of orthogonal polynomials that offer a complete 
solution to recover rotational and scaling parameters. 
Used zernike to create mosaic - read more \cite{Zhanlong13}
Zernike Polynomials 
complex polynomials that are orthogonal over the unit circle $x^2 + y^2 = 1$. 
They can be expressed in radial and angular components. 


Alahi et al. show that using a grid of well performing descriptors achieves better 
matching than using a single one to match an image region \cite{Alahi10}. 

Recognizing panoramas \cite{Brown03} 
% Quantifying a match
Average number of keypoints, precision in percentage, recall in percentage, 
average number of best matches. Parameters in each of the detectors are 
tuned so that xxx features are detected in the reference image.  
If more than xxx features are detected, the first xxx are taken as 
in \cite{Bekele13}.  
%$
%\label{eq:zernike polynomial}
%V_{nm}(x,y) = V_{nm}(\rho, \theta) = R_{nm}(\rho)\emph{e}^{im\theta}
%$
%\emph{n} is a positive integer
%\emph{m} is an integer such that $n-|m|$ is even and $|m|<=n$
%$\rho$ is the magnitude of the vector from the origin to the point $(x,y)=x^2+y^2$
%$\theta$ is the angle between the vector and the x-axis in a counter-clockwise direction

\chapter{Segmentation}

Image stitching techniques utilize features that are consistent amongst 
overlapping images, however, UAV images are captured serially, so nonstationary 
features in the images are subject to change between images. In sea ice imagery, 
the sea is subject to waves and ripples that may be extracted as features, but 
will change over time and could result in false matches or no matches. 
There are many methods for mosaicing a scene with dynamics in the static mosaic. 
Some approaches eliminate all dynamic information in the scene, while others 
attempt to encapsulate the changes between images by overlaying the movement 
into the mosaic. For the purposes of the iceview system, the dynamic movement 
of waves is not interesting information, so we blur the movement in this section. 
We can exclude water from the feature extraction by first segmenting
the image into ice and non-ice pixels. 


TODO: 
Thresholding gray level occurance
gabor filter - texture
glcp - statistical
The histograms for sea ice images are generally bimodal

Show examples where bad keypoints are detected


\chapter{Feature Matching}

Periodicity leads to a large number of outliers in the match points

Our approach utilizes 
the knowledge that the UAV captured images in a spatial order as it was flying, 
so we attempt to match images with neighboring timestamps first.
This sequential approach is not necessary, but will decrease convergence time 
as it limits the number images that must be searched in a typical mission. 
Local motion around each feature point is expected to be mostly 
translational with minimal roll and pitch of the camera. 

To establish a match between corresponding images, four or more corresponding 
points must be identified. This is the minimal amount of information 
required to solve for eight unknowns in the 2D projective transformation. 

The RANSAC algorithm is used to perform filter poor matches. RAndom SAmple Consensus, 
select one match, count inliers

\chapter{Registration}
Parametric transformations apply a global deformation to an image that is 
defined by a small number of parameters depending on the transformation 
chosen. In near-flat  areas,  the 
errors of object height projections  may be  negligible. Thus, the 
affine  transformation  can  be  directly  implemented.  


Correspondences between features  allow us to compute the camera motion. 
Without distinctive features, this can fail. 
Quality of the mosaic is highly dependent on the acuracy of the calculated 
geometric relationship between overlapping images. For estimating relativ
transformations between adjacent image, 
the projective transformation is typically used. However, the projective
transformation is sub-optimatl with in instances with low overlap between 
images or when there are few distinctive features available. 


Affine tranformation describes scale, rotation, translation, and skew 
between two 2D planes in 2D space. This model is unable to 
explain 3D motions between two image planes, but provides superior 
stability when compared to perspective or projective transformation. 

Image registration refers to the process of geometrically aligning the 
set of images into a common reference plane. We consider pairs of images that 
were aquired under a weak perspective camera model. 
The eight paramerters that define the transformation of the an image onto a 
reference image is estimated by approximating perspective. 

*********
A Homography is a transformation ( a 3×3 matrix ) that maps the points in one image to the corresponding points in the other image.
Global registration is simplified by solving for homographies from image to mosaic and 
not the position of features. ******** For pairwise registration, Can use least 
suares to solve for homography because our use of projective models have 
linear parameters. When solving for global registration, sue 
planar projective transofrm the solves nonlinear least squares. The 2D transformation 
defines the displacement of every pixel. 

Once a match is determined between two images, each pixel from the source image 
must be mapped to a pixel coordinate in the destination image. 
For our ice imagery, we can take advantage of the 
large distance to the scene and the generally planar terrain surface 
to adopt a model which assumes equal distance to each object in the image and 
utilize affine transformation to translate the image coordinates \cite{Wang11}.
The distance from the camera to the target object is much greater than the 
motion between the camera views, so a homographic model can be used to describe. 
 2-D projective transformation. This can be computed without any knowledge of 
the internal camera calibration parameters such as focal length, 
optical center, or relative camera motion between frames. 
A projective transformation is  specified by eight independent parameters. 
The homography is represented as a 3x3 matrix that transforms homogenous 
image coordinates. 

To compute 2D homography between two images:
1. Features - compute interes point features in each pixel
2. Correspondences: compute a set of interest point matches based on 
proximity and similarity of their neighborhood. 
3. RANSAC estimation: 
- select a random set of 4 correspondences and compute the homography. 
- calculate a geometric image distance error for each correspondence. 
- compute the number of inliers consistent with the homography by the number 
of correspondences for which the distance error is less than a threshold 
- choose the homography with the most inliers
4. restimate homography from all correspondences classified as inliers by minimixing 
cost function

\section{FAILURES}
Fails because of repeated/similar regions, moving objects, low-overlap, 
feature-less regions -  to fix these, tune the feature detector
tuen feature matcher, turn ransac, use high-level knowledge



An image 
transformation can be described by ... type of transformation matrix.
\ref{eq:General tranformation equation} where 
\emph{$s_i$} indicates scaling, 
\emph{$r_i$} rotation, and \emph{$t_i$} dictactes translation in the i-th direction. 
Thus, the problem can be reduced to recovering each component independently.


 $$
 \label{eq:General transformation equation}
 M =
 \begin{bmatrix}
 s_xr_{11}&s_xr_{12}&t_x \\ s_yr_{21}&s_yr_{22}&t_y \\ 0&0&1\\
 \end{bmatrix}
 $$




add new images to mosaic one at a time, aligning the most recent image with the 
previous ones already in the collection. A better alternative is to simultaneously 
align all the images together using a least squares framework to distribute 
mis-registration errors. The process of simultaneously adjusting pose parameters 
number of images in bundle adjustment. structure from motion problem
Bundle adjustment can solve for all camera parameters jointly. This minimizes
accumulated errors between pairwise homographies. 

Incremental links - solves for the global mosaic using the overlaps of the 
temporal sequence. 
 
 The disadvantage of bundle adjustment is that there are more variables to solve 
 for, so both each iteration and overal onvergence is slower. 


TODO: \cite{Kekec14}
Could use direct reference with IMU/ GPS, but the relatively large error of position 
and altitude 
%
used four motion models (direct, translation, similarity
and affine) with 0, 2, 4 and 6 parameters respectively.
TODO show results - 
Note that matching performance
is degraded for each new parameter that is added
to the model


TODO: read \cite{Shum-local98}
%%%%%%%%%%%%%%%%%%%%%%
TODO: read \cite{Shum-3D98} about 3d stuff 
This reduces the undesirable projection errors that are easily propagated 
with prjojective transformations \cite{Wang11}.

Maybe talk about ghosting \cite{Uyttendaele01}

\section{Blending}
Neighboring images in a mosaic can vary greatly in lighting, especially when 
subsequent images are seperated by time. 
When merging two images into one image, the seams are typically blended 
to produce a result more pleasing to the human eye. 
Our approach utilizes the open 
source tool, Enblend, that uses a multi-resolution spline to blend images 
together using multi-resolution splines and Laplacian pyramids \cite{enblend, 
Burt83thelaplacian}. 
The spline operates across a transition zone that is proportional 
to the spatial frequency of the region. Homogenous regions like an ice sheet 
have low spatial frequency and are combined across a wide region.
Strong color changes, 
show high spatial frequency and are fused 
over a small area. 

\chapter{Assumptions and Approach}

\chapter{Experiments}
demo 
translation - minimal overlap, detected that there was no rotation or scaling.
rotation   - what angle limit?
-- show plot of actual angle of rotation vs calulated
scaling - images should be scaled to size of smallest before stitching
-- show plot of actual scaling vs calculated
demo 
\subsection{Aerial Surveys}

\subsection{Image Patches}

\chapter{Results}
\section{Error Metrics} 
standard measurments, cross correlation between images - 
speed ...


\section{Validation - Synthetic Mosaic}
A synthetic survey is generated from a single image by dividing the image into
a grid overlapping sub-images.  This provides a planar scene with an ideal 
pinhole camera. Simple translations produce the resulting image. Another test 
introduced rotation and scaling into each sub-image. 

\chapter{Conclusion and Future Work}
\subsection{UAV Sensor Integration}


\pagebreak{}
\section{References}
\bibliography{biblio}
\begin{vita}
This should be a one-page short vita.

There can be more paragraphs.\end{vita}
\end{document}



%
%\begin{figure}[H]
%\noindent \begin{centering}
%\framebox{\begin{minipage}[t]{1\columnwidth}%
%\textbackslash{}documentclass{[}12pt,english{]}\{report\}
%
%\textbackslash{}usepackage\{UTSAthesis\}
%
%... use other packages ...
%
%\textbackslash{}begin\{document\}
%
%\textbackslash{}committee\{... \}
%
%\textbackslash{}informationitems\{... \}
%
%\textbackslash{}thesiscopyright\{...\}
%
%\textbackslash{}dedication\{\textbackslash{}emph\{I would like to
%dedicate this thesis/dissertation to ...\}\}
%
%\textbackslash{}title\{\textbackslash{}textbf\{First line\}\textbackslash{}\textbackslash{}
%\textbackslash{}textbf\{second line \}...\}
%
%\textbackslash{}author\{...\} 
%\textbackslash{}maketitle 
%\textbackslash{}begin\{acknowledgements\} ... \textbackslash{}end\{acknowledgements\}
%\textbackslash{}begin\{abstract\} ... \textbackslash{}end\{abstract\}
%\textbackslash{}newpage 
%\textbackslash{}pagenumbering \{arabic\} 
%\textbackslash{}setcounter \{page\}\{1\} 
%\textbackslash{}pagestyle\{plain\}
%\textbackslash{}chapter\{...\} \% or \textbackslash{}include\{chap3\}
%...
%\textbackslash{}singlespace
%\textbackslash{}bibliographystyle\{...\} 
%\textbackslash{}bibliography\{...\}
%\textbackslash{}begin\{vita\}...\textbackslash{}end\{vita\}%
%\end{minipage}}
%\par\end{centering}
%\caption{Structure of a thesis \protect\LaTeX{} file\label{fig:Structure-of-thesis}}
%\end{figure}
%
%
%The following commands are defined in UTSAthesis.sty and should be
%used in the order suggested in Fig. \ref{fig:Structure-of-thesis}
%to provide required format information.
%\begin{itemize}
%\item \textbackslash{}title\{Thesis Title\}. This can contain multiple lines.
%Use ``\textbackslash{}\textbackslash{}'' to go to the next line.
%\item \textbackslash{}author\{Name of Thesis Author\}
%\item \textbackslash{}thesiscopyright\{Optional Copyright Statement\} 
%\item \textbackslash{}dedication\{Optional Dedication\} 
%\item Either \textbackslash{}committee\{Supervisor Name, Degree\}\{Co-Supervisor
%or Committee B Name, Degree\}\{Committee C Name, Degree\}\{Committee
%D Name, Degree\}\{Committee E Name, Degree\} or the following commands
%separately.
%
%\begin{itemize}
%\item \textbackslash{}supervisor\{Supervisor Name, Degree\} 
%\item \textbackslash{}cosupervisor\{Co-Supervisor Name, Degree\} or \textbackslash{}committeeB\{Committe
%member B Name, Degree\} 
%\item \textbackslash{}committeeC\{Committe member C, Degree\} 
%\item \textbackslash{}committeeD\{Committe member D, Degree\} 
%\item \textbackslash{}committeeE\{Committe member E, Degree\}
%\end{itemize}
%\item Either \textbackslash{}informationitems\{Full Name of Degree\}\{Short
%Name of Degree\}\{Full Name of Department\}\{Full Name of College\}\{Month
%of Thesis\}\{Year of Thesis\} or use the following commands separately.
%
%\begin{itemize}
%\item \textbackslash{}degree\{Full Degree Name\} 
%\item \textbackslash{}degreeshort\{Short Degree Name\} 
%\item \textbackslash{}department\{Department Name\} 
%\item \textbackslash{}college\{College Name\} 
%\item \textbackslash{}thesismonth\{Month\} 
%\item \textbackslash{}thesisyear\{Year\} 
%\end{itemize}
%\item \textbackslash{}maketitle is the command to produce the signature
%page, copyright page, dedication page, and the title page. The position
%of this command is important. 
%\item \textbackslash{}begin\{acknowledgements\}
%
%
%People, organization, supports that you want to thank for 
%
%
%\textbackslash{}end\{acknowledgements\}
%
%\item \textbackslash{}begin\{abstract\}
%
%
%The abstract starts here. Should within one page.
%
%
%\textbackslash{}end\{abstract\} 
%
%\item The thesis/dissertation should then continue with chapters, appendixes,
%references. Before the first chapter, it is necessary to set Arabic
%page number. If the thesis/dissertation is long, it may be better
%to place chapters into separate \LaTeX{} files and include these sub-files
%using \textbackslash{}include\{\} command.
%\item \textbackslash{}begin\{vita\}
%
%
%The last item is a one-page curriculum vita
%
%
%\textbackslash{}end\{vita\}
%
%\end{itemize}
%
%\subsection{Produce the Outcome}
%
%To produce the pdf version of the thesis/dissertation, run pdflatex
%and bibtex.
%
%
%\section{The utsathesis.layout Package}
%
%The utsathesis.layout is an \LyX{} layout that provides a \LyX{} document
%layout for UTSA dissertation/thesis. This layout should be used together
%with the UTSAthesis.sty.
%
%
%\subsection{Installation}
%
%First, install UTSAthesis.sty as described in Section \ref{sec:UTSAthesis.sty}.
%Then, installed the \LyX{} on your system by following the instruction
%that comes with the \LyX{} package. Next, place the utsathesis.layout
%into your personal \LyX{} directory. On a Linux/Unix system, this
%directory is at \textasciitilde{}/.lyx/layouts. On Mac OS, it is at
%/User/<name>/Library/Application Support/\LyX{}-<version>/layouts.
%On Windows 7, it is at C:\textbackslash{}Users\textbackslash{}<name>\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}lyx<version>\textbackslash{}layouts.
%Remember to run Tools->Reconfigure inside \LyX{} to re-configure the
%system.
%
%
%\subsection{Use of utsathesis.layout Package}
%
%This document (sampleThesis.lyx) provides a template for using the
%utsathesis.layout to write a Ph.D. dissertation. For a Master's thesis,
%go to Document->Settings and set the class option to ms. Other important
%settings may include Document->Settings->\LaTeX{} Preamble, and the
%bibliography style.
%
%The document setting should be ``report (UTSAthesis 2012)''. The
%document should begin with committee info, thesis info, copyright,
%and dedication. These can be formatted using items in the FrontMatter
%in the pull-down menu. These should be followed by title, author,
%acknowledgments and the abstract. The placement and the order of these
%four items are important for generating the correctly formatted front
%pages of the thesis/dissertation. It is also important to add the
%``Start First Page'' item right before the first chapter. This item
%will set the correct page numbers for the main portion of the thesis/dissertation.
%
%At the end of the document, the ``Vita'' item in the BackMatter
%in the pull-down menu needs to be used to format a one-page vita.
%
%Regular chapters can be included in the main thesis document or more
%likely as sub-files, one per chapter. If sub-files are preferred,
%make sure the document settings of all sub-files are identical to
%the main document. 
%
%
%\chapter{Literature Review}
%
%We have some citations \cite{dabiri-optimization-isqed-2008,melhem-ieeetc-2003,pradhan-fault-tolerance-1986}.
%See the Bibliography for the format of references.
%
%\include{chapt3}
%
%
%\chapter{Solution and Evaluation}
%
%In this chapter, we show the structures of math formula, theorem commands,
%and floats (such as algorithm and table).
%
%
%\section{A Theory}
%\begin{defn}
%This is another definition.\end{defn}
%\begin{thm}
%This is a theorem.
%\begin{equation}
%X=\frac{AB}{Y}
%\end{equation}
%\end{thm}
%\begin{proof}
%The proof is done here.
%\end{proof}
%
%\section{An Algorithm}
%
%The following is the algorithm.
%
%\begin{algorithm}
%\begin{enumerate}
%\item Step One
%\item Step Two
%\end{enumerate}
%\caption{The Do-It-Yourself Method}
%
%
%\end{algorithm}
%
%
%
%\subsection{Evaluation}
%
%The evaluation results is shown in the following table. It is straightforward
%to place the caption of the table above or below the table.
%
%\begin{table}
%\caption{Evaluation Results}
%
%
%\noindent \centering{}%
%\begin{tabular}{|c|c|c|c|}
%\hline 
% & Method 1 & Method 2 & Method 3\tabularnewline
%\hline 
%\hline 
%Criterion 1 &  &  & \tabularnewline
%\hline 
%Criterion 2 &  &  & \tabularnewline
%\hline 
%Criterion 3 &  &  & \tabularnewline
%\hline 
%\end{tabular}
%\end{table}
%
%
%The following is a long table
%
%\noindent \begin{center}
%\begin{longtable}{|c|c|c|c|c|}
%\caption{A Long Table\label{tab:A-Long-Table}}
%\endfirsthead
%\multicolumn{5}{c}{\textbf{Table \ref{tab:A-Long-Table}}: Continued}\tabularnewline
%\endhead
%\hline 
%Column1 & Column 2 & Column 3 & Column 4 & Column 5\tabularnewline
%\hline 
%\hline 
%1 &  &  &  & \tabularnewline
%\hline 
%2 &  &  &  & \tabularnewline
%\hline 
%3 &  &  &  & \tabularnewline
%\hline 
%4 &  &  &  & \tabularnewline
%\hline 
%5 &  &  &  & \tabularnewline
%\hline 
%6 &  &  &  & \tabularnewline
%\hline 
%7 &  &  &  & \tabularnewline
%\hline 
%8 &  &  &  & \tabularnewline
%\hline 
%9 &  &  &  & \tabularnewline
%\hline 
%10 &  &  &  & \tabularnewline
%\hline 
%11 &  &  &  & \tabularnewline
%\hline 
%12 &  &  &  & \tabularnewline
%\hline 
%13 &  &  &  & \tabularnewline
%\hline 
%14 &  &  &  & \tabularnewline
%\hline 
%15 &  &  &  & \tabularnewline
%\hline 
%16 &  &  &  & \tabularnewline
%\hline 
%17 &  &  &  & \tabularnewline
%\hline 
%18 &  &  &  & \tabularnewline
%\hline 
%19 &  &  &  & \tabularnewline
%\hline 
%20 &  &  &  & \tabularnewline
%\hline 
%21 &  &  &  & \tabularnewline
%\hline 
%22 &  &  &  & \tabularnewline
%\hline 
%23 &  &  &  & \tabularnewline
%\hline 
%24 &  &  &  & \tabularnewline
%\hline 
%25 &  &  &  & \tabularnewline
%\hline 
%26 &  &  &  & \tabularnewline
%\hline 
%27 &  &  &  & \tabularnewline
%\hline 
%28 &  &  &  & \tabularnewline
%\hline 
%29 &  &  &  & \tabularnewline
%\hline 
%30 &  &  &  & \tabularnewline
%\hline 
%31 &  &  &  & \tabularnewline
%\hline 
%32 &  &  &  & \tabularnewline
%\hline 
%33 &  &  &  & \tabularnewline
%\hline 
%\end{longtable}
%\par\end{center}
%
%
%\chapter{Future Directions}
%
%There can be more chapters.
%
%\appendix
%
%\chapter{Notations }
%
%Here we show the use of multiple appendixes.
%
%
%\section{Math Notations}
%
%Each appendix can have sub-sections as a regular chapter.
%
%
%\section{Additional Notations}
%
%
%\chapter{Ontologies}
%
%These is another appendix.

%the individual components. 
