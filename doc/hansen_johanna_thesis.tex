%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{longtable}
\usepackage{float}
\usepackage{calc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

%graphicx is not part of included utsa thesis
\usepackage{graphicx}
%\usepackage{subcaption}
\graphicspath{{./figures/}}
\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{UTSAthesis}      
\usepackage{times}            
\usepackage{latexsym}

\newenvironment{ruledcenter}{%
  \begin{center}
  \rule{\textwidth}{1mm} } {%
  \rule{\textwidth}{1mm} 
  \end{center}}%


  \theoremstyle{definition}
  \newtheorem{defn}{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

  \providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}

\begin{document}
\bibliographystyle{acm}
\committee{Sos Agaian, Ph.D., Chair}{Prof Hanumant Singh, Ph.D.}{Prof. C, Ph.D.}{Prof. D, Ph.D.}{Prof. E, Ph.D. }


\informationitems{Master of Science in Electrical Engineering}{M.Sc.}{Department of Electrical Engineering}{College of Engineering}{December}{ 2016 }


\thesiscopyright{Copyright 2016 Johanna Hansen \\
All rights reserved. }


\dedication{\emph{I would like to dedicate this thesis to the many mentors and 
teachers who have guided me throughout this process.}}


\title{\textbf{Monitoring Sea Ice with Unmanned Aerial Vehicles}}


\author{Johanna Hansen}
\maketitle
\begin{acknowledgements}

Thanks!

\end{acknowledgements}

\begin{abstract}

    Unmanned Aerial Vehicles (UAVs) are providing revolutionary  
real-time access to the terrain around us. The low cost and accessability of this technology has empowered military, agricultural, commercial, and recreational applications with new sensing capabilities. 
This thesis will focus on the application of low-altitude aerial photography for sea ice monitoring, useful for polar sea expidentions and research endeavors as scientists 
try to better understand the world's changing climate. 
For ships navigating in ice laden waters, UAVs provide the potential
to replace manned helicopters acting as scouts for 
 ships navigating in ice laden waters. For these ships, 
real-time knowledge about the changing and often dangerous 
conditions is necessary. Though UAVs provide an excellent data collection platform, 
that data can be labor intensive to process and interpret. Images captured from 
a UAV provide a small field-of-view, meaning that hundreds, if not thousands of 
images are collected on a single scouting mission. The common way to organize 
this information is by joining the overlapping images into a single field of
view image known as a mosaic. The process of creating a mosaic automatically requires 
finding overlapping scenes within neighboring images and then registering each image 
based on the overlap onto a common scene which is known as the mosaic. 
Although this is a fairly routine process with modern computers, traditional 
image mosaicing algorithms tend to fail when faced with sea ice 
scenes. Sea ice is difficult to mosaic for two main reasons; ice itself 
typically has very few distinguishing features from which 
to match to overlapping images, and water pixels are dynamic in nature,  
making it impossible to match images with overlapping scenes that are taken 
at different points in time as in the case of images captured from a UAV flying 
over a scene.
Here we present a method for adding robustness to the mosaicing process by utilizing
sensor information from the vehicle and providing a tier of matching solutions that
isolate dynamic scenes. In addition, we provide an estimate of surface coverage 
of ice. 
The surface estimation provides a quantitative tool which is useful for
scientific endeavors and vessel operators. 
This approach is demonstrated using 
real data obtained over several days on an Artic Expedition. 

\end{abstract}
\pageone{}

\chapter{Introduction}
Capturing images from a low-altitute provides detailed information of the 
target scene, but the tradeoff for resolution is field-of-view. To obtain understanding 
of a scene spread across many high resolution images with a small field-of-view, 
it necessary to combine the information into a larger image by mosaicking the images 
together into a single image. 
Image mosaicking has been utilized to join images of overlapping aerial
scenes since long before digital photographs \cite{Wolf83}. Originally, film 
photographs were captured from hot air balloons or low-flying aircraft and pasted 
together by hand. Later, satellites and digital photography advanced the field 
of remote sensing and we began to stitch and analyze large volumes of images 
with computers. Now, image stitching is commonplace and the technology is embedded 
in many smart phones equipped with cameras for use for stabilization, small panoramas, 
and multiple image super-resolution. Many dedicated software programs are 
available to provide image stitching including 
AutoPano, Hugin, PhotoScan \cite{AutoPano, Hugin, Photoscan}. In this work, we 
tackle a dataset which remains challenging for conventional mosaicking pipelines, 
high resolution imagery of sea ice. 

\section{Motivation}

Expeditions into the world's frozen oceans requires expert navigation and 
real-time knowledge of the constantly shifting conditions. This region of the earth 
is both interesting from a scientific perspective  
because much of it remains unexplored and because it is rapidly changing.
It also harbours rich natural resources 
that are increasingly accessible and important to government and commercial 
interests. However, navigating and working in remote sea ice still presents 
a significant technological challenge and requires constant monitoring of
sea ice to work 
safely. 

Historically, ships working in these conditions
have relied on human scouts, helicopters, and/or satellite imagery to monitor 
the sea ice movement.  However, these approaches are resource intensive in the 
case of helicopters and suboptimal in the case of satellites. 
Manned aircraft are expensive to operate, requiring 
expert pilots and precious deck space and do not necessarily solve the scientific 
problem of cataloguing the sea state. In addition, the low cost and lack of a human 
operator in a UAVs means that 
they can be operated in riskier conditions than manned aircraft. 
Satellite sensors can provide useful
overviews, but the data captured is low-resolution both in time and coverage. It 
is also prone to occlusion by cloud cover or atmospheric conditions. 

Unmanned Aerial Vehicles (UAVs) equipped with high
resolution digital cameras offer a low-cost alternative to manned aircraft. The 
advantage over sattelite imagery is obvious in that the 
data is much higher resolution and a survey can be conducted at the
operators discretion. 
UAVs require little expertise to operate and little deck space. However, because 
there is no human observer of the terrain, the data collected from the vehicle must 
be processed and analyzed in a way that is useful for non-technical decision makers. 
Although UAVs can provide images with high resolution, each image only covers a 
small part of the interesting area.
 This means that a single flight can result in thousands 
of images that must be organized into a human-readable format. 
A process called image mosaicing must be performed to merge overlapping images 
of the terrain into a single high resolution image that is easy to comprehend and 
integrate into existing workflows. 
Image registration is the process of developing a pixel-to-pixel mapping between 
the views in the distinct images. 
By registering the many images into a single image, 
we create a composite scene called a mosaic with a large field of 
view, while maintaining high resolution.  

Several commercially available programs 
have been applied to sea ice dataset with disappointing results. 
However, our experminents indicate that these packages were not 
reliable for developing mosaics with sea ice 
data. The large volume of images with poor features that results from a typical  UAV sea 
ice survey seemed to incapacitate the algorithms available in commercial software.
When the surveys were divided 
into geographic batches, 
stitching and warping errors typically resulted from the accuracy of feature 
matching or the projection of object height. 


The features 
from the sea ice data are often poor or dynamic, causing the non-specialized programs 
to misregister images or fail completely. 

Our approach addresses the reasons these
approaches fail and adds additional advantage in the form of sea ice coverage information. 

In addition, the size of an iceberg is necessary for calculating the 
iceberg's trajectory and stability. However, obtaining data on the geometry is not 
simple, and typically underwater and overhead measurements must be taken to determine 
the size. 

\section{Problem Statement}
The high-resolution low field-of-view tradeoff accepted by the  UAV means that many 
high resolution images are captured in an attempt to understand a scene. Our aim  
in this thesis is to make sense of the data by aligning the many images  
 into a an overview mosaic of the scene while providing useful information about 
 the survey area. The process of creating a mosaic 
requires recognizing overlapping regions between images (if they exist) and 
then determining the transformation between each image onto the base overview scene. 
We require that the scene be orthorectified so that the relative distances between 
features are preserved and georeferenced, so that the overview image can be 
incorporated into Geographic Information Systems (GIS) for further intrepretation, 
analysis, and combining with other data sources. We also wish to provide an 
analysis of the images in the form of ice coverage. This is important both for 
scienctific enquiries and for ship operations. Considering the aforementioned goals 
and challenges, we address and solve the three following problems: 
\begin{itemize}
    \item{Segmenting sea ice from water and other objects to reduce false matches 
        while providing ice coverage information at the same time. }
    \item{How to exploit metadata from the UAV to speed up image matching and 
            registration by reducing the search space of overlapping images and by 
            pre-aligning images so that low-cost feature descriptors can be used for 
            matching.}
    \item{Aligning images when metadata is not available by escalating feature 
            extraction complexity in regions with poor features.
    This iterative scheme adds additional complex only as needed, using fast descriptors when possible and slower, more robust methods only when needed. 
    }
\end{itemize}

\section{Contribution}
This process has been tested on data collected off of an ice breaker working in 
the Artic in various ice conditions. 

The problem of image mosaicing can be broken several steps. The first step 
is to identify images that have 
overlapping regions. Then these regions must be correctly aligned and 
merged onto the larger mosaic. Identifying overlapping regions is a difficult 
problem, especially in a large search space. Sea ice images also present a 
fairly unique problem in that the images contain largely repeating, homogenous 
pixels that do not perform well with traditional techniques.
We add an additional preliminary step to the typical stitching pipeline to detect 
known nonstationary features and remove them from the pixels that are considered for 
feature detection. We use these features to gain understanding about ice floes and 
provide an estimate of sea ice coverage based on this measurement. 
Our mosaic is built incementally by updating the scene 
as new images are captured. This approach means that the overview mosaic is
produced more quickly than with methods that wait for all images to refine homographies. 
We also utilize metatdata to speed up the 
matching process and reduce search space for matching images.


\section{Outline}
The remainder of this thesis is organized as follows. Chapter \ref{chap:background} 
provides a history of image mosaicking and stitching approaches. 
Chapter \ref{chap:related} discusses related work in sea ice and image mosaicking 
tasks of aerial and underwater imagery. In Chapter \ref{chap:features} we discuss 
the process of assessing feature descriptor performance on this dataset and present 
performance results of common approaches. Segmenting sea ice from the surrounding 
water and size estimation considered in Chapter \ref{chap:segmentation}. Image matching, 
registration, and blending is presented in Chapter \ref{chap:registration}. In Chapter 
\ref{chap:results} sample results are provided with a discussion and evaluation 
of the approach. Finally, in Chapter \ref{chap:conclusion}, a summary and goals 
for future work is presented. 

\chapter{Background}
\label{chap:background}
We assume that the readers have basic knowledge of digital photography and 
aerial vehicles, however basic concepts are summarized here before 
delving into more complicated computational concepts. 

\section{Digital Imaging}
Digital cameras are ubiquitous and convienent sensors for
capturing and recording a specific 
range of electromagnetic radiation. The images that we are working with in this 
thesis are from the visible spectrum and represent images as they are seen 
with the human eye. 
TODO: talk about focal length - lens properties, resolution

\section{Remote Sensing}
Remote sensing is the term used to describe the process of obtaining data without 
physical contact. The field of remote sensing, like most modern fields that 
are associated with data, has experienced an explosion in the amount, quality, and 
accessibility of data. Traditional remote sensing platforms like airplanes and 
satelites are being augmented with low-cost UAVs making data production and analysis 
accessible to hobbyist and professionals alike. In addition to sensors working through 
the air, underwater platforms like Remotely Operated Vehicles (ROVs) and Autonomous 
Underwater Vehicles (AUVs) are also providing remote sensing through water 
with sound and images. 
With the balloon in accessibility of data have come 
automated methods for interpreting the data including, but not limited to  mosaicking. 
Pixel-wise segmentation of imagery and object classification are 
two additional tasks that 
simplify the data into categories and allow for more complex 
analysis and understanding.


\section{Unmanned Aerial Vehicles}
UAVs have a wide variety of capabilities in terms of payload, endurance, weight, 
and speed. One important consideration for shipboard 
operations is the space needed for launch and recovery. Fixed wing vehicles are 
typically more stable and have longer range than rotary wing vehicles, but have 
a more complicated deployment, especially on a small ship. 
\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=.9\linewidth,height=0.6\linewidth]{uav_snow_d.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{The Phantom FPV Flying Wing EPO UAV used to gather data over sea ice. This vehicle was equipped with a TODO camera for capturing images. }
         \label{fig:no_features}
     \end{minipage}%
     \begin{minipage}{.5\textwidth}
         \centering
        \includegraphics[width=.9\linewidth,height=0.6\linewidth]{launch_uav_d.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{UAVs have small space requirments for both storage and flight, making them ideal scouts for working off of a ship.}
             \label{fig:good_features}
      \end{minipage}
\end{figure}

\chapter{Sea Ice Monitoring}

Sea ice monitoring is an important issue for vessels operating in polar environments. 

\section{Sensors}
Many governments and organizations dedicate significant resources to providing 
timely assessments and maps of sea ice coverage at a macro scale to ensure safety 
of their citizens and gain greater understanding of the earth's processes. 
Lagunov describes the value of sea ice monitoring and provided an 
overview of useful sensors, including the UAV \cite{Lagunov14}.

\begin{figure}
    \label{CanadaModis}
\centering
\includegraphics[width=.9\linewidth, height=0.6\linewidth]{modis-canada-sea-ice.jpg}
        \captionsetup{width=.9\linewidth}
        \captionof{figure}{
        Composite image with a resolution of 100 meters from the MODIS satelite of the Canadian Artic produced by the Canadian Ice Service. These mosaics are produced weekly by the agency, but are subject to atmospheric and sea conditions. \cite{MODIS, CanadianIceService}}
             \label{fig:good_features}
\end{figure}


Today, the most common technique for monitoring sea ice is through data obtained 
by satellites. 
In addition to cameras operating in the visual spectrum,
sea ice is also frequently monitored by 
active sensors which can 
build models of the physical geometry of the ice. 
Radar can effectively evalutate 
sea ice thickness and allow estimates of ice density. 
Synthetic Aperture Radars (SARs) 
are a form of high-resolution active microwave 
that is commonly used to determine the 
age of ice and differentiate between ice and water.
TODO: explain more about SAR maybe show an image

One of the most public available datasets is produced by the Canadian Ice Service, 
which provides many georeferenced images with ice assesments over the Artic. 
The Canadian Ice Services utilizes the low resolution RADARSAT and MODIS 
satellite data to provide a weekly macro observation every week \cite{CanadianIceService}. An example of a weekly report can be seen in 
Figure \ref{CanadaModis}.


The agency also produces daily ice charts, which are an estimate of the current ice 
conditions based on satelite data that is augmented with aerial and ship data. 
The aerial maps produced by the agency also include details on assessments by 
experts with a resolution of up to 1 meter. This is a valuble data source that 
also contains ice floe sizes, sheet boundaries, 
and the locations of icebergs and is used for ship routing


TODO: explain sonar
In addition to aerial imagery, sea ice can also be quantified from underwater sensors, 
typically sonars that measure physical properties of the ice. 
To obtain valid measurements from under the ice, underwater vehicles are typically 
deployed. These measurements can provide valuable information about the 
characteristics of ice, especially for scientific purposes, but are resource
intensive to operate and are generally out of scope for typical polar expeditions. 



%Manual of ICE
%https://www.ec.gc.ca/glaces-ice/default.asp?lang=En&n=2CE448E2-1

\section{Sea Ice Modeling}

Much of the published work concerning the segmentation of sea 
ice from water is performed on data collected 
from synthetic apertaure radar images collected from satellites. Yang introduced a 
Markov random field (MRF) model for segmentation \cite{Yang09}
Wang also presented results from estimating SAR imagery using a 
convolutional neural network (CNN) \cite{Wang16}. While this work is interesting 
and encouraging, the dataset from the low-resolution SAR imagery and our high 
resolution images are different enough that there exists little overlap in the 
applications. 


However, there has been interest in working with sea ice imagery collected 
from UAVs in recent years. 
Skjetne et. al proposed utilizing UAVs for drift prediction to aid ships 
attempting to maintain Dynamic Positioning (DP) in ice-laden waters \cite{Skjetne14}.
Dynamic Positioning refers to the computer control system that maintains a 
vessel's position and heading. DP systems typically actuate a vessels propellers 
and thrusters based on input from position reference sensors such as GPS, 
gyrocompasses, wind sensors, and current measurement devices. 
These systems are a vital part of modern ships and are incredibly 
important for drilling operations in which a vessel must maintain an absolute position 
above a drill site. For a ship attempting to maintain position amongst ice, it is 
important to know where the ice is moving in advance so as to correctly position 
the ship. At present, sea ice is usually measured at close range using a marine radar 
or manually with helicopter surveillence. UAVs are safer and less 
resouce intensive than helicopters and can easily provide larger coverage than 
marine solutions. Skjetne divided ice monitoring into two problems; the first is 
the one that we will tackle, dynamic sea ice monitoring to track the movement 
of large bodies of ice sheets. The second problem is that of tracking large icebergs 
which involves recognizing icebergs on temporally spaced observations and tracking 
their movement.  
Skjetne worked on path planning with simulated icebergs. He also proposed a method 
of monitoring sea ice concentration by thresholding grayscale imagery of sea ice. 
He also estimated floe size, by finding closed boundaries around individual 
ice flows using the Gradient Vector Flow Snake algorithm to detect closed curves. 

Flaten discussed mosaicing sea ice images for the purpose of UAV navigation in \cite{Flaten-thesis15}, 
but, was unable to demonstrate results using field data. 
Demonstrated sea ice segmentation on data collected from a UAV
and presented results from Otsu thresholding but lacked ground 
truth. This project also attempted to provide ice density 
estimation by segmenting the image to produce an occupancy grid 
map estimation of sea ice density. 


Billington proposed the use of UAVs for shape estimation of icebergs at sea
with UAVs equiped with imaging systems and provided a description of requirements 
for operations \cite{Billington15}. He proposed a neural network to perform 
shape estimation of the keel, or submerged portion of the iceberg based on the observed 
surface and demostrated his effort on a small sample size that made it difficult to 
evaluate. 


TODO: Phd thesis \cite{Haugen14}


\chapter{Image Mosaicking}

An image mosaic is a synthetic wide-angle camera view which is built from a set of smaller images with 
an overlapping field of view. 
Image mosaicking has been extensively used to gain a greater viewpoint of the world. 
Historically, images were captured on air balloons and airplanes and then printed 
and aligned by hand. In modern times, digital cameras and smartphones are capable of 
automatically stitching panoramas on a small platform. 
There exists a large and robust body of work for creating mosaics from digital photographs
\cite{Milgram75,  Szeliski97, Shum00, Brown03 },
video \cite{Szeliski96, Steedly05} and for full 3D 
reconstruction \cite{Morimoto97, Shum-3D98}. These methods are more fully 
reviewed by Prathap \cite{Prathap16} and Zitova \cite{Zitova03}.


TODO: panoramic vs mosaic
Mosaics with extended field of view benefit 
from the relatively large and equal distance to the scene in each image. 
- taken in such scenarios are challenging as compared to panoramic construction
or other mosaicking methods such as satellite image mosaicking. 

Constructing an image mosaic typically consists of several general steps:

\begin{enumerate}
    \item{\textbf{Determine images with overlapping views of a scene.} }
    \item{\textbf{Estimate the homography between images with overlapping scenes.} }
    \item{\textbf{Align overlapping images onto a common frame.}}
    \item{\textbf{Blend image seams to improve appearance.}}
\end{enumerate}

In the next few sections, each step in the mosaic building process will be 
discussed with more detail and we will give an explanation of our approach to the 
problem of mosaicing sea ice. 

\section{Determining Image Overlap}
A reasonable amount of scene overlap (about 15-30\% overlap) with high quality features 
is typically required to determine that two images should be stitched together. 
Even if two images contain the scene, they  
may have a different view of the same region. This difference in view can make
make determining the correspondence difficult. Common changes in scene include 
differences in illumination, a rotated view, scaling, or moving objects. 
In the next section we discuss 
methods used to quantify how similar two images are, given different viewpoints. 

\subsection{Quantifying Image Similarity}
Relating the images 
requires overcoming noise and finding unrelated, unknown translations, scaling, 
and rotations between images. 
Methods of determining image similarity generally falls into two camps:
direct and feature based approaches. Direct methods perform correlations or 
convolution operations over the prospective
images to measure their similarity. This involes 
a computation across all of the pixels in the image and tends to be
slow and memory intensive 
\cite{Lucas81, Barnea72, Szeliski95, Shum-local98, Irani00}. 
However, direct methods are able to solve for motion of the 
camera and the correspondence of every pixel at the same time. Because this approach 
compares pixel values directly, it is prone to falter under illumination changes. 
The more modern approach is feature based..
Feature
based methods only measure the similarity of images based on 
interesting regions of the image, such as lines, blobs, or edges. 
The interesting regions are called \emph{features} 
or \emph{keypoints}. Keypoints within the image must be found algorithmically 
by a keypoint detection algorithm. Then the keypoint is described by a 
\emph{descriptor} using a descriptor algorithm.  Descriptors have been developed so 
that they are invariant to many of the transformations that plague images. 
By comparing images using only their interesting features, the motion of the 
camera can be solved for using only the
parts of the image in which correspondence is easy to detect. This reduces 
computational waste and improves accuracy.
The geometry calculated using the descriptors 
is then used to transform all of the pixels in 
the image. 

The feature based technique was perhaps first described by Schmid, who utilized Gaussian derivitives 
to describe a keypoint in a manner that was rotationally invariant \cite{Schmid97}.
Feature based methods are typically the modern approach because they are 
generally less computationally intensive than direct methods and because the 
feature descriptors can be developed to be invariant to image
tranformations \cite{Forstner86, Lowe99, Brown03, Hu06, Elibol08}. 
Our approach utilizes features and is discussed more thouroughly in 
Chapter \ref{chap:features}. From here onward
we will assume that overlap detection 
is performed using the feature based approach. 

\subsection{Matching Features}
After keypoints are extracted from two images, they must be compared for 
similarity to determine if the images contain regions of the same scene. 

TODO: talk about Flann matcher - others, 


\subsection{Image Overlap Search Space}
Knowing the location of the viewpoint from 
which the images were captured can reduce the search space for overlap. This 
may include using a GPS location or timestamp of the photo with some knowledge 
of the motion of the camera. Low cost sensors, particularly those used on 
lightweight UAVs, generally do not provide accurate enough estimates of position 
to give per-pixel allignment for high-resolution images at close range (<100m). 

Several practitioners of image mosaicing have demonstrated 
ways in which to use sensor information to reduce the search space for overlapping 
images in applications. 

Proposed a real-time approach of mosaicing images from UAVs for disaster 
response. First, the images were downsampled and roughly aligned using only 
GPS and IMU data, then as bandwidth allowed, the alignment was refined using 
feature based methods.  \cite{TODO}

Lin used a low-resolution image (from a satelite) to provide rough-alignment of the 
images as they were captured on the UAV. This exploited known ground reference
points to enable georeferencing \cite{Lin07}. Although an interesting approach, 
satellite imagery generally updates too slowly 
to be useful for the dynamic state of sea ice. 


\section{Defining the Transformation}
After the corresponding pixels 
between overlapping images have been identified, we need to estimate
the relationship between the images. This 
process is called image registration and attempts to find an alignment  
between the images that minimizes the difference between overlapping pixels.
A Homography is a transformation that is defined by a matrix which 
maps the points in one image to
the corresponding points in the other image.
The transformations 
can be translation, similarity, affine, or projective with 2, 4, 6, and 8 parameters 
respectively. 
We will discuss each 
of these transformations in the following paragraphs as they are defined in 
\cite{SzeliskiBook}..
TODO explain transformations 

The image registration process can 
be described as $x'=H*x$ where $x$ is the image coordinate system and 
$x'$ is the mosaic coordinate system, and $H$ is the homography 
matrix that defines the tranformstion. 

A projective transform only preserves straight lines and is the farthest an 
image can be transformed. 
The projective transformation is used in many mosaicing approaches, but can 
result in errors in instances with low overlap between 
images or when there are few distinctive features available \cite{Wang11}.

An affine tranformation describes scale, rotation, translation, and skew 
between two 2D planes in 2D space. This model is unable to 
explain 3D motions between two image planes, but provides superior 
stability when compared to projective transformation. 
In near-flat  areas,  the 
errors of object height projections  may be  negligible. Thus, the 
affine  transformation  can  be  directly  implemented.  
For our sea ice imagery, we take advantage of the 
large distance to the scene and the generally planar terrain surface and
 adopt a model which assumes equal distance to each object in the image. This 
 allows the use of the more stable  
utilize affine transformation to translate the image coordinates.
 
% This can be computed without any knowledge of 
%the internal camera calibration parameters such as focal length, 
%optical center, or relative camera motion between frames. 


%An image 
%transformation can be described by ... type of transformation matrix.
%\ref{eq:General tranformation equation} where 
%\emph{$s_i$} indicates scaling, 
%\emph{$r_i$} rotation, and \emph{$t_i$} dictactes translation in the i-th direction. 
%Thus, the problem can be reduced to recovering each component independently.
%
%
% $$
% \label{eq:General transformation equation}
% M =
% \begin{bmatrix}
% s_xr_{11}&s_xr_{12}&t_x \\ s_yr_{21}&s_yr_{22}&t_y \\ 0&0&1\\
% \end{bmatrix}
% $$


%TODO: read \cite{Shum-local98}
%%%%%%%%%%%%%%%%%%%%%%%
%TODO: read \cite{Shum-3D98} about 3d stuff 
%This reduces the undesirable projection errors that are easily propagated 
%with prjoective transformations \cite{Wang11}.


\subsection{Match Refinement}

The correctness of the final mosaic is highly dependent on the 
acuracy of each of the calculated 
geometric relationship between overlapping images. 
Robust estimation methods are an essential part of determining the relationship 
between images. Many initial matches are incorrect. These incorrect matches 
can be thrown out by a filtering. 
Lowe showed that if the two best matches were close in distance, then the 
probability of a false match was high \cite{Lowe04}. To combat this, he 
proposed a simple \emph{Ratio Test}
to measure the distance of the best match over the distance 
of the second best match and eliminated the match if it was greater than a theshold. 

Another, more robust approach to filtering matches is RANSAC or "RANdom SAmple Consensus. RANSAC is a well known and widely used 
  iterative parameter 
 estimation technique. It works by repeatedly taking random samples from a set 
 of data, fitting it to a model and then measuring the error. 

 RANSAC can be described by the following actions: 
 TODO - check wording and correctness here 
\begin{enumerate}
    \item{Select a random set of minimum correspondences and compute the homography.}
    \item{Calculate a distance error for each of the sampled matches}
    \item{Compute the number of inliers consistent with the homography by the number 
    of correspondences for which the distance error is less than a set threshold }
   \item{Select the homography, $H$ with the most inliers as the matrix that describes the image transformation.}
   \item{Restimate the homography based on all of the matches classified as inliers by minimixing cost function}
\end{enumerate}



\section{Projection Models}


The calculated homography 
is used to warp the image onto the reference plane. 
A projection model is necessary to project a 3D scene onto a two-dimensional 
surface. The choice of a projection model is important and highly dependent on 
the selected data. 
For this work we assume a planar model to preserve simplicity and because the 
dataset consists of flat ice over a planar surface.
Here there exists a much  larger distance between 
the camera and the ground than  the vertical component of any of the  features. 

A spherical projection is often used in the case of a panoramoic in which 
the camera was rotated about its centerline. 

TODO: expand

\section{Global Optimization}

A globally consistent mosaic should use all overlap information to produce 
the best possible representation of the scene. This mosaic will include links
from images that are not consecutive in time

Typical approaches 
will either work by adding incremental links to the mosaics as in a real-time 
approach, or by solving for all of the images at once to distribute mis-registration 
errors after all images have been collected. 

TODO: talk about kalman filtering methods, etc

The process of simultaneously 
aligning all of the images is known as bundle adjustment and can be slow 
to converge, but generally produces a more correct image \cite{Pizarro-thesis}. 


\section{Blending}

Neighboring images in a mosaic can vary greatly in lighting, especially when 
subsequent images are seperated by time. 
To compensate for changes in illumination between neighboring images, 
it is often necessary to blend the images together in a 
manner such that the resulting mosaic is visually pleasing.  There are many 
methods of performing blending. 

TODO: talk about different approaches to blending

Our approach utilizes the open 
source tool, Enblend, that uses a multi-resolution spline to blend images 
together using multi-resolution splines and Laplacian pyramids \cite{enblend, 
Burt83thelaplacian}. 
The spline operates across a transition zone that is proportional 
to the spatial frequency of the region. Homogenous regions like an ice sheet 
have low spatial frequency and are combined across a wide region.
Strong color changes, 
show high spatial frequency and are fused over a small area. 


\chapter{Related Work}
\label{chap:related}
Although the area of image mosaicking has been widely studied for many years, 
some problems remain elusive. 
High altitude imagery and on-ground mosaicking such
as panoramic image construction are not in our area of in-
terest since they are dealing with different challenges.
These include but are not limited to: 
\begin{itemize}
    \item{Recovering from poor overlap}
    \item{Determining overlapping scenes with poor features}
    \item{Images taken at different seasons or with drastic lighting differences (day and night)} 
    \item{Resolution and quality of output mosaic}
    \item{Orthorectification and Structure from Motion TODO}
\end{itemize}

Prathap gives a thorough review of the current state of mosaicing \cite{Prathap16}. 


\section{Aerial Mosaicking}
Aerial mosaicking includes images captured from platforms such as satellites, 
manned aircraft, and unmanned aircraft. The first two platforms generally 
observe the earth from a higher altitude than what we are concerned with here and 
thus have looser requirements for stitching accuracy. For example, a popular instrument 
for observing the earth from satellite is MODIS (Moderate Resolution Imaging 
Spectroradiometer). MODIS is housed on the Terra and Aqua satellites which view the 
entire earth surface every 1 to 2 days at 36 distinct wavelengths with a spatial 
resoution of 500 m in the visible spectrum \cite{MODIS}. 



Many researchers and engineers have utilized UAVs to gather images to form large-scale 
photo mosaics \cite{ Caballero07, Yahyanejad10, Cheng10, Pritt14, Kekec14, Prasad16, Vousdoukas11, Wang11, Wang14}.
Images collected with a UAV can often be quickly, but roughly  aligned 
using data from sensors such as Global Positioning System (GPS) points and 
Intertial Measurement Unit (IMU) estimates.
However, these measurements are typically not 
accurate or reliable enough to generate a visually appealling image. 
Instead, most approaches for mosaicing UAV images use some form of a feature 
based approach to match images. Problems tend to occur when there exists 
low-overlap between images, moving objects in the survey area, or featureless 
images. 

Caballero uses the match success between images to limit the homography model selection. 
Using a simpler model if fewer matches are available \cite{Caballero07}.  
 Lin utilizes a low-resolution global map to align images \cite{Lin07}

 Qian et al. demonstrates the use of vehicle rotation rate
 information from gyros mounted to the vehicle to assist in the process 
 of matching camera features from frame to frame \cite{Qian01}. 

Registration \cite{Barnea72, Shum-local98, Sawhney99}



Prasad, et al investigated the problem of developing mosaics in quadcopter surveys 
with gaps in features using imu information to improve convergence time.
The approach was demonstrated on building walls with only small regions (paintings) 
that provided keypoints\cite{Prasad16} 

%\section{Related Tasks}
%Underwater scenes resemble ice scenes in that they can both be featureless and 
%large datasets. In 1996, Fleischer introduced video mosaicing underwater for arbitray 
%\cite{Fleischer96}. 


%Large area addition aided by navigational sensors 
%to generate 3D submaps that are merged using bundle adjustment \cite{Pizarro04}.
%
%MATISSE, released 
%in 2004 also provides mosaicing capability to seabed videos with navigation data
%in conjunction with ArcView\cite{Vincent03, Vincent04}. 
%TODO: read \cite{Eustice02, Ferrer07, Fleischer96, Vincent03, Vincent04} 
%In 2013 LAPM was 
%introduced to provide a general tool for underwater mosaicing for end-user scientists 
%in Matlab \cite{Marcon13}. It uses an open-source implementation of 
%SIFT features to match images in addition to track information. 
%Parallax free underwater \cite{Nagaraja14}
%Quantify scale changes and lighting changes 
%medium resolution 800x600 pixels 
%
%
%Discussed how to measure error in underwater mosaics using vehicle navigation 
%data \cite{Roman01}.
%


 \section{Dynamic Scenes}
Small dynamic scene mosaics have been tackled in \cite{Fitzgibbon01, Rav-Acha07, Davis98, Uyttendaele01}. 
However, our approach was to use a simpler, masking scheme to bar the feature 
extraction algorithm from extracting keypoints from the dynamic portions of our 
images. This is similar to the approach taken by Vousdoukas to mask sea and sea foam
from shoreline images captured form an UAV in which he 
manually selecting pixels associated with the 
sea and foam and thresholding based on these intensities \cite{Vousdoukas11}. Because 
Vousdoukas' mosaic was created along the shoreline, he was able to use 
interesting keypoints from the shoreline to complete the mosaic using SIFT features. 



\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{no_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A typical image of sea ice captured from a UAV with few features and homogoneous texture. }
         \label{fig:no_features}
     \end{minipage}%
     \begin{minipage}{.5\textwidth}
         \centering
        \includegraphics[width=.9\linewidth]{good_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A sea ice image with many corners and distinctive  features to use for feature matching. }
             \label{fig:good_features}
      \end{minipage}
\end{figure}


\chapter{Feature Evaluation in Homogenous Images}
\label{chap:features}

Like, most modern approaches, we register images by selecting key 
features from each image 
and attempting to relate them to other images in the scene. 
There exist a wide variety of feature extraction and description
techniques that enable matching between visual correspondences despite 
rotation, scaling, or environmental changes such as lighting 
noise. 
In addition to invariance, a high number of detected features is also desireable
to improve matching. 
Keypoints should have high information content as measured by 
repeatibility rate and information content. 

Feature detectors rely on the existence of edges, corners, or  blobs in 
the image to match images. If none occur, then no features can be detected. 
Feature detecting algorithms tend to have different strengths and weaknesses as 
discussed in several studies \cite{Tuytelaars08, Mikolajczyk05, Bekele13}. 
Bekele \cite{Bekele13} in particular proved a good 
overview of popular feature descriptors and 
detectors and their performance which guided our evaluation on sea ice dataset.
Describing keypoints is difficult in ice surveys 
because of the lack of distinguishable features on images that contain 
only ice or only water. All ice images often contain a high degree of repetitive 
simularity which means even distinctive features can be incorectly matched with 
non-overlapping images. 


% Quantifying a match
In the following sections, feature detectors and descriptors are discussed and 
evaluated on our dataset based on a number of points: 
\begin{itemize}
    \item{Average number of keypoints}
    \item{Precision of matches}
    \item{Recall of matches} 
    \item{Average number of best matches}
\end{itemize}
Parameters in each of the detectors are 
tuned so that 4000 features are detected in the reference image.  
If more than 4000 features are detected in the image, only the first 4000 
are used in the evaluation.  



\section{SIFT}
One of the most well known and often used keypoint descriptors is Scale
Invariant Feature Transforms (SIFT) \cite{Lowe04}. SIFT descriptors detects keypoints 
based on Difference of Gaussians (DOG). This algorithm, developed in 2004
has consistently been the top performer in terms of  
scale and rotation invariance, though it is has the highest overhead
of the descriptors discussed. 

\section{SURF}
A successor to SIFT, Speeded-Up Robust Features (SURF) 
yields similar feature performance to SURF, but with 
faster computation time \cite{Bay-SURF08}. The performance improvement is 
acomplished by describing keypoints with the responses of Haar-like filters. 
Haar features are global-texture based. Both SIFT and SURF use an orientation 
operator. 
%Good foundation paper on multiscale approach \cite{Brown05} ??
%- this seemed to have a good descript of sift: http://www.cs.cmu.edu/~rahuls/pub/cvpr2004-keypoint-rahuls.pdf

\section{ORB}
%ORB
The Oriented FAST and Rotated BRIEF descriptor, or ORB, 
is a computationally efficient alternative to SIFT and can be used in real-time 
on many platforms \cite{Rublee-ORB11}. 
Like its name suggests, it works off of the very efficient FAST keypoint 
detector \cite{Rosten-FAST06} and BRIEF descriptor \cite{Calonder-BRIEF10}.
ORB overcomes the lack or rotational invariance in the BRIEF descriptor by 
de-correlating BRIEF features under rotational invariance. 
Orb only somewhat scale invariant

%BRISK
%FREAK
\cite{FREAK}
The FREAK descriptor, developed in 2012 by Alahi et al improves upon the BRISK
descriptor \cite{Leutenegger-BRISK11}
inspired by the retinal pattern in the biological eye. 
FREAKs are in general faster to compute with lower memory load and also
more robust than SIFT, SURF or BRISK \cite{Alahi-FREAK12}
SURF keypoints are invariant to rotation and scale changes which makes them suitable to meet the requirements for BRISK and FREA.K

\section{Harris Keypoints with Zernike Descriptors}
In 2003, Pizarro introduced a zernike-feature based 
approach to mosaic large scale featureless.  
scenes underwater with lighting correction \cite{Pizarro03}. 
Zernike moment descriptors allow matching between points with arbitrary 
rotation and large scale changes in a computationally efficient methodology.  Zernike moements perform well in the presence of noise. 
Zernike momemnt are a set of orthogonal polynomials that offer a complete 
solution to recover rotational and scaling parameters. 
Used zernike to create mosaic - read more \cite{Zhanlong13}
\cite{dudek}

Harris keypoints are detected at the local minima of an autocorrelation 
function that is invariant to geometric image transformation \cite{Schmid98}. 
%ZERNIKE
Zernike \cite{Zhanlong13, Pizarro03, Badra98, Badra99}
\cite{Bin02}
about zernike \cite{Ameyah07} 

Zernike Polynomials 
complex polynomials that are orthogonal over the unit circle $x^2 + y^2 = 1$. 
They can be expressed in radial and angular components. 

%\label{eq:zernike polynomial}
%V_{nm}(x,y) = V_{nm}(\rho, \theta) = R_{nm}(\rho)\emph{e}^{im\theta}
%$
%\emph{n} is a positive integer
%\emph{m} is an integer such that $n-|m|$ is even and $|m|<=n$
%$\rho$ is the magnitude of the vector from the origin to the point $(x,y)=x^2+y^2$
%$\theta$ is the angle between the vector and the x-axis in a counter-clockwise direction



\section{Feature Discussion}
Alahi et al. show that using a grid of well performing descriptors achieves better 
matching than using a single one to match an image region \cite{Alahi10}. 


\chapter{Description of Approach}
\section{Online Approach}
\section{Global Approach}
This approach utilizes 
the knowledge that the UAV captured images in a spatial order as it was flying, 
so we attempt to match images with neighboring timestamps first.
This sequential approach is not necessary, but will decrease convergence time 
as it limits the number images that must be searched in a typical mission. 
Local motion around each feature point is expected to be mostly 
translational with minimal roll and pitch of the camera. 

%Features with a low success ratio in matching (about 0.5) are deleted from the 
%map if at least 10 matches have been attempted. Mapmaintence allows deleting of non 
%trackable features - for instance those captured on moving objects such as 
%waves or people. 

%The percentage of successful matches obtained by the point tracker is used to have an estimation about the level ofthehierarchywherethehomographycomputationshould start.Thesepercentagethresholdswereobtainedempirically byprocessinghundredsofaerialimages.Eachlevelinvolves thefollowingdifferentsteps:
%.Complete homography. Least median of squares (LMedS) is used for outlier rejection and a M-Estimator to compute the final result. This model is used if more than the 65\% of the matches are successfully tracked.
%. Affine homography. If the percentage of success in thetrackingstepisbetween40\% and65\%,thenthe LMedS isnotused,giventhereductioninthenumber ofmatches.A relaxedM-Estimator(softpenalization) is carried out to compute the model.
%
%Euclidean homography. If the percentage is below 40\%, the set of data is too noisy and small to apply non- linear minimizations. The model is computed using least-squares.
%\cite{Caballero07}



\chapter{Segmentation}
\label{chap:segmentation}
Because image stitching techniques utilize features that are consistent amongst 
overlapping images, dynamic or moving objects can cause false matches and incorrect 
homography estimations. Our images are captured serially with a single camera so 
that no two views of the scene are captured at the same moment. This means that 
nonstationary 
features in the scene are subject to change between images. In sea ice imagery, 
the sea is subject to waves and ripples that may be extracted as features, but 
will change over time and could result in false matches or no matches. 
There are many methods for mosaicing a scene with dynamics in the static mosaic. 
Some approaches eliminate all dynamic information in the scene, while others 
attempt to encapsulate the changes between images by overlaying the movement 
into the mosaic. For the purposes of this system, the dynamic movement 
of waves is not interesting information, mask this section. 
We can exclude water from the feature extraction by first segmenting
the image into ice and non-ice pixels. In addition to improving the feature 
extraction process, we are also able to form an estimate of the sea ice coverage 
for scientific and ship navigational purposes. 


TODO: 
Thresholding gray level occurance
gabor filter - texture
glcp - statistical
The histograms for sea ice images are generally bimodal
Show examples where bad keypoints are detected

***

\chapter{Experiments and Results}
\label{chap:results}
demo 
translation - minimal overlap, detected that there was no rotation or scaling.
rotation   - what angle limit?
-- show plot of actual angle of rotation vs calulated
scaling - images should be scaled to size of smallest before stitching
-- show plot of actual scaling vs calculated
demo 
\subsection{Aerial Surveys}

\subsection{Image Patches}
\section{Error Metrics} 
standard measurments, cross correlation between images - 
speed ...


\section{Validation - Synthetic Mosaic}
A synthetic survey is generated from a single image by dividing the image into
a grid overlapping sub-images.  This provides a planar scene with an ideal 
pinhole camera. Simple translations produce the resulting image. Another test 
introduced rotation and scaling into each sub-image. 

\chapter{Conclusion and Future Work}
\label{chap:conclusion}


\pagebreak{}
\section{References}
\bibliography{biblio}
\begin{vita}
This should be a one-page short vita.

There can be more paragraphs.\end{vita}
\end{document}



%
%\begin{figure}[H]
%\noindent \begin{centering}
%\framebox{\begin{minipage}[t]{1\columnwidth}%
%\textbackslash{}documentclass{[}12pt,english{]}\{report\}
%
%\textbackslash{}usepackage\{UTSAthesis\}
%
%... use other packages ...
%
%\textbackslash{}begin\{document\}
%
%\textbackslash{}committee\{... \}
%
%\textbackslash{}informationitems\{... \}
%
%\textbackslash{}thesiscopyright\{...\}
%
%\textbackslash{}dedication\{\textbackslash{}emph\{I would like to
%dedicate this thesis/dissertation to ...\}\}
%
%\textbackslash{}title\{\textbackslash{}textbf\{First line\}\textbackslash{}\textbackslash{}
%\textbackslash{}textbf\{second line \}...\}
%
%\textbackslash{}author\{...\} 
%\textbackslash{}maketitle 
%\textbackslash{}begin\{acknowledgements\} ... \textbackslash{}end\{acknowledgements\}
%\textbackslash{}begin\{abstract\} ... \textbackslash{}end\{abstract\}
%\textbackslash{}newpage 
%\textbackslash{}pagenumbering \{arabic\} 
%\textbackslash{}setcounter \{page\}\{1\} 
%\textbackslash{}pagestyle\{plain\}
%\textbackslash{}chapter\{...\} \% or \textbackslash{}include\{chap3\}
%...
%\textbackslash{}singlespace
%\textbackslash{}bibliographystyle\{...\} 
%\textbackslash{}bibliography\{...\}
%\textbackslash{}begin\{vita\}...\textbackslash{}end\{vita\}%
%\end{minipage}}
%\par\end{centering}
%\caption{Structure of a thesis \protect\LaTeX{} file\label{fig:Structure-of-thesis}}
%\end{figure}
%
%
%The following commands are defined in UTSAthesis.sty and should be
%used in the order suggested in Fig. \ref{fig:Structure-of-thesis}
%to provide required format information.
%\begin{itemize}
%\item \textbackslash{}title\{Thesis Title\}. This can contain multiple lines.
%Use ``\textbackslash{}\textbackslash{}'' to go to the next line.
%\item \textbackslash{}author\{Name of Thesis Author\}
%\item \textbackslash{}thesiscopyright\{Optional Copyright Statement\} 
%\item \textbackslash{}dedication\{Optional Dedication\} 
%\item Either \textbackslash{}committee\{Supervisor Name, Degree\}\{Co-Supervisor
%or Committee B Name, Degree\}\{Committee C Name, Degree\}\{Committee
%D Name, Degree\}\{Committee E Name, Degree\} or the following commands
%separately.
%
%\begin{itemize}
%\item \textbackslash{}supervisor\{Supervisor Name, Degree\} 
%\item \textbackslash{}cosupervisor\{Co-Supervisor Name, Degree\} or \textbackslash{}committeeB\{Committe
%member B Name, Degree\} 
%\item \textbackslash{}committeeC\{Committe member C, Degree\} 
%\item \textbackslash{}committeeD\{Committe member D, Degree\} 
%\item \textbackslash{}committeeE\{Committe member E, Degree\}
%\end{itemize}
%\item Either \textbackslash{}informationitems\{Full Name of Degree\}\{Short
%Name of Degree\}\{Full Name of Department\}\{Full Name of College\}\{Month
%of Thesis\}\{Year of Thesis\} or use the following commands separately.
%
%\begin{itemize}
%\item \textbackslash{}degree\{Full Degree Name\} 
%\item \textbackslash{}degreeshort\{Short Degree Name\} 
%\item \textbackslash{}department\{Department Name\} 
%\item \textbackslash{}college\{College Name\} 
%\item \textbackslash{}thesismonth\{Month\} 
%\item \textbackslash{}thesisyear\{Year\} 
%\end{itemize}
%\item \textbackslash{}maketitle is the command to produce the signature
%page, copyright page, dedication page, and the title page. The position
%of this command is important. 
%\item \textbackslash{}begin\{acknowledgements\}
%
%
%People, organization, supports that you want to thank for 
%
%
%\textbackslash{}end\{acknowledgements\}
%
%\item \textbackslash{}begin\{abstract\}
%
%
%The abstract starts here. Should within one page.
%
%
%\textbackslash{}end\{abstract\} 
%
%\item The thesis/dissertation should then continue with chapters, appendixes,
%references. Before the first chapter, it is necessary to set Arabic
%page number. If the thesis/dissertation is long, it may be better
%to place chapters into separate \LaTeX{} files and include these sub-files
%using \textbackslash{}include\{\} command.
%\item \textbackslash{}begin\{vita\}
%
%
%The last item is a one-page curriculum vita
%
%
%\textbackslash{}end\{vita\}
%
%\end{itemize}
%
%\subsection{Produce the Outcome}
%
%To produce the pdf version of the thesis/dissertation, run pdflatex
%and bibtex.
%
%
%\section{The utsathesis.layout Package}
%
%The utsathesis.layout is an \LyX{} layout that provides a \LyX{} document
%layout for UTSA dissertation/thesis. This layout should be used together
%with the UTSAthesis.sty.
%
%
%\subsection{Installation}
%
%First, install UTSAthesis.sty as described in Section \ref{sec:UTSAthesis.sty}.
%Then, installed the \LyX{} on your system by following the instruction
%that comes with the \LyX{} package. Next, place the utsathesis.layout
%into your personal \LyX{} directory. On a Linux/Unix system, this
%directory is at \textasciitilde{}/.lyx/layouts. On Mac OS, it is at
%/User/<name>/Library/Application Support/\LyX{}-<version>/layouts.
%On Windows 7, it is at C:\textbackslash{}Users\textbackslash{}<name>\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}lyx<version>\textbackslash{}layouts.
%Remember to run Tools->Reconfigure inside \LyX{} to re-configure the
%system.
%
%
%\subsection{Use of utsathesis.layout Package}
%
%This document (sampleThesis.lyx) provides a template for using the
%utsathesis.layout to write a Ph.D. dissertation. For a Master's thesis,
%go to Document->Settings and set the class option to ms. Other important
%settings may include Document->Settings->\LaTeX{} Preamble, and the
%bibliography style.
%
%The document setting should be ``report (UTSAthesis 2012)''. The
%document should begin with committee info, thesis info, copyright,
%and dedication. These can be formatted using items in the FrontMatter
%in the pull-down menu. These should be followed by title, author,
%acknowledgments and the abstract. The placement and the order of these
%four items are important for generating the correctly formatted front
%pages of the thesis/dissertation. It is also important to add the
%``Start First Page'' item right before the first chapter. This item
%will set the correct page numbers for the main portion of the thesis/dissertation.
%
%At the end of the document, the ``Vita'' item in the BackMatter
%in the pull-down menu needs to be used to format a one-page vita.
%
%Regular chapters can be included in the main thesis document or more
%likely as sub-files, one per chapter. If sub-files are preferred,
%make sure the document settings of all sub-files are identical to
%the main document. 
%
%
%\chapter{Literature Review}
%
%We have some citations \cite{dabiri-optimization-isqed-2008,melhem-ieeetc-2003,pradhan-fault-tolerance-1986}.
%See the Bibliography for the format of references.
%
%\include{chapt3}
%
%
%\chapter{Solution and Evaluation}
%
%In this chapter, we show the structures of math formula, theorem commands,
%and floats (such as algorithm and table).
%
%
%\section{A Theory}
%\begin{defn}
%This is another definition.\end{defn}
%\begin{thm}
%This is a theorem.
%\begin{equation}
%X=\frac{AB}{Y}
%\end{equation}
%\end{thm}
%\begin{proof}
%The proof is done here.
%\end{proof}
%
%\section{An Algorithm}
%
%The following is the algorithm.
%
%\begin{algorithm}
%\begin{enumerate}
%\item Step One
%\item Step Two
%\end{enumerate}
%\caption{The Do-It-Yourself Method}
%
%
%\end{algorithm}
%
%
%
%\subsection{Evaluation}
%
%The evaluation results is shown in the following table. It is straightforward
%to place the caption of the table above or below the table.
%
%\begin{table}
%\caption{Evaluation Results}
%
%
%\noindent \centering{}%
%\begin{tabular}{|c|c|c|c|}
%\hline 
% & Method 1 & Method 2 & Method 3\tabularnewline
%\hline 
%\hline 
%Criterion 1 &  &  & \tabularnewline
%\hline 
%Criterion 2 &  &  & \tabularnewline
%\hline 
%Criterion 3 &  &  & \tabularnewline
%\hline 
%\end{tabular}
%\end{table}
%
%
%The following is a long table
%
%\noindent \begin{center}
%\begin{longtable}{|c|c|c|c|c|}
%\caption{A Long Table\label{tab:A-Long-Table}}
%\endfirsthead
%\multicolumn{5}{c}{\textbf{Table \ref{tab:A-Long-Table}}: Continued}\tabularnewline
%\endhead
%\hline 
%Column1 & Column 2 & Column 3 & Column 4 & Column 5\tabularnewline
%\hline 
%\hline 
%1 &  &  &  & \tabularnewline
%\hline 
%2 &  &  &  & \tabularnewline
%\hline 
%3 &  &  &  & \tabularnewline
%\hline 
%4 &  &  &  & \tabularnewline
%\hline 
%5 &  &  &  & \tabularnewline
%\hline 
%6 &  &  &  & \tabularnewline
%\hline 
%7 &  &  &  & \tabularnewline
%\hline 
%8 &  &  &  & \tabularnewline
%\hline 
%9 &  &  &  & \tabularnewline
%\hline 
%10 &  &  &  & \tabularnewline
%\hline 
%11 &  &  &  & \tabularnewline
%\hline 
%12 &  &  &  & \tabularnewline
%\hline 
%13 &  &  &  & \tabularnewline
%\hline 
%14 &  &  &  & \tabularnewline
%\hline 
%15 &  &  &  & \tabularnewline
%\hline 
%16 &  &  &  & \tabularnewline
%\hline 
%17 &  &  &  & \tabularnewline
%\hline 
%18 &  &  &  & \tabularnewline
%\hline 
%19 &  &  &  & \tabularnewline
%\hline 
%20 &  &  &  & \tabularnewline
%\hline 
%21 &  &  &  & \tabularnewline
%\hline 
%22 &  &  &  & \tabularnewline
%\hline 
%23 &  &  &  & \tabularnewline
%\hline 
%24 &  &  &  & \tabularnewline
%\hline 
%25 &  &  &  & \tabularnewline
%\hline 
%26 &  &  &  & \tabularnewline
%\hline 
%27 &  &  &  & \tabularnewline
%\hline 
%28 &  &  &  & \tabularnewline
%\hline 
%29 &  &  &  & \tabularnewline
%\hline 
%30 &  &  &  & \tabularnewline
%\hline 
%31 &  &  &  & \tabularnewline
%\hline 
%32 &  &  &  & \tabularnewline
%\hline 
%33 &  &  &  & \tabularnewline
%\hline 
%\end{longtable}
%\par\end{center}
%
%
%\chapter{Future Directions}
%
%There can be more chapters.
%
%\appendix
%
%\chapter{Notations }
%
%Here we show the use of multiple appendixes.
%
%
%\section{Math Notations}
%
%Each appendix can have sub-sections as a regular chapter.
%
%
%\section{Additional Notations}
%
%
%\chapter{Ontologies}
%
%These is another appendix.

%the individual components. 
