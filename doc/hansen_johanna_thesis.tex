%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{longtable}
\usepackage{float}
\usepackage{calc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

%graphicx is not part of included utsa thesis
\usepackage{graphicx}
%\usepackage{subcaption}
\graphicspath{{./figures/}}
\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{UTSAthesis}      
\usepackage{times}            
\usepackage{latexsym}

\newenvironment{ruledcenter}{%
  \begin{center}
  \rule{\textwidth}{1mm} } {%
  \rule{\textwidth}{1mm} 
  \end{center}}%


  \theoremstyle{definition}
  \newtheorem{defn}{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

  \providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}

\begin{document}
\bibliographystyle{acm}
\committee{Sos Agaian, Ph.D., Chair}{Prof Hanumant Singh, Ph.D.}{Prof. C, Ph.D.}{Prof. D, Ph.D.}{Prof. E, Ph.D. }


\informationitems{Master of Science in Electrical Engineering}{M.Sc.}{Department of Electrical Engineering}{College of Engineering}{May}{ 2016 }


\thesiscopyright{Copyright 2016 Johanna Hansen \\
All rights reserved. }


\dedication{\emph{I would like to dedicate this thesis to the many mentors and 
teachers who have guided me throughout this process.}}


\title{\textbf{IceView: A System for Mosaicing Sea Ice in Changing Environments}}


\author{Johanna Hansen}
\maketitle
\begin{acknowledgements}

Thanks!

\end{acknowledgements}

\begin{abstract}
Unmanned Aerial Vehicles are providing revolutionary inexpensive, 
real-time access to the terrain around us. One application where this technology 
is especially valuable is for ships navigating in ice laden waters. For these ships, 
satellites are often too slow to provide up-to-date information and helicopters 
are cost prohibitive. 
Traditional image mosaicing algorithms tend to fail when faced with sea ice 
scenes for two reasons; ice itself typically has very few features from which 
to match to overlapping images and water pixels are dynamic in nature  
making it impossible to match with overlapping images that are taken at different 
points in time. The Iceview system attempts to solve these obstacles by 
utilizing multi-scale Harris point detector coupled with a Zernike feature 
descriptor.  This approach assumes that the extended scene 
is planar and determines homographies for each image by topology estimation 
through feature-based pairwise image registation across all images using a 
multi-scale Harris point detector with a feature descriptor. The approach is 
demonstrated using real data obtained on an Artic Expedition. 

\end{abstract}
\pageone{}

\chapter{Introduction}

\section{Motivation}

Expeditions into the world's frozen oceans requires expert navigation and 
real-time knowledge of the constantly shifting conditions. This region of the earth 
is both interesting from a scientific perspective  
because much of it remains unexplored. It also harbours rich natural resources 
that passage ways that are increasingly important to government and commercial 
interests. However, navigating and working in remote sea ice still presents 
a significant technological challenge and requires constant monitoring to work 
safely. Historically, ships working in these conditions
have relied on human scouts, helicopters, and/or satellite imagery to monitor 
the sea ice movement.  However, these approaches are resource intensive suboptimal
solutions. Manned aircraft such as helicopters are often prohibitively 
expensive and require 
expert pilots and precious deck space. Satellite sensors provide useful overviews, 
but are typically low-resolution, 
prone to occlusion by cloudcover or atmospheric conditions, 
and often updated at a prohibitively low frequency for shifting conditions.

Unmanned Aerial Vehicles (UAVs) equipped with high
resolution digital cameras offer a low-cost, real-time alternative to manned aircraft. 
They require little expertise to operate and little deck space. However, because 
there is no human observer of the terrain, the data collected from the vehicle must 
be processed and analyzed in a way that is useful for non-technical decision makers. 
Although UAVs can provide images with high resolution, each image only covers a 
small part of the interesting area.
 This means that a single flight can result in thousands 
of images that must be organized into a human-readable format. 
A process called image mosaicing must be performed to merge overlapping images 
of the terrain into a single high resolution image that is easy to comprehend and 
integrate into existing workflows. 
Image registration is the process of developing a pixel-to-pixel mapping between 
the views in the distinct images. 
By registering the many images into a single mosaic, 
we can create a composite scene called a mosaic with a large field of 
view, while maintaining high resolution.  

Algorithms for aligning and stitching images into photomosaics have been 
widely studied and commercialized, however, traditional
methods tend to fail when tasked with stitching sea ice imagery.
Both the ice and sea that are present in this type of imagery present challenges 
for tradational mosaicing approaches. The ice itself is often nearly featureless, 
making it difficult for feature-based matching schemes to work robustly. 
Bodies of water are generally useless for feature matching because of its dynamic 
properties and meaningless features over time. 
This report approaches these problems by developing a pipeline for working 
with a seaice dataset. 


\section{Background}
 [8], [20] [6]
[5]
Aerial photography has been used to gain a greater viewpoint of the world and 
has been used extensively reconassance, agriculture, and science. 
Historically, images were captured on air balloons and airplanes and then printed 
and aligned by hand. In modern times, digital cameras and smartphones are capable of 
automatically stitching panoramas on a small platform. 
There exists a large body of work for creating mosaics from digital photographs, 
beginning perhaps in 1975 with Milgram \cite{computermosaic, milgram2, }.
Early work in digital mosaicing generally fell into two camps, 
direct and feature based. Direct methods attempt to use correlations 
over the entire image to find overlapping regions in images, while feature based methods extract interesting regions (such as lines or edges) and measures the similarity of these regions to determine overlaps. 

In 2005, Brown et. al. defined a rotationally invariant, multi-scale, feature descriptor to match overlapping images \cite{multiscalepatch}.  
This panorama is a rotational motion solved by a cylindrical or spherical surface model.
To produce a UAV image mosaic, however, the rotional motion about the camera axis 
is replaced by a translational motion model that changes point of view.
Mosaics with extended field of view benefit 
from the relatively large and equal distance to the scene in each image. 

Images can be aligned quickly with Global Positioning System (GPS) and 
Intertial Measurement Unit (IMU) data, however, these measurements are not 
accurate enough for a visually appealling image. In addition, accurate measurements 
would require more expensive sensors. 
Moreover, GPS is not always a available or reliable at extreme latitudes where 
ships are often working in sea ice.
Prasad, et. al investigated the problem of developing mosaics in quadcopter surveys 
with gaps in features using imu information to improve convergence time.
The approach was demonstrated on building walls with only small regions (paintings) 
that provided keypoints\cite{mosaicimu} 
Instead, most approaches for mosaicing UAV images is to extract common 
features between consecutive images to infer the motion between images.
This approach requires some degree of overlap between images and significantly 
higher computing requirments than a simple alignment based on sensors, but it 
produces much more accurate results. 

There exist many open-source and proprietary packages for developing mosaics 
from overlapping imagery such as Autopano or PhotoScan \cite{Autopano, PhotoScan}. 
Autopano uses SIFT
However, our experminents indicate that these packages were not 
reliable for developing mosaics with sea ice 
data.  
The large volume of images with poor features that results from a typical  UAV sea-
ice survey seemed to incapacitate the algorithm. When the surveys were divided 
into geographic batches, 
stitching and warping errors typically resulted from the accuracy of feature 
matching or the projection of object height. We assume that the scene lies on a 
planar surface, and utilize knowledge about the structure of the survey to reduce 
the search space.
Traditional image mosaicing approaches work by finding an intersection of 
feature space between overlapping images. However, these methods fail when there
are gaps in the survey due to featureless spaces (such as solid ice or waves) 
in the images to be stitched. 

Flaten \cite{Norway} developed a system for navigating a quadcopter over sea ice using 
an infared camera. His approach compared SIFT, SURF, and ORB detectors and found 
that SURF performed best. A brute force search was used to match 3431 out of 
4119 images tested.

Most methods utilize intersting points, such as regions of color, edges, 
contours, or distinctive points. These features are then searched for in 
nearby images. If distinctive features are detected, they are matched to 
determine correspondences. 

TODO: overview of air, underwater mosaic

\section{Thesis Overview}

The problem of image mosaicing can be broken several steps involving detecting 
overlapping regions between images and then aligning merging them into a larger image.
For the iceview problem, we add an additional preliminary step to detect 
nonstationary features and remove them from the pixels that are considered for 
feature detection. 

\begin{enumerate}
\item{Segment the image into non-water and water regions}
\item{Extract features from non-water regions}
\item{Determine matching features between images}
\item{Estimate homography between images that contain the same keypoints}
\item{Warp images according to estimated homographies so that their overlapping 
regions align}
\item{Paste warped images onto a common scene and blend neighboring pixels}
\end{enumerate}

This approach is purely image based and does not neccessitate the use 
of navigation data.



\chapter{Segmentation}

Image stitching techniques utilize features that are consistent amongst 
overlapping images, however, UAV images are captured serially, so nonstationary 
features in the images are subject to change between images. In sea ice imagery, 
the sea is subject to waves and ripples that may be extracted as features, but 
will change over time and could result in false matches or no matches. 
There are many methods for mosaicing a scene with dynamics in the static mosaic. 
Some approaches eliminate all dynamic information in the scene, while others 
attempt to encapsulate the changes between images by overlaying the movement 
into the mosaic. For the purposes of the iceview system, the dynamic movement 
of waves is not interesting information, so we blur the movement in this section. 
We can exclude water from the feature extraction by first segmenting
the image into ice and non-ice pixels. 

TODO: 
Thresholding gray level occurance
gabor filter - texture
glcp - statistical
The histograms for sea ice images are generally bimodal

\chapter{Feature Detection and Matching}

The main problem in generating a map from ice imagery is finding overlapping regions between neighboring images and pasting them together 
with the correct rotation, translation, and scaling between images. 
Our approach utilizes 
the knowledge that the UAV captured images in a spatial order as it was flying, and we attempt to match images with neighboring timestamps first. 
This sequential approach is not necessary, but will decrease convergence time 
as it limits the number images that must be searched in a typical mission. 
Like, most modern approaches, we register images by selecting key 
features from each image 
and attempting to relate them to other images in the scene. Relating the images 
requires overcoming noise and finding unrelated, unknown translations, scaling, 
and rotations between images. After the relationships have been determined, 
it is also necessary to blend the related images together in a 
manner such that the resulting mosaic is visually pleasing, seamless, and accurate.

\section{Description of Features}
A set of features is computed for every image in the scene in order to compare 
and match overlapping images. These features are 
typically selected to be differentiable from surrounding pixels, and typically 
include corners or 2D features. This is sometimes difficult for ice surveys 
because of the lack of corners or distinguishable features on images that contain 
only ice or only water. All ice images often contain a high degree of repetitive 
simularity which means even distinctive features can be incorectly matched with 
non-overlapping images. 


\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{no_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A typical image of sea ice captured from a UAV with few features and homogoneous texture. }
         \label{fig:no_features}
     \end{minipage}%
     \begin{minipage}{.5\textwidth}
         \centering
        \includegraphics[width=.9\linewidth]{good_features.jpg}
        \captionsetup{width=0.9\linewidth}
        \captionof{figure}{A sea ice image with many corners and distinctive  features to use for feature matching. }
             \label{fig:good_features}
      \end{minipage}
\end{figure}


feature tracking may fail if there is insufficient matches such in cases when the 
discrete images have low overlap or have unremarkable features, such as 
images of textures. 
Descriptors are used to pre-process images in order to make their 
features more invariant to scale, rotation, and translation transformations. 
Choosing an appropriate feature detection and description algorithm is a 
tradeoff between feature uniqueness, robustness, lighting, and 
computation time. 


\label{sec:features}
A descriptor describes the neighborhood of pixels around a keypoint.  
Considerable effort has been invested in improving the robustness of 
descriptors to changes in sensors, illumination, and zoom.  
There exists a wide variety of feature extraction algorithms.
One of the most well known and often used keypoint descriptors is Scale
Invariant Feature Transform  or SIFT \cite{SIFT} which detects keypoints 
based on Difference of Gaussians (DOG). 
A successor to SIFT, Speeded-Up Robust Features (SURF) is a popular 
algorithm that yields similar feature performance to SIFT, but with 
faster computation time \cite{SURF}. 


\subsection{Zernike Descriptors}
Zernike moment descriptors allow matching between points with arbitrary 
rotation and large scale changes in a computationally efficient methodology.  Zernike moements perform well in the presence of noise. 

Edge density

Pizarro sucessfully demonstrated the the use of Zernike Moments for shape descriptors 
in low-contrast environments \cite{pizarro}. This technique has been applied 
for mosaicing by \cite{dudek} and \cite{dudekold} as well as for classification 
problems TODO cite other.

rotational invariant and can be made to be scale and translational invariant. 
Magnitude of zernike moments are rotationally invariant. Used by \cite{pizarro}
Zernike momemnt are a set of orthogonal polynomials that offer a complete 
solution to recover rotational and scaling parameters. 

Zernike Polynomials 
complex polynomials that are orthogonal over the unit circle $x^2 + y^2 = 1$. 
They can be expressed in radial and angular components. 

$
\label{eq:zernike polynomial}
V_{nm}(x,y) = V_{nm}(\rho, \theta) = R_{nm}(\rho)\emph{e}^{im\theta}
$
\emph{n} is a positive integer
\emph{m} is an integer such that $n-|m|$ is even and $|m|<=n$
$\rho$ is the magnitude of the vector from the origin to the point $(x,y)=x^2+y^2$
$\theta$ is the angle between the vector and the x-axis in a counter-clockwise direction


Corner detectors are fast to find 
and describe, but more effort must be spent to match and reject incorrect 
matches. Sharp corners and edges make excellent features for detection 
and matching, this does not exist on images that are encompassed 
entirely be and iceberg. 
Corner like features -Hessian and eigenvalue.
Harris corners are not invariant to scaling, and cross correlation
is not invariant to translation. 
\section{Initial Match}
Local motion around each feature point is expected to be mostly 
translational. 
Manually identify four or more corresponding points between two views, which
 is enough information to solve for eight unknowns in the 2-D projective
 transformation. 

Two images contain brightness changes, viewpoint, rotation, scale.
To evaluate the descriptors on this dataset, four parameters were 
calculated for each of the proposed descriptors. 
Average number of keypoints, precision in percentage, recall in percentage, 
average number of best matches. Parameters in each of the detectors are 
tuned so that xxx features are detected in the reference image.  
If more than xxx features are detected, the first xxx are taken as 
in \cite{Bekele}.  

Calculation of the precision is performed by finding 
\section{Outlier Rejection}
the ration of the number of matches that are output of RANSAC from each 
ratio test matches. 

Recall is calculated by taking the ratio of ransac 
matches to the number of keypoints. 

Accuracy is the ratio of the number of ransac matches to the number of 
keypoints. 

Average number of best matches - multiplying the average number of 
keypoints with the percentage of the accuracy. 

\subsection{Evaluation of Feature Descriptors}
Evaluation of keypoint detectors. Bekele et al provides an evaluation 
of keypoint detectors in \cite{Bekele} in which escriptors are considered 
from BRIEF, ORB, BRISK, and FREAK. 
Recall and precision can be used to compare performance of descriptors 
demonstrated.

\chapter{Feature Matching}
\section{Topology Tranformation} 
For ice imagery, we can take advantage of the 
large distance to the scene and the generally planar terrain surface 
to adopt a model which assumes equal distance to each object in the image.
The distance from the camera to the target object is much greater than the 
motion between the camera views, so a homographic model can be used to describe. 
 2-D projective transformation. Can be computed without any knowledge of 
the internal camera calibration parameters.  No need to know focal length, 
optical center, or relative camera motion between frames. 

An image 
transformation can be described by ... type of transformation matrix.
\ref{eq:General tranformation equation} where 
\emph{$s_i$} indicates scaling, 
\emph{$r_i$} rotation, and \emph{$t_i$} dictactes translation in the i-th direction. 
Thus, the problem can be reduced to recovering each component independently.


 $$
 \label{eq:General transformation equation}
 M =
 \begin{bmatrix}
 s_xr_{11}&s_xr_{12}&t_x \\ s_yr_{21}&s_yr_{22}&t_y \\ 0&0&1\\
 \end{bmatrix}
 $$

TODO: Discuss the history of each of the problems and show tests
Traditional matching algorithms recover motion models 

Once a match is determined between two images, each pixel from the source image 
must be mapped to a pixel coordinate in the destination image. 


 Ratio test? - ratio of the distance of the best match to the second best
 match - if this ratio is greater than 0.9 both of the matches are ignored. 
 If not, the best match is kept. This eliminates false matches. 
add new images to mosaic one at a time, aligning the most recent image with the 
previous ones already in the collection. A better alternative is to simultaneously 
align all the images together using a least squares framework to distribute 
mis-registration errors. The process of simultaneously adjusting pose parameters 
number of images in bundle adjustment. structure from motion problem
Bundle adjustment can solve for all camera parameters jointly. This minimizes
accumulated errors between pairwise homographies. 

Incremental links - solves for the global mosaic using the overlaps of the 
temporal sequence. 
 
 The disadvantage of bundle adjustment is that there are more variables to solve 
 for, so both each iteration and overal onvergence is slower. 

extract features and put into indexing structure
compare feature descriptors to find best match
ransac find set of inliers using pair of matches to hypothesize a similary

The transformation between any two overlapping images can be described
linearly decomposed in to translation, rotation, and scaling components.
Image registration involves overlaying multiple images from the same scene 
that were captured from a subset of different viewpoints, times, and/or cameras.

\chapter{Global Registration}

We assume that the terrain to be mosaiked is approximately flat, 
we can utilize affine transofrmations to translate image coordinates \cite{Wang}.
This reduces the undesirable projection errors that are easily propagated 
with prjojective transformations \cite{Wang}.



\section{Blending}
Neighboring images in a mosaic can vary greatly in lighting, especially when 
subsequent images are seperated by time. 
When merging two images into one image, the seams are typically blended 
to produce a result more pleasing to the human eye. 
Our approach utilizes the open 
source tool, Enblend, that uses a multi-resolution spline to blend images 
together using multi-resolution splines and Laplacian pyramids \cite{enblend, 
Burt83thelaplacian}. 
The spline operates across a transition zone that is proportional 
to the spatial frequency of the region. Homogenous regions like an ice sheet 
have low spatial frequency and are combined across a wide region.
Strong color changes, 
like a seal lying on an ice sheet, show high spatial frequency and are fused 
over a small area. 

\chapter{Assumptions and Approach}
Assume that images have been acquired in a temporal sequence to improve matching time. 
Although this is
not required, it reduces convergence time. Navigation nor inertial measurement 
data is not required to properly match images, though could be 
incorporated for faster matching. 

\chapter{Experiments}
demo 
translation - minimal overlap, detected that there was no rotation or scaling.
rotation   - what angle limit?
-- show plot of actual angle of rotation vs calulated
scaling - images should be scaled to size of smallest before stitching
-- show plot of actual scaling vs calculated
demo 
\subsection{Aerial Surveys}

\subsection{Image Patches}

\chapter{Results}
\section{Error Metrics} 
standard measurments, cross correlation between images - 
speed ...


\section{Validation - Synthetic Mosaic}
A synthetic survey is generated from a single image by dividing the image into
a grid overlapping sub-images.  This provides a planar scene with an ideal 
pinhole camera. Simple translations produce the resulting image. Another test 
introduced rotation and scaling into each sub-image. 

\chapter{Conclusion and Future Work}
\subsection{UAV Sensor Integration}


\pagebreak{}
\section{References}
\bibliography{biblio}
\begin{vita}
This should be a one-page short vita.

There can be more paragraphs.\end{vita}
\end{document}



%
%\begin{figure}[H]
%\noindent \begin{centering}
%\framebox{\begin{minipage}[t]{1\columnwidth}%
%\textbackslash{}documentclass{[}12pt,english{]}\{report\}
%
%\textbackslash{}usepackage\{UTSAthesis\}
%
%... use other packages ...
%
%\textbackslash{}begin\{document\}
%
%\textbackslash{}committee\{... \}
%
%\textbackslash{}informationitems\{... \}
%
%\textbackslash{}thesiscopyright\{...\}
%
%\textbackslash{}dedication\{\textbackslash{}emph\{I would like to
%dedicate this thesis/dissertation to ...\}\}
%
%\textbackslash{}title\{\textbackslash{}textbf\{First line\}\textbackslash{}\textbackslash{}
%\textbackslash{}textbf\{second line \}...\}
%
%\textbackslash{}author\{...\} 
%\textbackslash{}maketitle 
%\textbackslash{}begin\{acknowledgements\} ... \textbackslash{}end\{acknowledgements\}
%\textbackslash{}begin\{abstract\} ... \textbackslash{}end\{abstract\}
%\textbackslash{}newpage 
%\textbackslash{}pagenumbering \{arabic\} 
%\textbackslash{}setcounter \{page\}\{1\} 
%\textbackslash{}pagestyle\{plain\}
%\textbackslash{}chapter\{...\} \% or \textbackslash{}include\{chap3\}
%...
%\textbackslash{}singlespace
%\textbackslash{}bibliographystyle\{...\} 
%\textbackslash{}bibliography\{...\}
%\textbackslash{}begin\{vita\}...\textbackslash{}end\{vita\}%
%\end{minipage}}
%\par\end{centering}
%\caption{Structure of a thesis \protect\LaTeX{} file\label{fig:Structure-of-thesis}}
%\end{figure}
%
%
%The following commands are defined in UTSAthesis.sty and should be
%used in the order suggested in Fig. \ref{fig:Structure-of-thesis}
%to provide required format information.
%\begin{itemize}
%\item \textbackslash{}title\{Thesis Title\}. This can contain multiple lines.
%Use ``\textbackslash{}\textbackslash{}'' to go to the next line.
%\item \textbackslash{}author\{Name of Thesis Author\}
%\item \textbackslash{}thesiscopyright\{Optional Copyright Statement\} 
%\item \textbackslash{}dedication\{Optional Dedication\} 
%\item Either \textbackslash{}committee\{Supervisor Name, Degree\}\{Co-Supervisor
%or Committee B Name, Degree\}\{Committee C Name, Degree\}\{Committee
%D Name, Degree\}\{Committee E Name, Degree\} or the following commands
%separately.
%
%\begin{itemize}
%\item \textbackslash{}supervisor\{Supervisor Name, Degree\} 
%\item \textbackslash{}cosupervisor\{Co-Supervisor Name, Degree\} or \textbackslash{}committeeB\{Committe
%member B Name, Degree\} 
%\item \textbackslash{}committeeC\{Committe member C, Degree\} 
%\item \textbackslash{}committeeD\{Committe member D, Degree\} 
%\item \textbackslash{}committeeE\{Committe member E, Degree\}
%\end{itemize}
%\item Either \textbackslash{}informationitems\{Full Name of Degree\}\{Short
%Name of Degree\}\{Full Name of Department\}\{Full Name of College\}\{Month
%of Thesis\}\{Year of Thesis\} or use the following commands separately.
%
%\begin{itemize}
%\item \textbackslash{}degree\{Full Degree Name\} 
%\item \textbackslash{}degreeshort\{Short Degree Name\} 
%\item \textbackslash{}department\{Department Name\} 
%\item \textbackslash{}college\{College Name\} 
%\item \textbackslash{}thesismonth\{Month\} 
%\item \textbackslash{}thesisyear\{Year\} 
%\end{itemize}
%\item \textbackslash{}maketitle is the command to produce the signature
%page, copyright page, dedication page, and the title page. The position
%of this command is important. 
%\item \textbackslash{}begin\{acknowledgements\}
%
%
%People, organization, supports that you want to thank for 
%
%
%\textbackslash{}end\{acknowledgements\}
%
%\item \textbackslash{}begin\{abstract\}
%
%
%The abstract starts here. Should within one page.
%
%
%\textbackslash{}end\{abstract\} 
%
%\item The thesis/dissertation should then continue with chapters, appendixes,
%references. Before the first chapter, it is necessary to set Arabic
%page number. If the thesis/dissertation is long, it may be better
%to place chapters into separate \LaTeX{} files and include these sub-files
%using \textbackslash{}include\{\} command.
%\item \textbackslash{}begin\{vita\}
%
%
%The last item is a one-page curriculum vita
%
%
%\textbackslash{}end\{vita\}
%
%\end{itemize}
%
%\subsection{Produce the Outcome}
%
%To produce the pdf version of the thesis/dissertation, run pdflatex
%and bibtex.
%
%
%\section{The utsathesis.layout Package}
%
%The utsathesis.layout is an \LyX{} layout that provides a \LyX{} document
%layout for UTSA dissertation/thesis. This layout should be used together
%with the UTSAthesis.sty.
%
%
%\subsection{Installation}
%
%First, install UTSAthesis.sty as described in Section \ref{sec:UTSAthesis.sty}.
%Then, installed the \LyX{} on your system by following the instruction
%that comes with the \LyX{} package. Next, place the utsathesis.layout
%into your personal \LyX{} directory. On a Linux/Unix system, this
%directory is at \textasciitilde{}/.lyx/layouts. On Mac OS, it is at
%/User/<name>/Library/Application Support/\LyX{}-<version>/layouts.
%On Windows 7, it is at C:\textbackslash{}Users\textbackslash{}<name>\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}lyx<version>\textbackslash{}layouts.
%Remember to run Tools->Reconfigure inside \LyX{} to re-configure the
%system.
%
%
%\subsection{Use of utsathesis.layout Package}
%
%This document (sampleThesis.lyx) provides a template for using the
%utsathesis.layout to write a Ph.D. dissertation. For a Master's thesis,
%go to Document->Settings and set the class option to ms. Other important
%settings may include Document->Settings->\LaTeX{} Preamble, and the
%bibliography style.
%
%The document setting should be ``report (UTSAthesis 2012)''. The
%document should begin with committee info, thesis info, copyright,
%and dedication. These can be formatted using items in the FrontMatter
%in the pull-down menu. These should be followed by title, author,
%acknowledgments and the abstract. The placement and the order of these
%four items are important for generating the correctly formatted front
%pages of the thesis/dissertation. It is also important to add the
%``Start First Page'' item right before the first chapter. This item
%will set the correct page numbers for the main portion of the thesis/dissertation.
%
%At the end of the document, the ``Vita'' item in the BackMatter
%in the pull-down menu needs to be used to format a one-page vita.
%
%Regular chapters can be included in the main thesis document or more
%likely as sub-files, one per chapter. If sub-files are preferred,
%make sure the document settings of all sub-files are identical to
%the main document. 
%
%
%\chapter{Literature Review}
%
%We have some citations \cite{dabiri-optimization-isqed-2008,melhem-ieeetc-2003,pradhan-fault-tolerance-1986}.
%See the Bibliography for the format of references.
%
%\include{chapt3}
%
%
%\chapter{Solution and Evaluation}
%
%In this chapter, we show the structures of math formula, theorem commands,
%and floats (such as algorithm and table).
%
%
%\section{A Theory}
%\begin{defn}
%This is another definition.\end{defn}
%\begin{thm}
%This is a theorem.
%\begin{equation}
%X=\frac{AB}{Y}
%\end{equation}
%\end{thm}
%\begin{proof}
%The proof is done here.
%\end{proof}
%
%\section{An Algorithm}
%
%The following is the algorithm.
%
%\begin{algorithm}
%\begin{enumerate}
%\item Step One
%\item Step Two
%\end{enumerate}
%\caption{The Do-It-Yourself Method}
%
%
%\end{algorithm}
%
%
%
%\subsection{Evaluation}
%
%The evaluation results is shown in the following table. It is straightforward
%to place the caption of the table above or below the table.
%
%\begin{table}
%\caption{Evaluation Results}
%
%
%\noindent \centering{}%
%\begin{tabular}{|c|c|c|c|}
%\hline 
% & Method 1 & Method 2 & Method 3\tabularnewline
%\hline 
%\hline 
%Criterion 1 &  &  & \tabularnewline
%\hline 
%Criterion 2 &  &  & \tabularnewline
%\hline 
%Criterion 3 &  &  & \tabularnewline
%\hline 
%\end{tabular}
%\end{table}
%
%
%The following is a long table
%
%\noindent \begin{center}
%\begin{longtable}{|c|c|c|c|c|}
%\caption{A Long Table\label{tab:A-Long-Table}}
%\endfirsthead
%\multicolumn{5}{c}{\textbf{Table \ref{tab:A-Long-Table}}: Continued}\tabularnewline
%\endhead
%\hline 
%Column1 & Column 2 & Column 3 & Column 4 & Column 5\tabularnewline
%\hline 
%\hline 
%1 &  &  &  & \tabularnewline
%\hline 
%2 &  &  &  & \tabularnewline
%\hline 
%3 &  &  &  & \tabularnewline
%\hline 
%4 &  &  &  & \tabularnewline
%\hline 
%5 &  &  &  & \tabularnewline
%\hline 
%6 &  &  &  & \tabularnewline
%\hline 
%7 &  &  &  & \tabularnewline
%\hline 
%8 &  &  &  & \tabularnewline
%\hline 
%9 &  &  &  & \tabularnewline
%\hline 
%10 &  &  &  & \tabularnewline
%\hline 
%11 &  &  &  & \tabularnewline
%\hline 
%12 &  &  &  & \tabularnewline
%\hline 
%13 &  &  &  & \tabularnewline
%\hline 
%14 &  &  &  & \tabularnewline
%\hline 
%15 &  &  &  & \tabularnewline
%\hline 
%16 &  &  &  & \tabularnewline
%\hline 
%17 &  &  &  & \tabularnewline
%\hline 
%18 &  &  &  & \tabularnewline
%\hline 
%19 &  &  &  & \tabularnewline
%\hline 
%20 &  &  &  & \tabularnewline
%\hline 
%21 &  &  &  & \tabularnewline
%\hline 
%22 &  &  &  & \tabularnewline
%\hline 
%23 &  &  &  & \tabularnewline
%\hline 
%24 &  &  &  & \tabularnewline
%\hline 
%25 &  &  &  & \tabularnewline
%\hline 
%26 &  &  &  & \tabularnewline
%\hline 
%27 &  &  &  & \tabularnewline
%\hline 
%28 &  &  &  & \tabularnewline
%\hline 
%29 &  &  &  & \tabularnewline
%\hline 
%30 &  &  &  & \tabularnewline
%\hline 
%31 &  &  &  & \tabularnewline
%\hline 
%32 &  &  &  & \tabularnewline
%\hline 
%33 &  &  &  & \tabularnewline
%\hline 
%\end{longtable}
%\par\end{center}
%
%
%\chapter{Future Directions}
%
%There can be more chapters.
%
%\appendix
%
%\chapter{Notations }
%
%Here we show the use of multiple appendixes.
%
%
%\section{Math Notations}
%
%Each appendix can have sub-sections as a regular chapter.
%
%
%\section{Additional Notations}
%
%
%\chapter{Ontologies}
%
%These is another appendix.

%the individual components. 
